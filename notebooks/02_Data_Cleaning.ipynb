{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4828def3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 NETTOYAGE SYSTÉMATIQUE DES DONNÉES E-COMMERCE\n",
      "=======================================================\n",
      "📋 Plan d'action basé sur l'analyse qualité\n",
      "🎯 Approche MLOps : fonctions réutilisables\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NOTEBOOK 2 : NETTOYAGE DES DONNÉES E-COMMERCE\n",
    "# ============================================================================\n",
    "# Objectif : Nettoyer SYSTEMATIQUEMENT toutes les anomalies identifiées\n",
    "# Pipeline : Automatisable et scalable\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🧹 NETTOYAGE SYSTÉMATIQUE DES DONNÉES E-COMMERCE\")\n",
    "print(\"=\" * 55)\n",
    "print(\"📋 Plan d'action basé sur l'analyse qualité\")\n",
    "print(\"🎯 Approche MLOps : fonctions réutilisables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e8b6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 ÉTAT INITIAL DU DATASET\n",
      "==============================\n",
      "Lignes : 1,067,371\n",
      "Colonnes : 8\n",
      "Mémoire : 345.1 MB\n",
      "\n",
      "🔴 PROBLÈMES IDENTIFIÉS :\n",
      "  missing_customer_id: 243,007\n",
      "  missing_description: 4,382\n",
      "  total_duplicates: 34,335\n",
      "  negative_quantities: 22,950\n",
      "  zero_prices: 6,202\n",
      "  negative_prices: 5\n",
      "  wrong_dtypes: 2\n",
      "\n",
      "📊 TOTAL PROBLÈMES : 310,883\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📊 1. CHARGEMENT ET ÉTAT INITIAL\n",
    "# ============================================================================\n",
    "\n",
    "# Chargement des données\n",
    "df = pd.read_csv('C:/Users/Moi/E-commerce_Marketing_Analytics/data/raw/online_retail_II.csv', encoding='iso-8859-1')\n",
    "\n",
    "print(\"📊 ÉTAT INITIAL DU DATASET\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Lignes : {len(df):,}\")\n",
    "print(f\"Colonnes : {len(df.columns)}\")\n",
    "print(f\"Mémoire : {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Snapshot des problèmes AVANT nettoyage\n",
    "initial_issues = {\n",
    "    'missing_customer_id': df['Customer ID'].isnull().sum(),\n",
    "    'missing_description': df['Description'].isnull().sum(),\n",
    "    'total_duplicates': df.duplicated().sum(),\n",
    "    'negative_quantities': (df['Quantity'] < 0).sum(),\n",
    "    'zero_prices': (df['Price'] == 0).sum(),\n",
    "    'negative_prices': (df['Price'] < 0).sum(),\n",
    "    'wrong_dtypes': 2  # InvoiceDate + Customer ID\n",
    "}\n",
    "\n",
    "print(\"\\n🔴 PROBLÈMES IDENTIFIÉS :\")\n",
    "for issue, count in initial_issues.items():\n",
    "    print(f\"  {issue}: {count:,}\")\n",
    "\n",
    "total_issues = sum(initial_issues.values())\n",
    "print(f\"\\n📊 TOTAL PROBLÈMES : {total_issues:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20885367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 FONCTIONS DE NETTOYAGE CRÉÉES\n",
      "✅ Prêtes pour pipeline automatisé\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🔧 2. FONCTIONS DE NETTOYAGE (PIPELINE RÉUTILISABLE)\n",
    "# ============================================================================\n",
    "\n",
    "def clean_data_types(df):\n",
    "    \"\"\"\n",
    "    Convertit les types de données aux formats appropriés\n",
    "    NOMS RÉELS: Invoice, Price, Customer ID, InvoiceDate\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"🔧 CORRECTION DES TYPES DE DONNÉES\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # 1. Conversion InvoiceDate\n",
    "    try:\n",
    "        df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])\n",
    "        print(\"✅ InvoiceDate: object → datetime64\")\n",
    "    except:\n",
    "        print(\"⚠️  Erreur conversion InvoiceDate\")\n",
    "    \n",
    "    # 2. Customer ID: float → string (IDENTIFIANT MÉTIER)\n",
    "    df_clean['Customer ID'] = df_clean['Customer ID'].apply(\n",
    "        lambda x: str(int(x)) if pd.notna(x) else x\n",
    "    )\n",
    "    print(\"✅ Customer ID: float64 → string (identifiant métier)\")\n",
    "    print(f\"   Exemple: {df_clean['Customer ID'].dropna().head(3).tolist()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    Gère les valeurs manquantes selon la logique métier\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"\\n🔍 GESTION DES VALEURS MANQUANTES\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Customer ID manquants : créer des IDs temporaires\n",
    "    missing_customers = df_clean['Customer ID'].isnull()\n",
    "    n_missing = missing_customers.sum()\n",
    "    \n",
    "    if n_missing > 0:\n",
    "        # Créer des IDs temporaires uniques\n",
    "        temp_ids = [f\"GUEST_{i:06d}\" for i in range(n_missing)]\n",
    "        df_clean.loc[missing_customers, 'Customer ID'] = temp_ids\n",
    "        print(f\"✅ {n_missing:,} Customer ID manquants → IDs temporaires\")\n",
    "        print(f\"   Exemple: {temp_ids[:3]}\")\n",
    "    \n",
    "    # Description manquantes : garder comme NaN pour analyse\n",
    "    missing_desc = df_clean['Description'].isnull().sum()\n",
    "    if missing_desc > 0:\n",
    "        print(f\"📝 {missing_desc:,} descriptions manquantes conservées\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def handle_duplicates(df):\n",
    "    \"\"\"\n",
    "    Identifie et supprime les doublons\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"\\n🔄 GESTION DES DOUBLONS\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Identifier les doublons\n",
    "    duplicates = df_clean.duplicated()\n",
    "    n_duplicates = duplicates.sum()\n",
    "    \n",
    "    if n_duplicates > 0:\n",
    "        print(f\"🔍 {n_duplicates:,} doublons identifiés\")\n",
    "        \n",
    "        # Analyser les doublons avant suppression - NOM CORRECT: Invoice\n",
    "        duplicate_invoices = df_clean[duplicates]['Invoice'].nunique()\n",
    "        print(f\"📋 Factures concernées: {duplicate_invoices:,}\")\n",
    "        \n",
    "        # Supprimer les doublons\n",
    "        df_clean = df_clean.drop_duplicates()\n",
    "        print(f\"✅ {n_duplicates:,} doublons supprimés\")\n",
    "    else:\n",
    "        print(\"✅ Aucun doublon détecté\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def handle_business_logic(df):\n",
    "    \"\"\"\n",
    "    Applique les règles métier e-commerce\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"\\n🏪 LOGIQUE MÉTIER E-COMMERCE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # 1. Séparer les ventes et les retours - NOM CORRECT: Invoice\n",
    "    returns = df_clean['Invoice'].str.startswith('C', na=False)\n",
    "    sales = ~returns\n",
    "    \n",
    "    n_returns = returns.sum()\n",
    "    n_sales = sales.sum()\n",
    "    \n",
    "    print(f\"📊 Ventes normales: {n_sales:,}\")\n",
    "    print(f\"📊 Retours/Annulations: {n_returns:,}\")\n",
    "    \n",
    "    # 2. Marquer le type de transaction\n",
    "    df_clean['Transaction_Type'] = np.where(returns, 'RETURN', 'SALE')\n",
    "    \n",
    "    # 3. Calculer le montant total \n",
    "    df_clean['Total_Amount'] = df_clean['Quantity'] * df_clean['Price']\n",
    "    \n",
    "    # 4. Identifier les transactions suspectes \n",
    "    df_clean['Suspicious'] = (\n",
    "        (df_clean['Price'] <= 0) | \n",
    "        (df_clean['Quantity'] == 0) |\n",
    "        (df_clean['Total_Amount'] == 0)\n",
    "    )\n",
    "    \n",
    "    suspicious_count = df_clean['Suspicious'].sum()\n",
    "    print(f\"🚨 Transactions suspectes: {suspicious_count:,}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def handle_outliers(df):\n",
    "    \"\"\"\n",
    "    Identifie et marque les outliers (sans les supprimer)\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print(\"\\n📊 GESTION DES OUTLIERS\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Outliers pour les prix - NOM CORRECT: Price\n",
    "    price_positive = df_clean[df_clean['Price'] > 0]['Price']\n",
    "    if len(price_positive) > 0:\n",
    "        Q1_price = price_positive.quantile(0.25)\n",
    "        Q3_price = price_positive.quantile(0.75)\n",
    "        IQR_price = Q3_price - Q1_price\n",
    "        price_upper = Q3_price + 1.5 * IQR_price\n",
    "        \n",
    "        df_clean['Price_Outlier'] = (df_clean['Price'] > price_upper) & (df_clean['Price'] > 0)\n",
    "        price_outliers = df_clean['Price_Outlier'].sum()\n",
    "        print(f\"📈 Outliers prix: {price_outliers:,} (seuil: {price_upper:.2f})\")\n",
    "    \n",
    "    # Outliers pour les quantités\n",
    "    qty_positive = df_clean[df_clean['Quantity'] > 0]['Quantity']\n",
    "    if len(qty_positive) > 0:\n",
    "        Q1_qty = qty_positive.quantile(0.25)\n",
    "        Q3_qty = qty_positive.quantile(0.75)\n",
    "        IQR_qty = Q3_qty - Q1_qty\n",
    "        qty_upper = Q3_qty + 1.5 * IQR_qty\n",
    "        \n",
    "        df_clean['Quantity_Outlier'] = (df_clean['Quantity'] > qty_upper) & (df_clean['Quantity'] > 0)\n",
    "        qty_outliers = df_clean['Quantity_Outlier'].sum()\n",
    "        print(f\"📦 Outliers quantité: {qty_outliers:,} (seuil: {qty_upper:.0f})\")\n",
    "    \n",
    "    print(\"📝 Outliers conservés mais marqués pour analyse\")\n",
    "    \n",
    "    return df_clean\n",
    "print(\"🔧 FONCTIONS DE NETTOYAGE CRÉÉES\")\n",
    "print(\"✅ Prêtes pour pipeline automatisé\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41ee4aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 EXÉCUTION DU PIPELINE COMPLET\n",
      "========================================\n",
      "🚀 DÉMARRAGE DU PIPELINE DE NETTOYAGE\n",
      "=============================================\n",
      "🔧 CORRECTION DES TYPES DE DONNÉES\n",
      "===================================\n",
      "✅ InvoiceDate: object → datetime64\n",
      "✅ Customer ID: float64 → string (identifiant métier)\n",
      "   Exemple: ['13085', '13085', '13085']\n",
      "\n",
      "🔍 GESTION DES VALEURS MANQUANTES\n",
      "===================================\n",
      "✅ 243,007 Customer ID manquants → IDs temporaires\n",
      "   Exemple: ['GUEST_000000', 'GUEST_000001', 'GUEST_000002']\n",
      "📝 4,382 descriptions manquantes conservées\n",
      "\n",
      "🔄 GESTION DES DOUBLONS\n",
      "=========================\n",
      "🔍 26,479 doublons identifiés\n",
      "📋 Factures concernées: 5,132\n",
      "✅ 26,479 doublons supprimés\n",
      "\n",
      "🏪 LOGIQUE MÉTIER E-COMMERCE\n",
      "==============================\n",
      "📊 Ventes normales: 1,021,752\n",
      "📊 Retours/Annulations: 19,140\n",
      "🚨 Transactions suspectes: 6,206\n",
      "\n",
      "📊 GESTION DES OUTLIERS\n",
      "=========================\n",
      "📈 Outliers prix: 67,113 (seuil: 8.50)\n",
      "📦 Outliers quantité: 53,759 (seuil: 28)\n",
      "📝 Outliers conservés mais marqués pour analyse\n",
      "\n",
      "✅ NETTOYAGE TERMINÉ !\n",
      "📊 Données finales: 1,040,892 lignes\n",
      "📊 Nouvelles colonnes: 13\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🚀 3. PIPELINE DE NETTOYAGE COMPLET\n",
    "# ============================================================================\n",
    "\n",
    "def complete_cleaning_pipeline(df):\n",
    "    \"\"\"\n",
    "    Pipeline complet de nettoyage des données\n",
    "    \"\"\"\n",
    "    print(\"🚀 DÉMARRAGE DU PIPELINE DE NETTOYAGE\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Étape 1: Types de données\n",
    "    df_clean = clean_data_types(df)\n",
    "    \n",
    "    # Étape 2: Valeurs manquantes\n",
    "    df_clean = handle_missing_values(df_clean)\n",
    "    \n",
    "    # Étape 3: Doublons\n",
    "    df_clean = handle_duplicates(df_clean)\n",
    "    \n",
    "    # Étape 4: Logique métier\n",
    "    df_clean = handle_business_logic(df_clean)\n",
    "    \n",
    "    # Étape 5: Outliers\n",
    "    df_clean = handle_outliers(df_clean)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Exécution du pipeline\n",
    "print(\"🎯 EXÉCUTION DU PIPELINE COMPLET\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "df_cleaned = complete_cleaning_pipeline(df)\n",
    "\n",
    "print(f\"\\n✅ NETTOYAGE TERMINÉ !\")\n",
    "print(f\"📊 Données finales: {len(df_cleaned):,} lignes\")\n",
    "print(f\"📊 Nouvelles colonnes: {len(df_cleaned.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "104410e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 ANALYSE DÉTAILLÉE DES RÉSULTATS\n",
      "========================================\n",
      "📈 RÉSUMÉ DES TRANSFORMATIONS :\n",
      "  • Lignes originales: 1,067,371\n",
      "  • Lignes finales: 1,040,892\n",
      "  • Lignes supprimées: 26,479\n",
      "  • Colonnes ajoutées: 5\n",
      "\n",
      "🆕 NOUVELLES COLONNES CRÉÉES :\n",
      "  • Transaction_Type\n",
      "  • Total_Amount\n",
      "  • Suspicious\n",
      "  • Price_Outlier\n",
      "  • Quantity_Outlier\n",
      "\n",
      "👥 ANALYSIS DES CUSTOMER ID :\n",
      "  • Total clients uniques: 248,949\n",
      "  • Clients enregistrés: 248,947\n",
      "  • Clients invités: 2\n",
      "\n",
      "💰 ANALYSE DES TRANSACTIONS :\n",
      "  • Ventes: 1,021,752\n",
      "  • Retours: 19,140\n",
      "\n",
      "💵 ANALYSE DES MONTANTS :\n",
      "  • Chiffre d'affaires brut: $20,445,293.52\n",
      "  • Montant des retours: $1,516,344.05\n",
      "  • Chiffre d'affaires net: $18,928,949.47\n",
      "\n",
      "🚨 ANALYSE DES OUTLIERS :\n",
      "  • Outliers prix: 67,113 (6.4%)\n",
      "  • Outliers quantité: 53,759 (5.2%)\n",
      "  • Transactions suspectes: 6,206 (0.6%)\n",
      "\n",
      "📋 APERÇU DES DONNÉES NETTOYÉES :\n",
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
      "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
      "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
      "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
      "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
      "\n",
      "          InvoiceDate  Price Customer ID         Country Transaction_Type  \\\n",
      "0 2009-12-01 07:45:00   6.95       13085  United Kingdom             SALE   \n",
      "1 2009-12-01 07:45:00   6.75       13085  United Kingdom             SALE   \n",
      "2 2009-12-01 07:45:00   6.75       13085  United Kingdom             SALE   \n",
      "3 2009-12-01 07:45:00   2.10       13085  United Kingdom             SALE   \n",
      "4 2009-12-01 07:45:00   1.25       13085  United Kingdom             SALE   \n",
      "\n",
      "   Total_Amount  Suspicious  Price_Outlier  Quantity_Outlier  \n",
      "0          83.4       False          False             False  \n",
      "1          81.0       False          False             False  \n",
      "2          81.0       False          False             False  \n",
      "3         100.8       False          False              True  \n",
      "4          30.0       False          False             False  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📊 ANALYSE DÉTAILLÉE DES RÉSULTATS DE NETTOYAGE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"🎯 ANALYSE DÉTAILLÉE DES RÉSULTATS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Résumé des transformations\n",
    "print(\"📈 RÉSUMÉ DES TRANSFORMATIONS :\")\n",
    "print(f\"  • Lignes originales: {len(df):,}\")\n",
    "print(f\"  • Lignes finales: {len(df_cleaned):,}\")\n",
    "print(f\"  • Lignes supprimées: {len(df) - len(df_cleaned):,}\")\n",
    "print(f\"  • Colonnes ajoutées: {len(df_cleaned.columns) - len(df.columns)}\")\n",
    "\n",
    "# 2. Analyse des nouvelles colonnes\n",
    "print(\"\\n🆕 NOUVELLES COLONNES CRÉÉES :\")\n",
    "new_columns = [col for col in df_cleaned.columns if col not in df.columns]\n",
    "for col in new_columns:\n",
    "    print(f\"  • {col}\")\n",
    "\n",
    "# 3. Analyse des Customer ID\n",
    "print(\"\\n👥 ANALYSIS DES CUSTOMER ID :\")\n",
    "total_customers = df_cleaned['Customer ID'].nunique()\n",
    "guest_customers = df_cleaned['Customer ID'].str.startswith('GUEST_').sum()\n",
    "real_customers = total_customers - df_cleaned['Customer ID'].str.startswith('GUEST_').nunique()\n",
    "\n",
    "print(f\"  • Total clients uniques: {total_customers:,}\")\n",
    "print(f\"  • Clients enregistrés: {real_customers:,}\")\n",
    "print(f\"  • Clients invités: {df_cleaned['Customer ID'].str.startswith('GUEST_').nunique():,}\")\n",
    "\n",
    "# 4. Analyse des transactions\n",
    "print(\"\\n💰 ANALYSE DES TRANSACTIONS :\")\n",
    "transaction_summary = df_cleaned['Transaction_Type'].value_counts()\n",
    "print(f\"  • Ventes: {transaction_summary.get('SALE', 0):,}\")\n",
    "print(f\"  • Retours: {transaction_summary.get('RETURN', 0):,}\")\n",
    "\n",
    "# 5. Analyse des montants\n",
    "print(\"\\n💵 ANALYSE DES MONTANTS :\")\n",
    "total_sales = df_cleaned[df_cleaned['Transaction_Type'] == 'SALE']['Total_Amount'].sum()\n",
    "total_returns = df_cleaned[df_cleaned['Transaction_Type'] == 'RETURN']['Total_Amount'].sum()\n",
    "net_revenue = total_sales + total_returns  # Les retours sont déjà négatifs\n",
    "\n",
    "print(f\"  • Chiffre d'affaires brut: ${total_sales:,.2f}\")\n",
    "print(f\"  • Montant des retours: ${abs(total_returns):,.2f}\")\n",
    "print(f\"  • Chiffre d'affaires net: ${net_revenue:,.2f}\")\n",
    "\n",
    "# 6. Analyse des outliers\n",
    "print(\"\\n🚨 ANALYSE DES OUTLIERS :\")\n",
    "price_outliers = df_cleaned['Price_Outlier'].sum()\n",
    "qty_outliers = df_cleaned['Quantity_Outlier'].sum()\n",
    "suspicious = df_cleaned['Suspicious'].sum()\n",
    "\n",
    "print(f\"  • Outliers prix: {price_outliers:,} ({price_outliers/len(df_cleaned)*100:.1f}%)\")\n",
    "print(f\"  • Outliers quantité: {qty_outliers:,} ({qty_outliers/len(df_cleaned)*100:.1f}%)\")\n",
    "print(f\"  • Transactions suspectes: {suspicious:,} ({suspicious/len(df_cleaned)*100:.1f}%)\")\n",
    "\n",
    "# 7. Aperçu des données nettoyées\n",
    "print(\"\\n📋 APERÇU DES DONNÉES NETTOYÉES :\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc22da34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 CONTRÔLE QUALITÉ FINAL\n",
      "==============================\n",
      "📊 VALEURS MANQUANTES RESTANTES :\n",
      "  • Description: 4,382 (0.4%)\n",
      "\n",
      "🔧 TYPES DE DONNÉES FINAUX :\n",
      "  • Invoice: object\n",
      "  • StockCode: object\n",
      "  • Description: object\n",
      "  • Quantity: int64\n",
      "  • InvoiceDate: datetime64[ns]\n",
      "  • Price: float64\n",
      "  • Customer ID: object\n",
      "  • Country: object\n",
      "  • Transaction_Type: object\n",
      "  • Total_Amount: float64\n",
      "  • Suspicious: bool\n",
      "  • Price_Outlier: bool\n",
      "  • Quantity_Outlier: bool\n",
      "\n",
      "🔄 DOUBLONS RESTANTS: 0\n",
      "\n",
      "✅ TESTS DE COHÉRENCE :\n",
      "  • Dates valides: 1,040,892\n",
      "  • Customer IDs valides: 1,040,892\n",
      "  • Montants calculés: 1,040,892\n",
      "\n",
      "🎉 CONTRÔLE QUALITÉ TERMINÉ !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🔍 CONTRÔLE QUALITÉ FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔍 CONTRÔLE QUALITÉ FINAL\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 1. Vérification des valeurs manquantes\n",
    "print(\"📊 VALEURS MANQUANTES RESTANTES :\")\n",
    "missing_summary = df_cleaned.isnull().sum()\n",
    "for col, missing in missing_summary.items():\n",
    "    if missing > 0:\n",
    "        print(f\"  • {col}: {missing:,} ({missing/len(df_cleaned)*100:.1f}%)\")\n",
    "\n",
    "# 2. Vérification des types de données\n",
    "print(\"\\n🔧 TYPES DE DONNÉES FINAUX :\")\n",
    "for col in df_cleaned.columns:\n",
    "    print(f\"  • {col}: {df_cleaned[col].dtype}\")\n",
    "\n",
    "# 3. Vérification des doublons\n",
    "remaining_duplicates = df_cleaned.duplicated().sum()\n",
    "print(f\"\\n🔄 DOUBLONS RESTANTS: {remaining_duplicates:,}\")\n",
    "\n",
    "# 4. Cohérence des données\n",
    "print(\"\\n✅ TESTS DE COHÉRENCE :\")\n",
    "print(f\"  • Dates valides: {df_cleaned['InvoiceDate'].notna().sum():,}\")\n",
    "print(f\"  • Customer IDs valides: {df_cleaned['Customer ID'].notna().sum():,}\")\n",
    "print(f\"  • Montants calculés: {(df_cleaned['Total_Amount'] == df_cleaned['Quantity'] * df_cleaned['Price']).sum():,}\")\n",
    "\n",
    "print(\"\\n🎉 CONTRÔLE QUALITÉ TERMINÉ !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c8c24d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 SAUVEGARDE DES DONNÉES NETTOYÉES\n",
      "===================================\n",
      "✅ Données sauvegardées: 'data/cleaned_ecommerce_data.csv'\n",
      "\n",
      "📊 RÉSUMÉ DU NETTOYAGE :\n",
      "  • original_rows: 1,067,371\n",
      "  • final_rows: 1,040,892\n",
      "  • duplicates_removed: 26,479\n",
      "  • guest_customers_created: 243,007\n",
      "  • total_revenue: 20,445,293.518\n",
      "  • outliers_identified: 120,872\n",
      "\n",
      "🎯 DONNÉES PRÊTES POUR L'ANALYSE !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 💾 SAUVEGARDE DES DONNÉES NETTOYÉES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"💾 SAUVEGARDE DES DONNÉES NETTOYÉES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Sauvegarder le dataset nettoyé\n",
    "df_cleaned.to_pickle('C:/Users/Moi/E-commerce_Marketing_Analytics/data/processed/cleaned_ecommerce_data.pkl')\n",
    "print(\"✅ Données sauvegardées: 'data/cleaned_ecommerce_data.csv'\")\n",
    "\n",
    "# Sauvegarder un résumé du nettoyage\n",
    "cleaning_summary = {\n",
    "    'original_rows': len(df),\n",
    "    'final_rows': len(df_cleaned),\n",
    "    'duplicates_removed': len(df) - len(df_cleaned),\n",
    "    'guest_customers_created': df_cleaned['Customer ID'].str.startswith('GUEST_').sum(),\n",
    "    'total_revenue': df_cleaned[df_cleaned['Transaction_Type'] == 'SALE']['Total_Amount'].sum(),\n",
    "    'outliers_identified': df_cleaned['Price_Outlier'].sum() + df_cleaned['Quantity_Outlier'].sum()\n",
    "}\n",
    "\n",
    "print(\"\\n📊 RÉSUMÉ DU NETTOYAGE :\")\n",
    "for key, value in cleaning_summary.items():\n",
    "    print(f\"  • {key}: {value:,}\")\n",
    "\n",
    "print(\"\\n🎯 DONNÉES PRÊTES POUR L'ANALYSE !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0b75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
