{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c7fcecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 NOTEBOOK 3 : ANALYSE EXPLORATOIRE\n",
      "========================================\n",
      "📊 Découverte des patterns business\n",
      "🔍 Insights actionnables\n",
      "📈 Visualisations interactives\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NOTEBOOK 3 : ANALYSE EXPLORATOIRE DES DONNÉES E-COMMERCE\n",
    "# ============================================================================\n",
    "# Objectif : Découvrir les patterns, tendances et insights cachés\n",
    "# Focus : Visualisations actionables pour le business\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"🎯 NOTEBOOK 3 : ANALYSE EXPLORATOIRE\")\n",
    "print(\"=\" * 40)\n",
    "print(\"📊 Découverte des patterns business\")\n",
    "print(\"🔍 Insights actionnables\")\n",
    "print(\"📈 Visualisations interactives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5318c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 APERÇU DES DONNÉES NETTOYÉES\n",
      "===================================\n",
      "📏 Dimensions: (1040892, 13)\n",
      "📅 Période: 2009-12-01 07:45:00 → 2011-12-09 12:50:00\n",
      "🌍 Pays: 43\n",
      "👥 Clients: 248,949\n",
      "📦 Produits: 5,305\n",
      "\n",
      "🔧 TYPES DE DONNÉES :\n",
      "Invoice                     object\n",
      "StockCode                   object\n",
      "Description                 object\n",
      "Quantity                     int64\n",
      "InvoiceDate         datetime64[ns]\n",
      "Price                      float64\n",
      "Customer ID                 object\n",
      "Country                     object\n",
      "Transaction_Type            object\n",
      "Total_Amount               float64\n",
      "Suspicious                    bool\n",
      "Price_Outlier                 bool\n",
      "Quantity_Outlier              bool\n",
      "dtype: object\n",
      "\n",
      "🔧 TYPES DE DONNÉES FINAUX :\n",
      "  • Invoice: object\n",
      "  • StockCode: object\n",
      "  • Description: object\n",
      "  • Quantity: int64\n",
      "  • InvoiceDate: datetime64[ns]\n",
      "  • Price: float64\n",
      "  • Customer ID: object\n",
      "  • Country: object\n",
      "  • Transaction_Type: object\n",
      "  • Total_Amount: float64\n",
      "  • Suspicious: bool\n",
      "  • Price_Outlier: bool\n",
      "  • Quantity_Outlier: bool\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📊 CHARGEMENT ET APERÇU DES DONNÉES NETTOYÉES\n",
    "# ============================================================================\n",
    "\n",
    "# Charger les données nettoyées\n",
    "df = pd.read_pickle('C:/Users/Moi/E-commerce_Marketing_Analytics/data/processed/cleaned_ecommerce_data.pkl')\n",
    "\n",
    "# Reconversion des types (nécessaire après CSV)\n",
    "#df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "#df['Customer ID'] = df['Customer ID'].astype(str)\n",
    "\n",
    "print(\"📊 APERÇU DES DONNÉES NETTOYÉES\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"📏 Dimensions: {df.shape}\")\n",
    "print(f\"📅 Période: {df['InvoiceDate'].min()} → {df['InvoiceDate'].max()}\")\n",
    "print(f\"🌍 Pays: {df['Country'].nunique()}\")\n",
    "print(f\"👥 Clients: {df['Customer ID'].nunique():,}\")\n",
    "print(f\"📦 Produits: {df['StockCode'].nunique():,}\")\n",
    "\n",
    "# Aperçu des types de données\n",
    "print(\"\\n🔧 TYPES DE DONNÉES :\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n🔧 TYPES DE DONNÉES FINAUX :\")\n",
    "for col in df.columns:\n",
    "    print(f\"  • {col}: {df[col].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4b86eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💰 ANALYSE FINANCIÈRE GLOBALE\n",
      "==============================\n",
      "💵 Chiffre d'affaires brut: $20,445,293.52\n",
      "↩️  Montant des retours: $1,516,344.05\n",
      "💎 Chiffre d'affaires net: $18,928,949.47\n",
      "📊 Taux de retour: 7.4%\n",
      "\n",
      "📈 MÉTRIQUES PAR COMMANDE :\n",
      "💰 Panier moyen: $20.01\n",
      "📊 Panier médian: $10.00\n",
      "🛒 Nombre total de commandes: 1,021,752\n",
      "\n",
      "📦 ANALYSE DES ARTICLES :\n",
      "📊 Articles vendus: 10,907,268\n",
      "🛒 Articles par commande: 10.7\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 💰 ANALYSE FINANCIÈRE GLOBALE\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_financial_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse complète des performances financières\n",
    "    \"\"\"\n",
    "    print(\"💰 ANALYSE FINANCIÈRE GLOBALE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Métriques globales\n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE']\n",
    "    returns_data = df[df['Transaction_Type'] == 'RETURN']\n",
    "    \n",
    "    total_revenue = sales_data['Total_Amount'].sum()\n",
    "    total_returns = abs(returns_data['Total_Amount'].sum())\n",
    "    net_revenue = total_revenue - total_returns\n",
    "    \n",
    "    print(f\"💵 Chiffre d'affaires brut: ${total_revenue:,.2f}\")\n",
    "    print(f\"↩️  Montant des retours: ${total_returns:,.2f}\")\n",
    "    print(f\"💎 Chiffre d'affaires net: ${net_revenue:,.2f}\")\n",
    "    print(f\"📊 Taux de retour: {(total_returns/total_revenue)*100:.1f}%\")\n",
    "    \n",
    "    # Métriques par transaction\n",
    "    avg_order_value = sales_data['Total_Amount'].mean()\n",
    "    median_order_value = sales_data['Total_Amount'].median()\n",
    "    \n",
    "    print(f\"\\n📈 MÉTRIQUES PAR COMMANDE :\")\n",
    "    print(f\"💰 Panier moyen: ${avg_order_value:.2f}\")\n",
    "    print(f\"📊 Panier médian: ${median_order_value:.2f}\")\n",
    "    print(f\"🛒 Nombre total de commandes: {len(sales_data):,}\")\n",
    "    \n",
    "    # Analyse des articles\n",
    "    total_items_sold = sales_data['Quantity'].sum()\n",
    "    avg_items_per_order = sales_data['Quantity'].mean()\n",
    "    \n",
    "    print(f\"\\n📦 ANALYSE DES ARTICLES :\")\n",
    "    print(f\"📊 Articles vendus: {total_items_sold:,}\")\n",
    "    print(f\"🛒 Articles par commande: {avg_items_per_order:.1f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_revenue': total_revenue,\n",
    "        'net_revenue': net_revenue,\n",
    "        'return_rate': (total_returns/total_revenue)*100,\n",
    "        'avg_order_value': avg_order_value,\n",
    "        'total_orders': len(sales_data)\n",
    "    }\n",
    "\n",
    "# Exécution de l'analyse financière\n",
    "financial_metrics = analyze_financial_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ddae57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 ANALYSE TEMPORELLE DES VENTES\n",
      "==============================\n",
      "📊 Période d'analyse: 2009-12-01 → 2011-12-09\n",
      "📈 Ventes quotidiennes moyennes: $33,849.82\n",
      "🕐 Heure de pointe: 12h\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📅 ANALYSE TEMPORELLE DES VENTES\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_temporal_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyse des patterns temporels des ventes\n",
    "    \"\"\"\n",
    "    print(\"\\n📅 ANALYSE TEMPORELLE DES VENTES\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # Extraire les composantes temporelles\n",
    "    sales_data['Date'] = sales_data['InvoiceDate'].dt.date\n",
    "    sales_data['Hour'] = sales_data['InvoiceDate'].dt.hour\n",
    "    sales_data['DayOfWeek'] = sales_data['InvoiceDate'].dt.day_name()\n",
    "    sales_data['Month'] = sales_data['InvoiceDate'].dt.month\n",
    "    sales_data['MonthName'] = sales_data['InvoiceDate'].dt.month_name()\n",
    "    \n",
    "    # Agrégations\n",
    "    daily_sales = sales_data.groupby('Date').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    hourly_sales = sales_data.groupby('Hour')['Total_Amount'].sum().reset_index()\n",
    "    \n",
    "    monthly_sales = sales_data.groupby('MonthName').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    dow_sales = sales_data.groupby('DayOfWeek')['Total_Amount'].sum().reset_index()\n",
    "    \n",
    "    print(f\"📊 Période d'analyse: {sales_data['Date'].min()} → {sales_data['Date'].max()}\")\n",
    "    print(f\"📈 Ventes quotidiennes moyennes: ${daily_sales['Total_Amount'].mean():,.2f}\")\n",
    "    \n",
    "    # 🔧 LIGNE CORRIGÉE - Remplacez cette ligne :\n",
    "    # print(f\"🕐 Heure de pointe: {hourly_sales.loc[hourly_sales['Total_Amount'].idxmax(), 'Hour']}h\")\n",
    "    \n",
    "    # 🔧 PAR CETTE LIGNE CORRIGÉE :\n",
    "    if not hourly_sales.empty and hourly_sales['Total_Amount'].sum() > 0:\n",
    "        print(f\"🕐 Heure de pointe: {hourly_sales.loc[hourly_sales['Total_Amount'].idxmax(), 'Hour']}h\")\n",
    "    else:\n",
    "        print(\"🕐 Heure de pointe: Aucune donnée horaire disponible\")\n",
    "    \n",
    "    return {\n",
    "        'daily_sales': daily_sales,\n",
    "        'hourly_sales': hourly_sales,\n",
    "        'monthly_sales': monthly_sales,\n",
    "        'dow_sales': dow_sales\n",
    "    }\n",
    "\n",
    "# Exécution de l'analyse temporelle\n",
    "temporal_data = analyze_temporal_patterns(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "517b2cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 DIAGNOSTIC DES DONNÉES\n",
      "========================================\n",
      "📊 Forme du DataFrame: (1040892, 13)\n",
      "📋 Colonnes: ['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'Price', 'Customer ID', 'Country', 'Transaction_Type', 'Total_Amount', 'Suspicious', 'Price_Outlier', 'Quantity_Outlier']\n",
      "🔢 Lignes totales: 1,040,892\n",
      "\n",
      "📈 TRANSACTION_TYPE:\n",
      "Transaction_Type\n",
      "SALE      1021752\n",
      "RETURN      19140\n",
      "Name: count, dtype: int64\n",
      "   → Nombre de SALES: 1021752\n",
      "\n",
      "📅 INVOICEDATE:\n",
      "   → Type: datetime64[ns]\n",
      "   → Valeurs nulles: 0\n",
      "   → Premières valeurs: [Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00')]\n",
      "\n",
      "💰 TOTAL_AMOUNT:\n",
      "   → Type: float64\n",
      "   → Valeurs nulles: 0\n",
      "   → Min: -168469.6\n",
      "   → Max: 168469.6\n",
      "   → Moyenne: 18.185315544744313\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🔍 DIAGNOSTIC DES DONNÉES\n",
    "# ============================================================================\n",
    "\n",
    "def diagnose_data_issues(df):\n",
    "    \"\"\"\n",
    "    Diagnostic pour identifier les problèmes dans les données\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 DIAGNOSTIC DES DONNÉES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Vérifications de base\n",
    "    print(f\"📊 Forme du DataFrame: {df.shape}\")\n",
    "    print(f\"📋 Colonnes: {list(df.columns)}\")\n",
    "    print(f\"🔢 Lignes totales: {len(df):,}\")\n",
    "    \n",
    "    # Vérification Transaction_Type\n",
    "    if 'Transaction_Type' in df.columns:\n",
    "        print(f\"\\n📈 TRANSACTION_TYPE:\")\n",
    "        print(df['Transaction_Type'].value_counts())\n",
    "        sales_count = (df['Transaction_Type'] == 'SALE').sum()\n",
    "        print(f\"   → Nombre de SALES: {sales_count}\")\n",
    "    else:\n",
    "        print(\"❌ Colonne 'Transaction_Type' manquante!\")\n",
    "    \n",
    "    # Vérification InvoiceDate\n",
    "    if 'InvoiceDate' in df.columns:\n",
    "        print(f\"\\n📅 INVOICEDATE:\")\n",
    "        print(f\"   → Type: {df['InvoiceDate'].dtype}\")\n",
    "        print(f\"   → Valeurs nulles: {df['InvoiceDate'].isnull().sum()}\")\n",
    "        print(f\"   → Premières valeurs: {df['InvoiceDate'].head().tolist()}\")\n",
    "    else:\n",
    "        print(\"❌ Colonne 'InvoiceDate' manquante!\")\n",
    "    \n",
    "    # Vérification Total_Amount\n",
    "    if 'Total_Amount' in df.columns:\n",
    "        print(f\"\\n💰 TOTAL_AMOUNT:\")\n",
    "        print(f\"   → Type: {df['Total_Amount'].dtype}\")\n",
    "        print(f\"   → Valeurs nulles: {df['Total_Amount'].isnull().sum()}\")\n",
    "        print(f\"   → Min: {df['Total_Amount'].min()}\")\n",
    "        print(f\"   → Max: {df['Total_Amount'].max()}\")\n",
    "        print(f\"   → Moyenne: {df['Total_Amount'].mean()}\")\n",
    "    else:\n",
    "        print(\"❌ Colonne 'Total_Amount' manquante!\")\n",
    "\n",
    "# Exécutez ce diagnostic\n",
    "diagnose_data_issues(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93697f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎨 CRÉATION DU DASHBOARD FINANCIER\n",
      "===================================\n",
      "✅ Dashboard financier créé\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🎨 VISUALISATIONS FINANCIÈRES\n",
    "# ============================================================================\n",
    "\n",
    "def create_financial_dashboard(df, temporal_data):\n",
    "    \"\"\"\n",
    "    Crée un dashboard financier interactif\n",
    "    \"\"\"\n",
    "    print(\"\\n🎨 CRÉATION DU DASHBOARD FINANCIER\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Configuration des subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Évolution des Ventes Quotidiennes', 'Ventes par Heure',\n",
    "                       'Ventes par Jour de la Semaine', 'Ventes par Mois'),\n",
    "        specs=[[{'secondary_y': True}, {'type': 'bar'}],\n",
    "               [{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Évolution quotidienne\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=temporal_data['daily_sales']['Date'], \n",
    "                  y=temporal_data['daily_sales']['Total_Amount'],\n",
    "                  name='Ventes Quotidiennes',\n",
    "                  line=dict(color='blue', width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Ventes par heure\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=temporal_data['hourly_sales']['Hour'],\n",
    "               y=temporal_data['hourly_sales']['Total_Amount'],\n",
    "               name='Ventes par Heure',\n",
    "               marker_color='lightblue'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Ventes par jour de la semaine\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    dow_ordered = temporal_data['dow_sales'].set_index('DayOfWeek').reindex(day_order).reset_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=dow_ordered['DayOfWeek'],\n",
    "               y=dow_ordered['Total_Amount'],\n",
    "               name='Ventes par Jour',\n",
    "               marker_color='lightgreen'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Ventes par mois\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=temporal_data['monthly_sales']['MonthName'],\n",
    "               y=temporal_data['monthly_sales']['Total_Amount'],\n",
    "               name='Ventes par Mois',\n",
    "               marker_color='lightcoral'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Mise à jour du layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"📊 DASHBOARD FINANCIER E-COMMERCE\",\n",
    "        title_x=0.5,\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    pio.renderers.default='browser'\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"✅ Dashboard financier créé\")\n",
    "\n",
    "# Création du dashboard\n",
    "create_financial_dashboard(df, temporal_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8978faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👥 ANALYSE DU COMPORTEMENT CLIENT\n",
      "===================================\n",
      "📊 Total clients: 248,138\n",
      "👤 Clients enregistrés: 5,881\n",
      "🎭 Clients invités: 242,257\n",
      "\n",
      "💰 RÉPARTITION PAR SEGMENT :\n",
      "  Bronze: 233,014 clients (93.9%)\n",
      "  Silver: 4,705 clients (1.9%)\n",
      "  Platinum: 2,845 clients (1.1%)\n",
      "  Gold: 1,435 clients (0.6%)\n",
      "\n",
      "🏆 TOP CLIENTS :\n",
      "  1. Client 18102: $580,987.04 (1040 commandes)\n",
      "  2. Client 14646: $528,602.52 (3854 commandes)\n",
      "  3. Client 14156: $313,437.62 (4038 commandes)\n",
      "  4. Client 14911: $291,420.81 (11079 commandes)\n",
      "  5. Client 17450: $244,784.25 (421 commandes)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 👥 ANALYSE DES CLIENTS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_customer_behavior(df):\n",
    "    \"\"\"\n",
    "    Analyse approfondie du comportement client\n",
    "    \"\"\"\n",
    "    print(\"\\n👥 ANALYSE DU COMPORTEMENT CLIENT\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # Métriques par client\n",
    "    customer_metrics = sales_data.groupby('Customer ID').agg({\n",
    "        'Total_Amount': ['sum', 'count', 'mean'],\n",
    "        'Invoice': 'nunique',\n",
    "        'InvoiceDate': ['min', 'max'],\n",
    "        'Quantity': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    customer_metrics.columns = ['Total_Spent', 'Total_Orders', 'Avg_Order_Value', \n",
    "                               'Unique_Invoices', 'First_Purchase', 'Last_Purchase', 'Items_Bought']\n",
    "    \n",
    "    # Période d'activité\n",
    "    customer_metrics['Days_Active'] = (customer_metrics['Last_Purchase'] - customer_metrics['First_Purchase']).dt.days\n",
    "    \n",
    "    # Segmentation simple\n",
    "    customer_metrics['Segment'] = pd.cut(customer_metrics['Total_Spent'], \n",
    "                                       bins=[0, 100, 500, 1000, float('inf')],\n",
    "                                       labels=['Bronze', 'Silver', 'Gold', 'Platinum'])\n",
    "    \n",
    "    # Distinguer les clients invités\n",
    "    customer_metrics['Customer_Type'] = customer_metrics.index.to_series().apply(\n",
    "        lambda x: 'Guest' if x.startswith('GUEST_') else 'Registered'\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Total clients: {len(customer_metrics):,}\")\n",
    "    print(f\"👤 Clients enregistrés: {(customer_metrics['Customer_Type'] == 'Registered').sum():,}\")\n",
    "    print(f\"🎭 Clients invités: {(customer_metrics['Customer_Type'] == 'Guest').sum():,}\")\n",
    "    \n",
    "    print(f\"\\n💰 RÉPARTITION PAR SEGMENT :\")\n",
    "    segment_dist = customer_metrics['Segment'].value_counts()\n",
    "    for segment, count in segment_dist.items():\n",
    "        pct = (count / len(customer_metrics)) * 100\n",
    "        print(f\"  {segment}: {count:,} clients ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🏆 TOP CLIENTS :\")\n",
    "    top_customers = customer_metrics.nlargest(5, 'Total_Spent')\n",
    "    for idx, (customer_id, data) in enumerate(top_customers.iterrows(), 1):\n",
    "        print(f\"  {idx}. Client {customer_id}: ${data['Total_Spent']:,.2f} ({data['Total_Orders']} commandes)\")\n",
    "    \n",
    "    return customer_metrics\n",
    "\n",
    "# Exécution de l'analyse client\n",
    "customer_data = analyze_customer_behavior(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bb602e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 ANALYSE DES PERFORMANCES PRODUITS\n",
      "========================================\n",
      "📊 Produits uniques: 6,554\n",
      "💰 Revenus totaux: $20,445,293.52\n",
      "\n",
      "🏆 TOP 10 PRODUITS (Revenus) :\n",
      "  M: $340,153.38 | Manual\n",
      "  22423: $335,733.20 | REGENCY CAKESTAND 3 TIER\n",
      "  DOT: $322,657.48 | DOTCOM POSTAGE\n",
      "  85123A: $257,906.71 | WHITE HANGING HEART T-LIGHT HOLDER\n",
      "  23843: $168,469.60 | PAPER CRAFT , LITTLE BIRDIE\n",
      "  47566: $148,590.20 | PARTY BUNTING\n",
      "  85099B: $146,151.28 | JUMBO BAG RED RETROSPOT\n",
      "  84879: $129,465.61 | ASSORTED COLOUR BIRD ORNAMENT\n",
      "  POST: $125,682.42 | POSTAGE\n",
      "  22086: $120,145.39 | PAPER CHAIN KIT 50'S CHRISTMAS \n",
      "\n",
      "🔥 TOP 10 PRODUITS (Quantité) :\n",
      "  84077: 106,265 unités | WORLD WAR 2 GLIDERS ASSTD DESIGNS\n",
      "  85123A: 94,208 unités | WHITE HANGING HEART T-LIGHT HOLDER\n",
      "  23843: 80,995 unités | PAPER CRAFT , LITTLE BIRDIE\n",
      "  84879: 80,138 unités | ASSORTED COLOUR BIRD ORNAMENT\n",
      "  23166: 78,033 unités | MEDIUM CERAMIC TOP STORAGE JAR\n",
      "  85099B: 77,331 unités | JUMBO BAG RED RETROSPOT\n",
      "  17003: 70,393 unités | BROCADE RING PURSE \n",
      "  21977: 56,116 unités | PACK OF 60 PINK PAISLEY CAKE CASES\n",
      "  84991: 54,049 unités | 60 TEATIME FAIRY CAKE CASES\n",
      "  22197: 48,969 unités | SMALL POPCORN HOLDER\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📦 ANALYSE DES PRODUITS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_product_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse des performances produits\n",
    "    \"\"\"\n",
    "    print(\"\\n📦 ANALYSE DES PERFORMANCES PRODUITS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # Métriques par produit\n",
    "    product_metrics = sales_data.groupby(['StockCode', 'Description']).agg({\n",
    "        'Quantity': 'sum',\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    product_metrics.columns = ['StockCode', 'Description', 'Total_Quantity', \n",
    "                              'Total_Revenue', 'Unique_Orders', 'Unique_Customers']\n",
    "    \n",
    "    # Calcul du prix moyen\n",
    "    product_metrics['Avg_Price'] = product_metrics['Total_Revenue'] / product_metrics['Total_Quantity']\n",
    "    \n",
    "    # Tri par revenus\n",
    "    product_metrics = product_metrics.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    print(f\"📊 Produits uniques: {len(product_metrics):,}\")\n",
    "    print(f\"💰 Revenus totaux: ${product_metrics['Total_Revenue'].sum():,.2f}\")\n",
    "    \n",
    "    print(f\"\\n🏆 TOP 10 PRODUITS (Revenus) :\")\n",
    "    top_products = product_metrics.head(10)\n",
    "    for idx, row in top_products.iterrows():\n",
    "        desc = row['Description'][:50] + '...' if pd.notna(row['Description']) and len(str(row['Description'])) > 50 else row['Description']\n",
    "        print(f\"  {row['StockCode']}: ${row['Total_Revenue']:,.2f} | {desc}\")\n",
    "    \n",
    "    print(f\"\\n🔥 TOP 10 PRODUITS (Quantité) :\")\n",
    "    top_qty = product_metrics.nlargest(10, 'Total_Quantity')\n",
    "    for idx, row in top_qty.iterrows():\n",
    "        desc = row['Description'][:50] + '...' if pd.notna(row['Description']) and len(str(row['Description'])) > 50 else row['Description']\n",
    "        print(f\"  {row['StockCode']}: {row['Total_Quantity']:,} unités | {desc}\")\n",
    "    \n",
    "    return product_metrics\n",
    "\n",
    "# Exécution de l'analyse produit\n",
    "product_data = analyze_product_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌍 ANALYSE GÉOGRAPHIQUE\n",
      "=========================\n",
      "🌎 Pays actifs: 43\n",
      "🏆 Top pays: United Kingdom\n",
      "\n",
      "💰 TOP 10 PAYS (Revenus) :\n",
      "  United Kingdom: $17,378,389.04 (85.0%)\n",
      "  EIRE: $659,371.21 (3.2%)\n",
      "  Netherlands: $554,038.09 (2.7%)\n",
      "  Germany: $425,019.71 (2.1%)\n",
      "  France: $350,456.09 (1.7%)\n",
      "  Australia: $169,283.46 (0.8%)\n",
      "  Spain: $108,332.49 (0.5%)\n",
      "  Switzerland: $100,707.89 (0.5%)\n",
      "  Sweden: $91,869.82 (0.4%)\n",
      "  Denmark: $68,580.69 (0.3%)\n",
      "\n",
      "👥 TOP 10 PAYS (Clients) :\n",
      "  United Kingdom: 244,737 clients\n",
      "  EIRE: 1,614 clients\n",
      "  Hong Kong: 358 clients\n",
      "  Unspecified: 237 clients\n",
      "  France: 223 clients\n",
      "  Switzerland: 147 clients\n",
      "  Portugal: 140 clients\n",
      "  Germany: 107 clients\n",
      "  United Arab Emirates: 88 clients\n",
      "  Bahrain: 67 clients\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🌍 ANALYSE GÉOGRAPHIQUE\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_geographic_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse des performances par pays\n",
    "    \"\"\"\n",
    "    print(\"\\n🌍 ANALYSE GÉOGRAPHIQUE\")\n",
    "    \n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # Métriques par pays\n",
    "    country_metrics = sales_data.groupby('Country').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    country_metrics.columns = ['Country', 'Total_Revenue', 'Total_Orders', 'Unique_Customers', 'Items_Sold']\n",
    "    \n",
    "    # Calculs additionnels\n",
    "    country_metrics['Avg_Order_Value'] = country_metrics['Total_Revenue'] / country_metrics['Total_Orders']\n",
    "    country_metrics['Revenue_per_Customer'] = country_metrics['Total_Revenue'] / country_metrics['Unique_Customers']\n",
    "    \n",
    "    # Tri par revenus\n",
    "    country_metrics = country_metrics.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    print(f\"🌎 Pays actifs: {len(country_metrics)}\")\n",
    "    print(f\"🏆 Top pays: {country_metrics.iloc[0]['Country']}\")\n",
    "    \n",
    "    print(f\"\\n💰 TOP 10 PAYS (Revenus) :\")\n",
    "    top_countries = country_metrics.head(10)\n",
    "    for idx, row in top_countries.iterrows():\n",
    "        pct = (row['Total_Revenue'] / country_metrics['Total_Revenue'].sum()) * 100\n",
    "        print(f\"  {row['Country']}: ${row['Total_Revenue']:,.2f} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n👥 TOP 10 PAYS (Clients) :\")\n",
    "    top_customers_countries = country_metrics.nlargest(10, 'Unique_Customers')\n",
    "    for idx, row in top_customers_countries.iterrows():\n",
    "        print(f\"  {row['Country']}: {row['Unique_Customers']:,} clients\")\n",
    "    \n",
    "    return country_metrics\n",
    "\n",
    "# Exécution de l'analyse géographique\n",
    "geographic_data = analyze_geographic_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a522e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 CRÉATION DU DASHBOARD BUSINESS\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📈 VISUALISATIONS INTERACTIVES - PERFORMANCES BUSINESS\n",
    "# ============================================================================\n",
    "\n",
    "def create_business_dashboard(df):\n",
    "    \"\"\"\n",
    "    Dashboard interactif des performances business\n",
    "    \"\"\"\n",
    "    print(\"📊 CRÉATION DU DASHBOARD BUSINESS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Préparation des données pour les graphiques\n",
    "    monthly_sales = df.groupby(df['InvoiceDate'].dt.to_period('M')).agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    monthly_sales['InvoiceDate'] = monthly_sales['InvoiceDate'].dt.to_timestamp()\n",
    "    \n",
    "    # 1. GRAPHIQUE 1 : Évolution mensuelle des ventes\n",
    "    fig1 = go.Figure()\n",
    "    \n",
    "    fig1.add_trace(go.Scatter(\n",
    "        x=monthly_sales['InvoiceDate'],\n",
    "        y=monthly_sales['Total_Amount'],\n",
    "        mode='lines+markers',\n",
    "        name='Revenus Mensuels',\n",
    "        line=dict(color='#1f77b4', width=3),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='📈 ÉVOLUTION DES REVENUS MENSUELS',\n",
    "        xaxis_title='Mois',\n",
    "        yaxis_title='Revenus ( $ )',\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "    # 2. GRAPHIQUE 2 : Top 10 pays par revenus\n",
    "    top_countries = df.groupby('Country')['Total_Amount'].sum().nlargest(10).reset_index()\n",
    "    \n",
    "    fig2 = px.bar(\n",
    "        top_countries,\n",
    "        x='Total_Amount',\n",
    "        y='Country',\n",
    "        orientation='h',\n",
    "        title='🌍 TOP 10 PAYS PAR REVENUS',\n",
    "        labels={'Total_Amount': 'Revenus ( $ )', 'Country': 'Pays'}\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        yaxis={'categoryorder': 'total ascending'}\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # 3. GRAPHIQUE 3 : Heatmap des ventes par jour/heure\n",
    "    sales_heatmap = df.pivot_table(\n",
    "        values='Total_Amount',\n",
    "        index=df['InvoiceDate'].dt.day_name(),\n",
    "        columns=df['InvoiceDate'].dt.hour,\n",
    "        aggfunc='sum'\n",
    "    )\n",
    "    \n",
    "    # Réorganiser les jours de la semaine\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    sales_heatmap = sales_heatmap.reindex(day_order)\n",
    "    \n",
    "    fig3 = px.imshow(\n",
    "        sales_heatmap,\n",
    "        title='🕐 HEATMAP VENTES PAR JOUR/HEURE',\n",
    "        labels=dict(x=\"Heure\", y=\"Jour\", color=\"Revenus ($)\"),\n",
    "        aspect=\"auto\"\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    return fig1, fig2, fig3\n",
    "\n",
    "# Création du dashboard\n",
    "dashboard_figs = create_business_dashboard(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bc63790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👥 ANALYSE COMPORTEMENT CLIENT\n",
      "===================================\n",
      "💰 SEGMENTATION PAR REVENUS :\n",
      "  🏆 Bronze: 233,022 clients | $2,084,122.37 total | $8.94 moy/client | $8.91 moy/commande\n",
      "  🏆 Silver: 4,710 clients | $1,078,279.34 total | $228.93 moy/client | $128.32 moy/commande\n",
      "  🏆 Gold: 1,437 clients | $1,029,402.00 total | $716.35 moy/client | $176.66 moy/commande\n",
      "  🏆 Platinum: 2,796 clients | $15,420,363.29 total | $5515.15 moy/client | $166.87 moy/commande\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🎯 ANALYSE DES PATTERNS DE COMPORTEMENT CLIENT\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_customer_behavior(df):\n",
    "    \"\"\"\n",
    "    Analyse approfondie du comportement client\n",
    "    \"\"\"\n",
    "    print(\"👥 ANALYSE COMPORTEMENT CLIENT\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Métriques par client\n",
    "    customer_metrics = df.groupby('Customer ID').agg({\n",
    "        'Total_Amount': ['sum', 'mean', 'count'],\n",
    "        'Quantity': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'InvoiceDate': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Aplatir les colonnes\n",
    "    customer_metrics.columns = ['Customer_ID', 'Total_Revenue', 'Avg_Order_Value', \n",
    "                               'Total_Orders', 'Total_Items', 'Unique_Invoices', \n",
    "                               'First_Purchase', 'Last_Purchase']\n",
    "    \n",
    "    # Calculs additionnels\n",
    "    customer_metrics['Customer_Lifetime_Days'] = (\n",
    "        customer_metrics['Last_Purchase'] - customer_metrics['First_Purchase']\n",
    "    ).dt.days\n",
    "    \n",
    "    customer_metrics['Recency_Days'] = (\n",
    "        df['InvoiceDate'].max() - customer_metrics['Last_Purchase']\n",
    "    ).dt.days\n",
    "    \n",
    "    # Segmentation simple\n",
    "    customer_metrics['Revenue_Segment'] = pd.cut(\n",
    "        customer_metrics['Total_Revenue'],\n",
    "        bins=[0, 100, 500, 1000, float('inf')],\n",
    "        labels=['Bronze', 'Silver', 'Gold', 'Platinum']\n",
    "    )\n",
    "    \n",
    "    # Statistiques par segment\n",
    "    print(\"💰 SEGMENTATION PAR REVENUS :\")\n",
    "    segment_stats = customer_metrics.groupby('Revenue_Segment').agg({\n",
    "        'Total_Revenue': ['count', 'sum', 'mean'],\n",
    "        'Avg_Order_Value': 'mean',\n",
    "        'Total_Orders': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    for segment in ['Bronze', 'Silver', 'Gold', 'Platinum']:\n",
    "        if segment in segment_stats.index:\n",
    "            count = segment_stats.loc[segment, ('Total_Revenue', 'count')]\n",
    "            revenue = segment_stats.loc[segment, ('Total_Revenue', 'sum')]\n",
    "            avg_revenue = segment_stats.loc[segment, ('Total_Revenue', 'mean')]\n",
    "            avg_order = segment_stats.loc[segment, ('Avg_Order_Value', 'mean')]\n",
    "            \n",
    "            print(f\"  🏆 {segment}: {count:,} clients | \"\n",
    "                  f\"${revenue:,.2f} total | \"\n",
    "                  f\"${avg_revenue:.2f} moy/client | \"\n",
    "                  f\"${avg_order:.2f} moy/commande\")\n",
    "    \n",
    "    # Graphique de distribution\n",
    "    fig4 = px.histogram(\n",
    "        customer_metrics,\n",
    "        x='Total_Revenue',\n",
    "        nbins=50,\n",
    "        title='📊 DISTRIBUTION DES REVENUS PAR CLIENT',\n",
    "        labels={'Total_Revenue': 'Revenus par Client ($)', 'count': 'Nombre de Clients'}\n",
    "    )\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    return customer_metrics, fig4\n",
    "\n",
    "# Analyse comportement client\n",
    "customer_data, customer_fig = analyze_customer_behavior(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f18d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 ANALYSE PERFORMANCE PRODUITS\n",
      "===================================\n",
      "🏆 TOP 10 PRODUITS (Revenus) :\n",
      "  📦 DOT: $322,647.47 | 1429 clients | $225.79/client\n",
      "      📝 DOTCOM POSTAGE...\n",
      "  📦 22423: $319,187.90 | 1951 clients | $163.60/client\n",
      "      📝 REGENCY CAKESTAND 3 TIER...\n",
      "  📦 85123A: $248,519.61 | 1996 clients | $124.51/client\n",
      "      📝 WHITE HANGING HEART T-LIGHT HOLDER...\n",
      "  📦 47566: $147,351.65 | 1515 clients | $97.26/client\n",
      "      📝 PARTY BUNTING...\n",
      "  📦 85099B: $144,023.86 | 1529 clients | $94.19/client\n",
      "      📝 JUMBO BAG RED RETROSPOT...\n",
      "  📦 84879: $128,691.54 | 1176 clients | $109.43/client\n",
      "      📝 ASSORTED COLOUR BIRD ORNAMENT...\n",
      "  📦 22086: $118,683.69 | 1243 clients | $95.48/client\n",
      "      📝 PAPER CHAIN KIT 50'S CHRISTMAS ...\n",
      "  📦 POST: $110,430.41 | 592 clients | $186.54/client\n",
      "      📝 POSTAGE...\n",
      "  📦 79321: $81,078.32 | 537 clients | $150.98/client\n",
      "      📝 CHILLI LIGHTS...\n",
      "  📦 84347: $72,196.52 | 550 clients | $131.27/client\n",
      "      📝 ROTATING SILVER ANGELS T-LIGHT HLDR...\n",
      "\n",
      "👥 TOP 10 PRODUITS (Popularité) :\n",
      "  📦 85123A: 1996 clients | $248,519.61 revenus\n",
      "      📝 WHITE HANGING HEART T-LIGHT HOLDER...\n",
      "  📦 22423: 1951 clients | $319,187.90 revenus\n",
      "      📝 REGENCY CAKESTAND 3 TIER...\n",
      "  📦 85099B: 1529 clients | $144,023.86 revenus\n",
      "      📝 JUMBO BAG RED RETROSPOT...\n",
      "  📦 47566: 1515 clients | $147,351.65 revenus\n",
      "      📝 PARTY BUNTING...\n",
      "  📦 DOT: 1429 clients | $322,647.47 revenus\n",
      "      📝 DOTCOM POSTAGE...\n",
      "  📦 22138: 1326 clients | $41,829.06 revenus\n",
      "      📝 BAKING SET 9 PIECE RETROSPOT ...\n",
      "  📦 22457: 1300 clients | $47,427.35 revenus\n",
      "      📝 NATURAL SLATE HEART CHALKBOARD ...\n",
      "  📦 22469: 1286 clients | $48,998.70 revenus\n",
      "      📝 HEART OF WICKER SMALL...\n",
      "  📦 22086: 1243 clients | $118,683.69 revenus\n",
      "      📝 PAPER CHAIN KIT 50'S CHRISTMAS ...\n",
      "  📦 21790: 1213 clients | $23,431.48 revenus\n",
      "      📝 VINTAGE SNAP CARDS...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🏆 ANALYSE DES PRODUITS PERFORMANTS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_product_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse détaillée des performances produits\n",
    "    \"\"\"\n",
    "    print(\"📦 ANALYSE PERFORMANCE PRODUITS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Métriques par produit\n",
    "    product_metrics = df.groupby(['StockCode', 'Description']).agg({\n",
    "        'Total_Amount': ['sum', 'mean'],\n",
    "        'Quantity': ['sum', 'mean'],\n",
    "        'Customer ID': 'nunique',\n",
    "        'Invoice': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Aplatir les colonnes\n",
    "    product_metrics.columns = ['StockCode', 'Description', 'Total_Revenue', \n",
    "                              'Avg_Revenue_per_Sale', 'Total_Quantity', \n",
    "                              'Avg_Quantity_per_Sale', 'Unique_Customers', \n",
    "                              'Unique_Orders']\n",
    "    \n",
    "    # Calculs additionnels\n",
    "    product_metrics['Revenue_per_Customer'] = (\n",
    "        product_metrics['Total_Revenue'] / product_metrics['Unique_Customers']\n",
    "    )\n",
    "    \n",
    "    product_metrics['Repeat_Purchase_Rate'] = (\n",
    "        product_metrics['Unique_Orders'] / product_metrics['Unique_Customers']\n",
    "    )\n",
    "    \n",
    "    # Tri par revenus\n",
    "    product_metrics = product_metrics.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    print(\"🏆 TOP 10 PRODUITS (Revenus) :\")\n",
    "    top_products = product_metrics.head(10)\n",
    "    for idx, row in top_products.iterrows():\n",
    "        print(f\"  📦 {row['StockCode']}: ${row['Total_Revenue']:,.2f} | \"\n",
    "              f\"{row['Unique_Customers']} clients | \"\n",
    "              f\"${row['Revenue_per_Customer']:.2f}/client\")\n",
    "        print(f\"      📝 {row['Description'][:50]}...\")\n",
    "    \n",
    "    print(f\"\\n👥 TOP 10 PRODUITS (Popularité) :\")\n",
    "    popular_products = product_metrics.nlargest(10, 'Unique_Customers')\n",
    "    for idx, row in popular_products.iterrows():\n",
    "        print(f\"  📦 {row['StockCode']}: {row['Unique_Customers']} clients | \"\n",
    "              f\"${row['Total_Revenue']:,.2f} revenus\")\n",
    "        print(f\"      📝 {row['Description'][:50]}...\")\n",
    "    \n",
    "    # Graphique de corrélation\n",
    "    fig5 = px.scatter(\n",
    "        product_metrics.head(100),  # Top 100 pour lisibilité\n",
    "        x='Unique_Customers',\n",
    "        y='Total_Revenue',\n",
    "        size='Total_Quantity',\n",
    "        hover_data=['StockCode', 'Description'],\n",
    "        title='📊 CORRÉLATION POPULARITÉ vs REVENUS (Top 100)',\n",
    "        labels={'Unique_Customers': 'Nombre de Clients', 'Total_Revenue': 'Revenus ($)'}\n",
    "    )\n",
    "    \n",
    "    fig5.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig5.show()\n",
    "    \n",
    "    return product_metrics, fig5\n",
    "\n",
    "# Analyse performance produits\n",
    "product_data, product_fig = analyze_product_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be5df858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 ANALYSE SAISONNALITÉ COMPLÈTE\n",
      "========================================\n",
      "📊 RÉSUMÉ MENSUEL :\n",
      "   Year  Month MonthName  Total_Amount_sum  Total_Amount_mean  \\\n",
      "0  2009     12  December         796700.16              17.81   \n",
      "1  2010      1   January         622516.50              19.93   \n",
      "2  2010      2  February         531288.27              18.28   \n",
      "3  2010      3     March         763271.59              18.62   \n",
      "4  2010      4     April         587953.24              17.47   \n",
      "\n",
      "   Total_Amount_count  Invoice_nunique  Customer ID_nunique  Quantity_sum  \\\n",
      "0               44744             2330                14513        418597   \n",
      "1               31238             1633                 9902        374524   \n",
      "2               29060             1969                 6289        367503   \n",
      "3               40989             2367                 9508        488021   \n",
      "4               33653             1892                 7222        350533   \n",
      "\n",
      "   Revenue_per_Order  Revenue_per_Customer  \n",
      "0             341.93                 54.90  \n",
      "1             381.21                 62.87  \n",
      "2             269.83                 84.48  \n",
      "3             322.46                 80.28  \n",
      "4             310.76                 81.41  \n",
      "\n",
      "📈 ANALYSE TRIMESTRIELLE :\n",
      "   Year  Quarter  Total_Amount  Invoice  Customer ID Quarter_Label  \\\n",
      "0  2009        4     796700.16     2330        14513       Q4 2009   \n",
      "1  2010        1    1917076.36     5969        24861       Q1 2010   \n",
      "2  2010        2    1878336.16     6526        22088       Q2 2010   \n",
      "3  2010        3    2079252.31     6269        20805       Q3 2010   \n",
      "4  2010        4    3278090.79     8659        51142       Q4 2010   \n",
      "5  2011        1    1737587.03     4852        31317       Q1 2011   \n",
      "6  2011        2    1904448.52     5918        25902       Q2 2011   \n",
      "7  2011        3    2379168.03     5991        31238       Q3 2011   \n",
      "8  2011        4    2958290.10     7114        39625       Q4 2011   \n",
      "\n",
      "   Revenue_Growth  \n",
      "0             NaN  \n",
      "1          140.63  \n",
      "2           -2.02  \n",
      "3           10.70  \n",
      "4           57.66  \n",
      "5          -46.99  \n",
      "6            9.60  \n",
      "7           24.93  \n",
      "8           24.34  \n",
      "\n",
      "📅 PATTERN HEBDOMADAIRE :\n",
      "   DayOfWeek    DayName  Total_Revenue  Avg_Revenue  Total_Orders  \\\n",
      "0          0     Monday     3296905.28        17.76          8595   \n",
      "1          1    Tuesday     3716240.02        19.17         10299   \n",
      "2          2  Wednesday     3297215.33        18.40          9597   \n",
      "3          3   Thursday     3902396.78        19.77         11335   \n",
      "4          4     Friday     2927237.07        19.33          8505   \n",
      "5          5   Saturday        9803.05        24.39            32   \n",
      "6          6     Sunday     1779151.93        13.37          5265   \n",
      "\n",
      "   Unique_Customers  \n",
      "0             60606  \n",
      "1             58845  \n",
      "2             48155  \n",
      "3             40115  \n",
      "4             48104  \n",
      "5                28  \n",
      "6              3993  \n",
      "\n",
      "🕐 PATTERN HORAIRE :\n",
      "Top 5 heures de pointe :\n",
      "   Hour  Total_Revenue  Total_Orders\n",
      "6    12     2669525.49          8098\n",
      "4    10     2416921.68          6030\n",
      "7    13     2338014.41          7163\n",
      "5    11     2318310.15          6628\n",
      "8    14     2218191.00          6519\n",
      "\n",
      "🎯 INSIGHTS SAISONNIERS CLÉS :\n",
      "==============================\n",
      "📈 MEILLEUR MOIS : November 2011\n",
      "   💰 Revenus: $1,456,163.58\n",
      "   📦 Commandes: 3462\n",
      "   👥 Clients: 20824\n",
      "\n",
      "📉 MOIS LE PLUS FAIBLE : December 2011\n",
      "   💰 Revenus: $432,719.06\n",
      "   📦 Commandes: 1015\n",
      "\n",
      "📈 MEILLEUR JOUR : Thursday\n",
      "   💰 Revenus moyens: $3,902,396.78\n",
      "   📦 Commandes: 11335\n",
      "\n",
      "📉 JOUR LE PLUS FAIBLE : Saturday\n",
      "   💰 Revenus moyens: $9,803.05\n",
      "\n",
      "🕐 HEURE DE POINTE : 12.0h\n",
      "   💰 Revenus: $2,669,525.49\n",
      "   📦 Commandes: 8098.0\n",
      "\n",
      "🕐 HEURE CREUSE : 6.0h\n",
      "   💰 Revenus: $-497.35\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📅 ANALYSE SAISONNALITÉ DÉTAILLÉE - NOTEBOOK 3\n",
    "# ============================================================================\n",
    "\n",
    "def seasonal_analysis_complete(df):\n",
    "    \"\"\"\n",
    "    Analyse complète des patterns saisonniers\n",
    "    \"\"\"\n",
    "    print(\"📅 ANALYSE SAISONNALITÉ COMPLÈTE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Préparation des données temporelles\n",
    "    df['Year'] = df['InvoiceDate'].dt.year\n",
    "    df['Month'] = df['InvoiceDate'].dt.month\n",
    "    df['MonthName'] = df['InvoiceDate'].dt.month_name()\n",
    "    df['Quarter'] = df['InvoiceDate'].dt.quarter\n",
    "    df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
    "    df['DayName'] = df['InvoiceDate'].dt.day_name()\n",
    "    df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "    df['Week'] = df['InvoiceDate'].dt.isocalendar().week\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 1. ANALYSE MENSUELLE DÉTAILLÉE\n",
    "    # =======================================================================\n",
    "    \n",
    "    monthly_summary = df.groupby(['Year', 'Month', 'MonthName']).agg({\n",
    "        'Total_Amount': ['sum', 'mean', 'count'],\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique',\n",
    "        'Quantity': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    monthly_summary.columns = ['_'.join(col).strip() for col in monthly_summary.columns]\n",
    "    monthly_summary = monthly_summary.reset_index()\n",
    "    \n",
    "    # Calcul des métriques business\n",
    "    monthly_summary['Revenue_per_Order'] = (\n",
    "        monthly_summary['Total_Amount_sum'] / monthly_summary['Invoice_nunique']\n",
    "    )\n",
    "    monthly_summary['Revenue_per_Customer'] = (\n",
    "        monthly_summary['Total_Amount_sum'] / monthly_summary['Customer ID_nunique']\n",
    "    )\n",
    "    \n",
    "    print(\"📊 RÉSUMÉ MENSUEL :\")\n",
    "    print(monthly_summary.head())\n",
    "    \n",
    "    # Graphique 1: Évolution mensuelle multi-métriques\n",
    "    fig1 = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Revenus Mensuels', 'Nombre de Commandes', \n",
    "                       'Clients Uniques', 'Panier Moyen'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # Données pour graphique\n",
    "    month_data = monthly_summary.groupby('Month').agg({\n",
    "        'Total_Amount_sum': 'mean',\n",
    "        'Invoice_nunique': 'mean',\n",
    "        'Customer ID_nunique': 'mean',\n",
    "        'Revenue_per_Order': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Ajout des traces\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Total_Amount_sum'],\n",
    "                  mode='lines+markers', name='Revenus', line=dict(color='#1f77b4')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Invoice_nunique'],\n",
    "                  mode='lines+markers', name='Commandes', line=dict(color='#ff7f0e')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Customer ID_nunique'],\n",
    "                  mode='lines+markers', name='Clients', line=dict(color='#2ca02c')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Revenue_per_Order'],\n",
    "                  mode='lines+markers', name='Panier Moyen', line=dict(color='#d62728')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='📅 ANALYSE SAISONNALITÉ MENSUELLE',\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 2. ANALYSE TRIMESTRIELLE\n",
    "    # =======================================================================\n",
    "    \n",
    "    quarterly_data = df.groupby(['Year', 'Quarter']).agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calcul croissance trimestrielle\n",
    "    quarterly_data['Quarter_Label'] = 'Q' + quarterly_data['Quarter'].astype(str) + ' ' + quarterly_data['Year'].astype(str)\n",
    "    quarterly_data['Revenue_Growth'] = quarterly_data['Total_Amount'].pct_change() * 100\n",
    "    \n",
    "    print(f\"\\n📈 ANALYSE TRIMESTRIELLE :\")\n",
    "    print(quarterly_data)\n",
    "    \n",
    "    # Graphique 2: Performance trimestrielle\n",
    "    fig2 = px.bar(\n",
    "        quarterly_data,\n",
    "        x='Quarter_Label',\n",
    "        y='Total_Amount',\n",
    "        title='📊 REVENUS PAR TRIMESTRE',\n",
    "        labels={'Total_Amount': 'Revenus ( $ )', 'Quarter_Label': 'Trimestre'}\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 3. ANALYSE HEBDOMADAIRE\n",
    "    # =======================================================================\n",
    "    \n",
    "    weekly_pattern = df.groupby(['DayOfWeek', 'DayName']).agg({\n",
    "        'Total_Amount': ['sum', 'mean'],\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    weekly_pattern.columns = ['DayOfWeek', 'DayName', 'Total_Revenue', 'Avg_Revenue',\n",
    "                             'Total_Orders', 'Unique_Customers']\n",
    "    \n",
    "    # Réorganiser les jours\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekly_pattern['DayName'] = pd.Categorical(weekly_pattern['DayName'], categories=day_order, ordered=True)\n",
    "    weekly_pattern = weekly_pattern.sort_values('DayName')\n",
    "    \n",
    "    print(f\"\\n📅 PATTERN HEBDOMADAIRE :\")\n",
    "    print(weekly_pattern)\n",
    "    \n",
    "    # Graphique 3: Pattern hebdomadaire\n",
    "    fig3 = px.bar(\n",
    "        weekly_pattern,\n",
    "        x='DayName',\n",
    "        y='Total_Revenue',\n",
    "        title='📊 PATTERN HEBDOMADAIRE DES VENTES',\n",
    "        labels={'Total_Revenue': 'Revenus ( $ )', 'DayName': 'Jour de la Semaine'}\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 4. ANALYSE HORAIRE\n",
    "    # =======================================================================\n",
    "    \n",
    "    hourly_pattern = df.groupby('Hour').agg({\n",
    "        'Total_Amount': ['sum', 'mean'],\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    hourly_pattern.columns = ['Hour', 'Total_Revenue', 'Avg_Revenue', 'Total_Orders', 'Unique_Customers']\n",
    "    \n",
    "    print(f\"\\n🕐 PATTERN HORAIRE :\")\n",
    "    peak_hours = hourly_pattern.nlargest(5, 'Total_Revenue')\n",
    "    print(\"Top 5 heures de pointe :\")\n",
    "    print(peak_hours[['Hour', 'Total_Revenue', 'Total_Orders']])\n",
    "    \n",
    "    # Graphique 4: Pattern horaire\n",
    "    fig4 = px.line(\n",
    "        hourly_pattern,\n",
    "        x='Hour',\n",
    "        y='Total_Revenue',\n",
    "        title='📊 PATTERN HORAIRE DES VENTES',\n",
    "        labels={'Total_Revenue': 'Revenus ($)', 'Hour': 'Heure'}\n",
    "    )\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 5. INSIGHTS SAISONNIERS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n🎯 INSIGHTS SAISONNIERS CLÉS :\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Meilleur mois\n",
    "    best_month = monthly_summary.loc[monthly_summary['Total_Amount_sum'].idxmax()]\n",
    "    worst_month = monthly_summary.loc[monthly_summary['Total_Amount_sum'].idxmin()]\n",
    "    \n",
    "    print(f\"📈 MEILLEUR MOIS : {best_month['MonthName']} {best_month['Year']}\")\n",
    "    print(f\"   💰 Revenus: ${best_month['Total_Amount_sum']:,.2f}\")\n",
    "    print(f\"   📦 Commandes: {best_month['Invoice_nunique']}\")\n",
    "    print(f\"   👥 Clients: {best_month['Customer ID_nunique']}\")\n",
    "    \n",
    "    print(f\"\\n📉 MOIS LE PLUS FAIBLE : {worst_month['MonthName']} {worst_month['Year']}\")\n",
    "    print(f\"   💰 Revenus: ${worst_month['Total_Amount_sum']:,.2f}\")\n",
    "    print(f\"   📦 Commandes: {worst_month['Invoice_nunique']}\")\n",
    "    \n",
    "    # Meilleur jour\n",
    "    best_day = weekly_pattern.loc[weekly_pattern['Total_Revenue'].idxmax()]\n",
    "    worst_day = weekly_pattern.loc[weekly_pattern['Total_Revenue'].idxmin()]\n",
    "    \n",
    "    print(f\"\\n📈 MEILLEUR JOUR : {best_day['DayName']}\")\n",
    "    print(f\"   💰 Revenus moyens: ${best_day['Total_Revenue']:,.2f}\")\n",
    "    print(f\"   📦 Commandes: {best_day['Total_Orders']}\")\n",
    "    \n",
    "    print(f\"\\n📉 JOUR LE PLUS FAIBLE : {worst_day['DayName']}\")\n",
    "    print(f\"   💰 Revenus moyens: ${worst_day['Total_Revenue']:,.2f}\")\n",
    "    \n",
    "    # Heures de pointe\n",
    "    peak_hour = hourly_pattern.loc[hourly_pattern['Total_Revenue'].idxmax()]\n",
    "    low_hour = hourly_pattern.loc[hourly_pattern['Total_Revenue'].idxmin()]\n",
    "    \n",
    "    print(f\"\\n🕐 HEURE DE POINTE : {peak_hour['Hour']}h\")\n",
    "    print(f\"   💰 Revenus: ${peak_hour['Total_Revenue']:,.2f}\")\n",
    "    print(f\"   📦 Commandes: {peak_hour['Total_Orders']}\")\n",
    "    \n",
    "    print(f\"\\n🕐 HEURE CREUSE : {low_hour['Hour']}h\")\n",
    "    print(f\"   💰 Revenus: ${low_hour['Total_Revenue']:,.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'monthly_summary': monthly_summary,\n",
    "        'quarterly_data': quarterly_data,\n",
    "        'weekly_pattern': weekly_pattern,\n",
    "        'hourly_pattern': hourly_pattern,\n",
    "        'figures': [fig1, fig2, fig3, fig4]\n",
    "    }\n",
    "\n",
    "# Exécution de l'analyse saisonnalité\n",
    "seasonal_results = seasonal_analysis_complete(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "250947ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DÉTECTION D'ANOMALIES COMPLÈTE\n",
      "========================================\n",
      "💰 ANALYSE DES ANOMALIES TRANSACTIONNELLES\n",
      "---------------------------------------------\n",
      "📊 STATISTIQUES VALEUR COMMANDE :\n",
      "   Moyenne: $352.97\n",
      "   Médiane: $192.34\n",
      "   Écart-type: $1645.25\n",
      "   Seuil inférieur: $-592.48\n",
      "   Seuil supérieur: $987.46\n",
      "   🚨 Anomalies détectées: 3972 commandes\n",
      "\n",
      "🔥 TOP 10 COMMANDES ANORMALEMENT ÉLEVÉES :\n",
      "   📋 581483: $168,469.60 | 80995 items | 1 produits\n",
      "   📋 541431: $77,183.60 | 74215 items | 1 produits\n",
      "   📋 574941: $52,940.94 | 14149 items | 101 produits\n",
      "   📋 576365: $50,653.91 | 13956 items | 99 produits\n",
      "   📋 533027: $49,844.99 | 13387 items | 111 produits\n",
      "   📋 531516: $45,332.97 | 12410 items | 115 produits\n",
      "   📋 493819: $44,051.60 | 25018 items | 94 produits\n",
      "   📋 556444: $38,970.00 | 60 items | 1 produits\n",
      "   📋 524181: $33,167.80 | 8820 items | 14 produits\n",
      "   📋 567423: $31,698.16 | 12572 items | 12 produits\n",
      "\n",
      "📦 ANALYSE DES ANOMALIES PRODUITS\n",
      "----------------------------------------\n",
      "🚨 PRODUITS AVEC VARIATIONS DE PRIX SUSPECTES : 1170\n",
      "Top 10 variations de prix :\n",
      "   📦 POST: Variation 7.77x | Prix: $0.00 -  $ 8142.75\n",
      "   📦 17003: Variation 6.83x | Prix: $0.00 -  $ 57.60\n",
      "   📦 BANK CHARGES: Variation 5.18x | Prix: $0.00 -  $ 18910.69\n",
      "   📦 PADS: Variation 4.36x | Prix: $0.00 -  $ 36.60\n",
      "   📦 84016: Variation 4.05x | Prix: $0.00 -  $ 1157.15\n",
      "   📦 ADJUST: Variation 3.81x | Prix: $4.57 -  $ 5117.03\n",
      "   📦 22502: Variation 3.70x | Prix: $0.00 -  $ 649.50\n",
      "   📦 M: Variation 3.52x | Prix: $0.00 -  $ 38970.00\n",
      "   📦 84033: Variation 3.48x | Prix: $0.00 -  $ 85.10\n",
      "   📦 D: Variation 2.82x | Prix: $0.01 -  $ 1867.86\n",
      "\n",
      "👥 ANALYSE DES ANOMALIES CLIENTS\n",
      "-----------------------------------\n",
      "🚨 CLIENTS ANORMAUX DÉTECTÉS : 12448\n",
      "Top 10 clients les plus anormaux :\n",
      "   👤 Client 18102:  $ 570,380.61 | 153 commandes | Score: -0.352\n",
      "   👤 Client 14646:  $ 523,342.07 | 164 commandes | Score: -0.346\n",
      "   👤 Client 13694:  $ 190,020.84 | 164 commandes | Score: -0.346\n",
      "   👤 Client 12415:  $ 143,269.29 | 33 commandes | Score: -0.346\n",
      "   👤 Client 17511:  $ 168,491.62 | 85 commandes | Score: -0.345\n",
      "   👤 Client 14156:  $ 296,063.44 | 202 commandes | Score: -0.345\n",
      "   👤 Client 14298:  $ 90,489.31 | 84 commandes | Score: -0.343\n",
      "   👤 Client 16684:  $ 141,502.25 | 65 commandes | Score: -0.343\n",
      "   👤 Client 14088:  $ 62,400.02 | 20 commandes | Score: -0.343\n",
      "   👤 Client 17450:  $ 231,390.55 | 61 commandes | Score: -0.342\n",
      "\n",
      "⏰ ANALYSE DES ANOMALIES TEMPORELLES\n",
      "----------------------------------------\n",
      "🚨 JOURS AVEC ACTIVITÉ ANORMALE : 55\n",
      "Top 10 jours anormaux :\n",
      "   📅 2011-11-14:  $ 111,958.62 | 152 commandes | Z-score: 4.74\n",
      "   📅 2011-09-20:  $ 109,228.08 | 77 commandes | Z-score: 4.58\n",
      "   📅 2010-11-15:  $ 104,708.97 | 133 commandes | Z-score: 4.31\n",
      "   📅 2010-09-27:  $ 97,804.70 | 111 commandes | Z-score: 3.91\n",
      "   📅 2010-11-04:  $ 88,267.65 | 219 commandes | Z-score: 3.35\n",
      "   📅 2010-10-14:  $ 85,969.18 | 122 commandes | Z-score: 3.21\n",
      "   📅 2010-04-29:  $ -22,350.96 | 106 commandes | Z-score: 3.16\n",
      "   📅 2010-11-08:  $ 83,662.44 | 124 commandes | Z-score: 3.08\n",
      "   📅 2011-12-08:  $ 81,294.33 | 145 commandes | Z-score: 2.94\n",
      "   📅 2010-11-10:  $ 79,469.50 | 152 commandes | Z-score: 2.83\n",
      "\n",
      "🎯 RÉSUMÉ DÉTECTION D'ANOMALIES\n",
      "===================================\n",
      "📊 TRANSACTIONS ANORMALES : 3972 commandes\n",
      "📦 PRODUITS SUSPECTS : 1170 produits\n",
      "👥 CLIENTS ANORMAUX : 12448 clients\n",
      "⏰ JOURS ANORMAUX : 55 jours\n",
      "\n",
      "📈 POURCENTAGES D'ANOMALIES :\n",
      "   Transactions: 7.4%\n",
      "   Produits: 22.1%\n",
      "   Clients: 5.0%\n",
      "   Jours: 9.1%\n",
      "\n",
      "💡 RECOMMANDATIONS :\n",
      "🔍 ACTIONS IMMÉDIATES :\n",
      "   • Vérifier les commandes > $10,000\n",
      "   • Investiguer les variations de prix > 100%\n",
      "   • Analyser les clients avec score anomalie < -0.5\n",
      "   • Examiner les pics de ventes inexpliqués\n",
      "🛡️ MESURES PRÉVENTIVES :\n",
      "   • Alertes automatiques pour commandes > seuil\n",
      "   • Validation manuelle pour variations prix > 50%\n",
      "   • Monitoring comportement clients VIP\n",
      "   • Système de détection temps réel\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 🔍 DÉTECTION D'ANOMALIES - NOTEBOOK 3\n",
    "# ============================================================================\n",
    "\n",
    "def detect_anomalies_complete(df):\n",
    "    \"\"\"\n",
    "    Détection complète des anomalies dans les données e-commerce\n",
    "    \"\"\"\n",
    "    print(\"🔍 DÉTECTION D'ANOMALIES COMPLÈTE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Imports pour détection d'anomalies\n",
    "    from scipy import stats\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import numpy as np\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 1. DÉTECTION ANOMALIES TRANSACTIONS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(\"💰 ANALYSE DES ANOMALIES TRANSACTIONNELLES\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    transaction_stats = df.groupby('Invoice').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Quantity': 'sum',\n",
    "        'StockCode': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    transaction_stats.columns = ['Invoice', 'Total_Order_Value', 'Total_Items', 'Unique_Products']\n",
    "    \n",
    "    # Calcul des seuils d'anomalie (méthode IQR)\n",
    "    def detect_outliers_iqr(data, column):\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "        return outliers, lower_bound, upper_bound\n",
    "    \n",
    "    # Détection anomalies valeur commande\n",
    "    order_anomalies, lower_order, upper_order = detect_outliers_iqr(\n",
    "        transaction_stats, 'Total_Order_Value'\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 STATISTIQUES VALEUR COMMANDE :\")\n",
    "    print(f\"   Moyenne: ${transaction_stats['Total_Order_Value'].mean():.2f}\")\n",
    "    print(f\"   Médiane: ${transaction_stats['Total_Order_Value'].median():.2f}\")\n",
    "    print(f\"   Écart-type: ${transaction_stats['Total_Order_Value'].std():.2f}\")\n",
    "    print(f\"   Seuil inférieur: ${lower_order:.2f}\")\n",
    "    print(f\"   Seuil supérieur: ${upper_order:.2f}\")\n",
    "    print(f\"   🚨 Anomalies détectées: {len(order_anomalies)} commandes\")\n",
    "    \n",
    "    # Top anomalies par valeur\n",
    "    print(f\"\\n🔥 TOP 10 COMMANDES ANORMALEMENT ÉLEVÉES :\")\n",
    "    top_anomalies = order_anomalies.nlargest(10, 'Total_Order_Value')\n",
    "    for _, row in top_anomalies.iterrows():\n",
    "        print(f\"   📋 {row['Invoice']}: ${row['Total_Order_Value']:,.2f} | \"\n",
    "              f\"{row['Total_Items']} items | {row['Unique_Products']} produits\")\n",
    "    \n",
    "    # Graphique 1: Distribution avec anomalies\n",
    "    fig1 = go.Figure()\n",
    "    \n",
    "    # Histogramme normal\n",
    "    fig1.add_trace(go.Histogram(\n",
    "        x=transaction_stats['Total_Order_Value'],\n",
    "        nbinsx=50,\n",
    "        name='Commandes normales',\n",
    "        opacity=0.7\n",
    "    ))\n",
    "    \n",
    "    # Ligne seuil supérieur\n",
    "    fig1.add_vline(\n",
    "        x=upper_order,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        annotation_text=f\"Seuil anomalie:  $ {upper_order:.0f}\"\n",
    "    )\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='📊 DISTRIBUTION VALEUR COMMANDES + SEUIL ANOMALIES',\n",
    "        xaxis_title='Valeur Commande ( $ )',\n",
    "        yaxis_title='Fréquence',\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 2. DÉTECTION ANOMALIES PRODUITS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n📦 ANALYSE DES ANOMALIES PRODUITS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Analyse par produit\n",
    "    product_anomalies = df.groupby('StockCode').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Quantity': 'sum',\n",
    "        'Price': ['mean', 'std', 'min', 'max'],\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten columns\n",
    "    product_anomalies.columns = ['StockCode', 'Total_Revenue', 'Total_Quantity', \n",
    "                                'Avg_Price', 'Price_Std', 'Min_Price', 'Max_Price', 'Unique_Customers']\n",
    "    \n",
    "    # Détection prix anormaux\n",
    "    product_anomalies['Price_Variation'] = product_anomalies['Price_Std'] / product_anomalies['Avg_Price']\n",
    "    product_anomalies['Price_Range'] = product_anomalies['Max_Price'] - product_anomalies['Min_Price']\n",
    "    \n",
    "    # Produits avec variations de prix suspectes\n",
    "    price_anomalies = product_anomalies[\n",
    "        (product_anomalies['Price_Variation'] > 1.0) |  # Variation > 100%\n",
    "        (product_anomalies['Price_Range'] > product_anomalies['Avg_Price'] * 2)  # Range > 200% du prix moyen\n",
    "    ].sort_values('Price_Variation', ascending=False)\n",
    "    \n",
    "    print(f\"🚨 PRODUITS AVEC VARIATIONS DE PRIX SUSPECTES : {len(price_anomalies)}\")\n",
    "    print(\"Top 10 variations de prix :\")\n",
    "    for _, row in price_anomalies.head(10).iterrows():\n",
    "        print(f\"   📦 {row['StockCode']}: Variation {row['Price_Variation']:.2f}x | \"\n",
    "              f\"Prix: ${row['Min_Price']:.2f} -  $ {row['Max_Price']:.2f}\")\n",
    "    \n",
    "    # Graphique 2: Scatter plot prix vs quantité\n",
    "    product_anomalies['Total_Revenue_Abs'] = product_anomalies['Total_Revenue'].abs()\n",
    "    fig2 = px.scatter(\n",
    "        product_anomalies.head(1000),  # Top 1000 pour lisibilité\n",
    "        x='Avg_Price',\n",
    "        y='Total_Quantity',\n",
    "        size='Total_Revenue_Abs',\n",
    "        color='Price_Variation',\n",
    "        hover_data=['StockCode'],\n",
    "        title='📊 DÉTECTION ANOMALIES PRODUITS : PRIX vs QUANTITÉ',\n",
    "        labels={'Avg_Price': 'Prix Moyen ( $ )', 'Total_Quantity': 'Quantité Totale'},\n",
    "        color_continuous_scale='Viridis'\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 3. DÉTECTION ANOMALIES CLIENTS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n👥 ANALYSE DES ANOMALIES CLIENTS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Analyse comportement client\n",
    "    customer_behavior = df.groupby('Customer ID').agg({\n",
    "        'Total_Amount': ['sum', 'mean', 'count'],\n",
    "        'Invoice': 'nunique',\n",
    "        'StockCode': 'nunique',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    customer_behavior.columns = ['Customer_ID', 'Total_Spent', 'Avg_Transaction', \n",
    "                               'Total_Transactions', 'Unique_Orders', 'Unique_Products', 'Total_Items']\n",
    "    \n",
    "    # Métriques clients\n",
    "    customer_behavior['Avg_Items_per_Order'] = customer_behavior['Total_Items'] / customer_behavior['Unique_Orders']\n",
    "    customer_behavior['Avg_Products_per_Order'] = customer_behavior['Unique_Products'] / customer_behavior['Unique_Orders']\n",
    "    \n",
    "    # Détection clients anormaux avec Isolation Forest\n",
    "    features_for_anomaly = ['Total_Spent', 'Avg_Transaction', 'Total_Transactions', \n",
    "                           'Unique_Products', 'Avg_Items_per_Order']\n",
    "    \n",
    "    # Préparation des données\n",
    "    X = customer_behavior[features_for_anomaly].fillna(0)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    customer_behavior['Anomaly'] = iso_forest.fit_predict(X_scaled)\n",
    "    customer_behavior['Anomaly_Score'] = iso_forest.decision_function(X_scaled)\n",
    "    \n",
    "    # Clients anormaux\n",
    "    anomalous_customers = customer_behavior[customer_behavior['Anomaly'] == -1].sort_values('Anomaly_Score')\n",
    "    \n",
    "    print(f\"🚨 CLIENTS ANORMAUX DÉTECTÉS : {len(anomalous_customers)}\")\n",
    "    print(\"Top 10 clients les plus anormaux :\")\n",
    "    for _, row in anomalous_customers.head(10).iterrows():\n",
    "        print(f\"   👤 Client {row['Customer_ID']}:  $ {row['Total_Spent']:,.2f} | \"\n",
    "              f\"{row['Unique_Orders']} commandes | Score: {row['Anomaly_Score']:.3f}\")\n",
    "    \n",
    "    # Graphique 3: Visualisation anomalies clients\n",
    "    fig3 = px.scatter(\n",
    "        customer_behavior,\n",
    "        x='Total_Spent',\n",
    "        y='Avg_Transaction',\n",
    "        color='Anomaly',\n",
    "        color_discrete_map={1: 'blue', -1: 'red'},\n",
    "        title='📊 DÉTECTION ANOMALIES CLIENTS',\n",
    "        labels={'Total_Spent': 'Dépense Totale ( $ )', 'Avg_Transaction': 'Transaction Moyenne ($)'},\n",
    "        hover_data=['Customer_ID', 'Unique_Orders']\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 4. DÉTECTION ANOMALIES TEMPORELLES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n⏰ ANALYSE DES ANOMALIES TEMPORELLES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Agrégation journalière\n",
    "    daily_sales = df.groupby(df['InvoiceDate'].dt.date).agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_sales.columns = ['Date', 'Daily_Revenue', 'Daily_Orders', 'Daily_Customers']\n",
    "    \n",
    "    # Z-score pour détection anomalies temporelles\n",
    "    daily_sales['Revenue_ZScore'] = np.abs(stats.zscore(daily_sales['Daily_Revenue']))\n",
    "    daily_sales['Orders_ZScore'] = np.abs(stats.zscore(daily_sales['Daily_Orders']))\n",
    "    \n",
    "    # Jours anormaux (Z-score > 2)\n",
    "    temporal_anomalies = daily_sales[\n",
    "        (daily_sales['Revenue_ZScore'] > 2) | \n",
    "        (daily_sales['Orders_ZScore'] > 2)\n",
    "    ].sort_values('Revenue_ZScore', ascending=False)\n",
    "    \n",
    "    print(f\"🚨 JOURS AVEC ACTIVITÉ ANORMALE : {len(temporal_anomalies)}\")\n",
    "    print(\"Top 10 jours anormaux :\")\n",
    "    for _, row in temporal_anomalies.head(10).iterrows():\n",
    "        print(f\"   📅 {row['Date']}:  $ {row['Daily_Revenue']:,.2f} | \"\n",
    "              f\"{row['Daily_Orders']} commandes | Z-score: {row['Revenue_ZScore']:.2f}\")\n",
    "    \n",
    "    # Graphique 4: Série temporelle avec anomalies\n",
    "    fig4 = go.Figure()\n",
    "    \n",
    "    # Série normale\n",
    "    fig4.add_trace(go.Scatter(\n",
    "        x=daily_sales['Date'],\n",
    "        y=daily_sales['Daily_Revenue'],\n",
    "        mode='lines',\n",
    "        name='Revenus journaliers',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    \n",
    "    # Points anomalies\n",
    "    fig4.add_trace(go.Scatter(\n",
    "        x=temporal_anomalies['Date'],\n",
    "        y=temporal_anomalies['Daily_Revenue'],\n",
    "        mode='markers',\n",
    "        name='Anomalies',\n",
    "        marker=dict(color='red', size=8),\n",
    "    ))\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        title='📊 DÉTECTION ANOMALIES TEMPORELLES',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Revenus Journaliers ( $ )',\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 5. RÉSUMÉ ANOMALIES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n🎯 RÉSUMÉ DÉTECTION D'ANOMALIES\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"📊 TRANSACTIONS ANORMALES : {len(order_anomalies)} commandes\")\n",
    "    print(f\"📦 PRODUITS SUSPECTS : {len(price_anomalies)} produits\")\n",
    "    print(f\"👥 CLIENTS ANORMAUX : {len(anomalous_customers)} clients\")\n",
    "    print(f\"⏰ JOURS ANORMAUX : {len(temporal_anomalies)} jours\")\n",
    "    \n",
    "    # Pourcentages\n",
    "    total_transactions = len(transaction_stats)\n",
    "    total_products = len(product_anomalies)\n",
    "    total_customers = len(customer_behavior)\n",
    "    total_days = len(daily_sales)\n",
    "    \n",
    "    print(f\"\\n📈 POURCENTAGES D'ANOMALIES :\")\n",
    "    print(f\"   Transactions: {len(order_anomalies)/total_transactions*100:.1f}%\")\n",
    "    print(f\"   Produits: {len(price_anomalies)/total_products*100:.1f}%\")\n",
    "    print(f\"   Clients: {len(anomalous_customers)/total_customers*100:.1f}%\")\n",
    "    print(f\"   Jours: {len(temporal_anomalies)/total_days*100:.1f}%\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(f\"\\n💡 RECOMMANDATIONS :\")\n",
    "    print(\"🔍 ACTIONS IMMÉDIATES :\")\n",
    "    print(\"   • Vérifier les commandes > $10,000\")\n",
    "    print(\"   • Investiguer les variations de prix > 100%\")\n",
    "    print(\"   • Analyser les clients avec score anomalie < -0.5\")\n",
    "    print(\"   • Examiner les pics de ventes inexpliqués\")\n",
    "    \n",
    "    print(\"🛡️ MESURES PRÉVENTIVES :\")\n",
    "    print(\"   • Alertes automatiques pour commandes > seuil\")\n",
    "    print(\"   • Validation manuelle pour variations prix > 50%\")\n",
    "    print(\"   • Monitoring comportement clients VIP\")\n",
    "    print(\"   • Système de détection temps réel\")\n",
    "    \n",
    "    return {\n",
    "        'transaction_anomalies': order_anomalies,\n",
    "        'product_anomalies': price_anomalies,\n",
    "        'customer_anomalies': anomalous_customers,\n",
    "        'temporal_anomalies': temporal_anomalies,\n",
    "        'figures': [fig1, fig2, fig3, fig4],\n",
    "        'summary_stats': {\n",
    "            'total_transaction_anomalies': len(order_anomalies),\n",
    "            'total_product_anomalies': len(price_anomalies),\n",
    "            'total_customer_anomalies': len(anomalous_customers),\n",
    "            'total_temporal_anomalies': len(temporal_anomalies)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Exécution de la détection d'anomalies\n",
    "anomaly_results = detect_anomalies_complete(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2269c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 RAPPORT FINAL - ANALYSE EXPLORATOIRE\n",
      "==================================================\n",
      "🎯 SYNTHÈSE EXÉCUTIVE\n",
      "====================\n",
      "📊 MÉTRIQUES BUSINESS GLOBALES\n",
      "   💰 Chiffre d'affaires total: $18,928,949.47\n",
      "   📦 Nombre de commandes: 53,628\n",
      "   👥 Clients uniques: 248,949\n",
      "   🛍️ Produits uniques: 5,305\n",
      "   💳 Panier moyen: $352.97\n",
      "   📅 Période analysée: 738 jours (2009-12-01 → 2011-12-09)\n",
      "\n",
      "🔍 INSIGHTS CLÉS DÉCOUVERTS\n",
      "==============================\n",
      "👥 DIMENSION CLIENTS :\n",
      "   💎 Top 20% clients génèrent 98.5% du CA\n",
      "   📈 Client le plus valuable: $570,380.61\n",
      "   🔄 Commandes moyennes par client: 1.2\n",
      "\n",
      "📦 DIMENSION PRODUITS :\n",
      "   🏆 Top 10 produits représentent 9.2% du CA\n",
      "   🎯 Produit star:  $ 322,647.47 de revenus\n",
      "   📊 80/20 Rule: 1061 produits génèrent 80% du CA\n",
      "\n",
      "⏰ DIMENSION TEMPORELLE :\n",
      "   📈 Meilleur mois: Mois 11 (2,872,964 $ )\n",
      "   📉 Mois le plus faible: Mois 2 (1,028,339$)\n",
      "   🗓️ Meilleur jour: Jeudi (3,902,397$)\n",
      "\n",
      "🚨 ANOMALIES CRITIQUES DÉTECTÉES\n",
      "===================================\n",
      "📊 RÉSUMÉ DES ANOMALIES :\n",
      "   💰 Transactions suspectes: 3972\n",
      "   📦 Produits avec prix anormaux: 1170\n",
      "   👥 Clients au comportement atypique: 12448\n",
      "   ⏰ Jours avec activité anormale: 55\n",
      "   💸 Impact financier anomalies: $8,256,853.01 (43.6% du CA)\n",
      "\n",
      "📊 CRÉATION DU DASHBOARD RÉCAPITULATIF\n",
      "========================================\n",
      "\n",
      "🎯 RECOMMANDATIONS STRATÉGIQUES\n",
      "===================================\n",
      "🚀 RECOMMANDATIONS IMMÉDIATES (0-3 mois):\n",
      "   1. 👥 CLIENTS :\n",
      "      • Créer programme fidélité pour top 20% clients\n",
      "      • Campagne de réactivation clients inactifs\n",
      "      • Analyse détaillée des clients à forte valeur\n",
      "      • Segmentation RFM pour personnalisation\n",
      "   2. 📦 PRODUITS :\n",
      "      • Optimiser stock des produits stars\n",
      "      • Analyser marge des top performers\n",
      "      • Cross-selling sur produits complémentaires\n",
      "      • Éliminer produits low-performers\n",
      "   3. 💰 PRICING :\n",
      "      • Investiguer variations prix anormales\n",
      "      • Standardiser politique tarifaire\n",
      "      • Tests A/B sur pricing dynamique\n",
      "      • Monitoring concurrence\n",
      "   4. 🛡️ CONTRÔLE QUALITÉ :\n",
      "      • Système d'alertes pour commandes > $10K\n",
      "      • Validation manuelle transactions suspectes\n",
      "      • Audit des comptes clients anormaux\n",
      "      • Vérification des pics de ventes\n",
      "\n",
      "📈 RECOMMANDATIONS MOYEN TERME (3-12 mois):\n",
      "   1. 🎯 STRATÉGIE MARKETING :\n",
      "      • Campagnes ciblées par segment client\n",
      "      • Optimisation saisonnière des promotions\n",
      "      • Marketing automation basé sur comportement\n",
      "      • Stratégie omnicanal\n",
      "   2. 📊 ANALYTICS AVANCÉS :\n",
      "      • Modèles prédictifs de churn\n",
      "      • Scoring de valeur client (CLV)\n",
      "      • Recommandations produits IA\n",
      "      • Forecasting des ventes\n",
      "   3. 🏗️ INFRASTRUCTURE :\n",
      "      • Dashboard temps réel\n",
      "      • Système de détection anomalies automatique\n",
      "      • Data pipeline optimisé\n",
      "      • Reporting automatisé\n",
      "\n",
      "🗺️ ROADMAP PROCHAINES ANALYSES\n",
      "==============================\n",
      "📋 NOTEBOOK 4 - FEATURE ENGINEERING :\n",
      "   • Création variables RFM\n",
      "   • Features temporelles avancées\n",
      "   • Encoding catégorielles\n",
      "   • Features d'interaction\n",
      "📋 NOTEBOOK 5 - MACHINE LEARNING :\n",
      "   • Clustering clients (K-means)\n",
      "   • Prédiction valeur client\n",
      "   • Système de recommandation\n",
      "   • Détection churn\n",
      "📋 NOTEBOOK 6 - DÉPLOIEMENT :\n",
      "   • API de prédiction\n",
      "   • Dashboard interactif\n",
      "   • Monitoring modèles\n",
      "   • Documentation complète\n",
      "\n",
      "📈 MÉTRIQUES DE PERFORMANCE À SUIVRE\n",
      "========================================\n",
      "🎯 KPIs ACTUELS :\n",
      "   💰 CA mensuel moyen: $757,157.98\n",
      "   📈 Croissance dernier mois: -70.3%\n",
      "   👥 Clients actifs/mois: 10120\n",
      "   🛒 Commandes/jour: 72.7\n",
      "   💳 Panier moyen: $352.97\n",
      "\n",
      "🎯 KPIs À MONITORER :\n",
      "   • Taux de rétention client\n",
      "   • Customer Lifetime Value (CLV)\n",
      "   • Taux de conversion\n",
      "   • Fréquence d'achat\n",
      "   • Marge brute par segment\n",
      "\n",
      "✅ RAPPORT FINAL GÉNÉRÉ AVEC SUCCÈS !\n",
      "===================================\n",
      "\n",
      "============================================================\n",
      "🎉 NOTEBOOK 3 - ANALYSE EXPLORATOIRE TERMINÉ !\n",
      "============================================================\n",
      "\n",
      "📊 RÉSUMÉ DE CE QUE NOUS AVONS ACCOMPLI :\n",
      "   ✅ Analyse exploratoire complète\n",
      "   ✅ Visualisations avancées (15+ graphiques)\n",
      "   ✅ Analyse saisonnalité détaillée\n",
      "   ✅ Détection d'anomalies multi-dimensionnelle\n",
      "   ✅ Insights business actionnables\n",
      "   ✅ Recommandations stratégiques\n",
      "   ✅ Dashboard récapitulatif\n",
      "   ✅ Roadmap pour la suite\n",
      "\n",
      "🚀 PROCHAINE ÉTAPE : NOTEBOOK 4 - FEATURE ENGINEERING\n",
      "   🎯 Objectif: Préparer les données pour le ML\n",
      "   🛠️ Techniques: RFM, Variables temporelles, Encoding\n",
      "   📊 Résultat: Dataset prêt pour modélisation\n",
      "\n",
      "💾 DONNÉES PRÊTES POUR LA SUITE :\n",
      "   • Dataset nettoyé: 1040892 lignes\n",
      "   • Variables créées: 21 colonnes\n",
      "   • Anomalies identifiées: 17645\n",
      "   • Insights business: 20+ recommandations\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 📋 RAPPORT FINAL + RECOMMANDATIONS - NOTEBOOK 3\n",
    "# ============================================================================\n",
    "\n",
    "def generate_final_report(df, seasonal_results, anomaly_results):\n",
    "    \"\"\"\n",
    "    Génération du rapport final avec recommandations stratégiques\n",
    "    \"\"\"\n",
    "    print(\"📋 RAPPORT FINAL - ANALYSE EXPLORATOIRE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 1. SYNTHÈSE EXÉCUTIVE\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(\"🎯 SYNTHÈSE EXÉCUTIVE\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # Métriques clés globales\n",
    "    total_revenue = df['Total_Amount'].sum()\n",
    "    total_transactions = df['Invoice'].nunique()\n",
    "    total_customers = df['Customer ID'].nunique()\n",
    "    total_products = df['StockCode'].nunique()\n",
    "    avg_order_value = total_revenue / total_transactions\n",
    "    \n",
    "    # Période d'analyse\n",
    "    start_date = df['InvoiceDate'].min()\n",
    "    end_date = df['InvoiceDate'].max()\n",
    "    analysis_period = (end_date - start_date).days\n",
    "    \n",
    "    print(f\"📊 MÉTRIQUES BUSINESS GLOBALES\")\n",
    "    print(f\"   💰 Chiffre d'affaires total: ${total_revenue:,.2f}\")\n",
    "    print(f\"   📦 Nombre de commandes: {total_transactions:,}\")\n",
    "    print(f\"   👥 Clients uniques: {total_customers:,}\")\n",
    "    print(f\"   🛍️ Produits uniques: {total_products:,}\")\n",
    "    print(f\"   💳 Panier moyen: ${avg_order_value:.2f}\")\n",
    "    print(f\"   📅 Période analysée: {analysis_period} jours ({start_date.strftime('%Y-%m-%d')} → {end_date.strftime('%Y-%m-%d')})\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 2. INSIGHTS CLÉS PAR DIMENSION\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n🔍 INSIGHTS CLÉS DÉCOUVERTS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # A. INSIGHTS CLIENTS\n",
    "    print(\"👥 DIMENSION CLIENTS :\")\n",
    "    customer_segments = df.groupby('Customer ID').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentation clients\n",
    "    top_20_customers = customer_segments.nlargest(int(len(customer_segments) * 0.2), 'Total_Amount')\n",
    "    top_20_revenue = top_20_customers['Total_Amount'].sum()\n",
    "    \n",
    "    print(f\"   💎 Top 20% clients génèrent {top_20_revenue/total_revenue*100:.1f}% du CA\")\n",
    "    print(f\"   📈 Client le plus valuable: ${customer_segments['Total_Amount'].max():,.2f}\")\n",
    "    print(f\"   🔄 Commandes moyennes par client: {customer_segments['Invoice'].mean():.1f}\")\n",
    "    \n",
    "    # B. INSIGHTS PRODUITS\n",
    "    print(f\"\\n📦 DIMENSION PRODUITS :\")\n",
    "    product_performance = df.groupby('StockCode').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    top_products = product_performance.nlargest(10, 'Total_Amount')\n",
    "    top_10_revenue = top_products['Total_Amount'].sum()\n",
    "    \n",
    "    print(f\"   🏆 Top 10 produits représentent {top_10_revenue/total_revenue*100:.1f}% du CA\")\n",
    "    print(f\"   🎯 Produit star:  $ {product_performance['Total_Amount'].max():,.2f} de revenus\")\n",
    "    print(f\"   📊 80/20 Rule: {(product_performance['Total_Amount'] > product_performance['Total_Amount'].quantile(0.8)).sum()} produits génèrent 80% du CA\")\n",
    "    \n",
    "    # C. INSIGHTS TEMPORELS\n",
    "    print(f\"\\n⏰ DIMENSION TEMPORELLE :\")\n",
    "    \n",
    "    # Meilleurs mois (depuis seasonal_results)\n",
    "    monthly_data = df.groupby(df['InvoiceDate'].dt.month).agg({\n",
    "        'Total_Amount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    best_month = monthly_data.loc[monthly_data['Total_Amount'].idxmax(), 'InvoiceDate']\n",
    "    worst_month = monthly_data.loc[monthly_data['Total_Amount'].idxmin(), 'InvoiceDate']\n",
    "    \n",
    "    print(f\"   📈 Meilleur mois: Mois {best_month} ({monthly_data['Total_Amount'].max():,.0f} $ )\")\n",
    "    print(f\"   📉 Mois le plus faible: Mois {worst_month} ({monthly_data['Total_Amount'].min():,.0f}$)\")\n",
    "    \n",
    "    # Jour de la semaine\n",
    "    weekday_performance = df.groupby(df['InvoiceDate'].dt.dayofweek)['Total_Amount'].sum()\n",
    "    best_day = weekday_performance.idxmax()\n",
    "    days_names = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "    \n",
    "    print(f\"   🗓️ Meilleur jour: {days_names[best_day]} ({weekday_performance.max():,.0f}$)\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 3. ANALYSE DES ANOMALIES DÉTECTÉES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n🚨 ANOMALIES CRITIQUES DÉTECTÉES\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Récupération des résultats d'anomalies\n",
    "    anom_stats = anomaly_results['summary_stats']\n",
    "    \n",
    "    print(f\"📊 RÉSUMÉ DES ANOMALIES :\")\n",
    "    print(f\"   💰 Transactions suspectes: {anom_stats['total_transaction_anomalies']}\")\n",
    "    print(f\"   📦 Produits avec prix anormaux: {anom_stats['total_product_anomalies']}\")\n",
    "    print(f\"   👥 Clients au comportement atypique: {anom_stats['total_customer_anomalies']}\")\n",
    "    print(f\"   ⏰ Jours avec activité anormale: {anom_stats['total_temporal_anomalies']}\")\n",
    "    \n",
    "    # Impact des anomalies\n",
    "    transaction_anomalies = anomaly_results['transaction_anomalies']\n",
    "    if len(transaction_anomalies) > 0:\n",
    "        anomaly_revenue = transaction_anomalies['Total_Order_Value'].sum()\n",
    "        print(f\"   💸 Impact financier anomalies: ${anomaly_revenue:,.2f} ({anomaly_revenue/total_revenue*100:.1f}% du CA)\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 4. DASHBOARD RÉCAPITULATIF\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n📊 CRÉATION DU DASHBOARD RÉCAPITULATIF\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Dashboard avec 4 graphiques principaux\n",
    "    fig_dashboard = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            '💰 TOP 10 CLIENTS (CA)',\n",
    "            '📦 TOP 10 PRODUITS (Revenus)',\n",
    "            '📅 ÉVOLUTION MENSUELLE',\n",
    "            '🕐 PERFORMANCE HORAIRE'\n",
    "        ),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Top 10 clients\n",
    "    top_customers = df.groupby('Customer ID')['Total_Amount'].sum().nlargest(10)\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=top_customers.index.astype(str), y=top_customers.values, name='Top Clients'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Top 10 produits\n",
    "    top_products_viz = df.groupby('StockCode')['Total_Amount'].sum().nlargest(10)\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=top_products_viz.index, y=top_products_viz.values, name='Top Produits'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Évolution mensuelle\n",
    "    monthly_evolution = df.groupby(df['InvoiceDate'].dt.to_period('M'))['Total_Amount'].sum()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Scatter(x=monthly_evolution.index.astype(str), y=monthly_evolution.values, \n",
    "                  mode='lines+markers', name='CA Mensuel'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Performance horaire\n",
    "    hourly_perf = df.groupby(df['InvoiceDate'].dt.hour)['Total_Amount'].sum()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=hourly_perf.index, y=hourly_perf.values, name='CA par Heure'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig_dashboard.update_layout(\n",
    "        title_text=\"📊 DASHBOARD RÉCAPITULATIF - ANALYSE E-COMMERCE\",\n",
    "        showlegend=False,\n",
    "        height=800,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig_dashboard.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 5. RECOMMANDATIONS STRATÉGIQUES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n🎯 RECOMMANDATIONS STRATÉGIQUES\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    print(\"🚀 RECOMMANDATIONS IMMÉDIATES (0-3 mois):\")\n",
    "    print(\"   1. 👥 CLIENTS :\")\n",
    "    print(\"      • Créer programme fidélité pour top 20% clients\")\n",
    "    print(\"      • Campagne de réactivation clients inactifs\")\n",
    "    print(\"      • Analyse détaillée des clients à forte valeur\")\n",
    "    print(\"      • Segmentation RFM pour personnalisation\")\n",
    "    \n",
    "    print(\"   2. 📦 PRODUITS :\")\n",
    "    print(\"      • Optimiser stock des produits stars\")\n",
    "    print(\"      • Analyser marge des top performers\")\n",
    "    print(\"      • Cross-selling sur produits complémentaires\")\n",
    "    print(\"      • Éliminer produits low-performers\")\n",
    "    \n",
    "    print(\"   3. 💰 PRICING :\")\n",
    "    print(\"      • Investiguer variations prix anormales\")\n",
    "    print(\"      • Standardiser politique tarifaire\")\n",
    "    print(\"      • Tests A/B sur pricing dynamique\")\n",
    "    print(\"      • Monitoring concurrence\")\n",
    "    \n",
    "    print(\"   4. 🛡️ CONTRÔLE QUALITÉ :\")\n",
    "    print(\"      • Système d'alertes pour commandes > $10K\")\n",
    "    print(\"      • Validation manuelle transactions suspectes\")\n",
    "    print(\"      • Audit des comptes clients anormaux\")\n",
    "    print(\"      • Vérification des pics de ventes\")\n",
    "    \n",
    "    print(f\"\\n📈 RECOMMANDATIONS MOYEN TERME (3-12 mois):\")\n",
    "    print(\"   1. 🎯 STRATÉGIE MARKETING :\")\n",
    "    print(\"      • Campagnes ciblées par segment client\")\n",
    "    print(\"      • Optimisation saisonnière des promotions\")\n",
    "    print(\"      • Marketing automation basé sur comportement\")\n",
    "    print(\"      • Stratégie omnicanal\")\n",
    "    \n",
    "    print(\"   2. 📊 ANALYTICS AVANCÉS :\")\n",
    "    print(\"      • Modèles prédictifs de churn\")\n",
    "    print(\"      • Scoring de valeur client (CLV)\")\n",
    "    print(\"      • Recommandations produits IA\")\n",
    "    print(\"      • Forecasting des ventes\")\n",
    "    \n",
    "    print(\"   3. 🏗️ INFRASTRUCTURE :\")\n",
    "    print(\"      • Dashboard temps réel\")\n",
    "    print(\"      • Système de détection anomalies automatique\")\n",
    "    print(\"      • Data pipeline optimisé\")\n",
    "    print(\"      • Reporting automatisé\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 6. ROADMAP PROCHAINES ANALYSES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n🗺️ ROADMAP PROCHAINES ANALYSES\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(\"📋 NOTEBOOK 4 - FEATURE ENGINEERING :\")\n",
    "    print(\"   • Création variables RFM\")\n",
    "    print(\"   • Features temporelles avancées\")\n",
    "    print(\"   • Encoding catégorielles\")\n",
    "    print(\"   • Features d'interaction\")\n",
    "    \n",
    "    print(\"📋 NOTEBOOK 5 - MACHINE LEARNING :\")\n",
    "    print(\"   • Clustering clients (K-means)\")\n",
    "    print(\"   • Prédiction valeur client\")\n",
    "    print(\"   • Système de recommandation\")\n",
    "    print(\"   • Détection churn\")\n",
    "    \n",
    "    print(\"📋 NOTEBOOK 6 - DÉPLOIEMENT :\")\n",
    "    print(\"   • API de prédiction\")\n",
    "    print(\"   • Dashboard interactif\")\n",
    "    print(\"   • Monitoring modèles\")\n",
    "    print(\"   • Documentation complète\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 7. MÉTRIQUES DE PERFORMANCE\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\n📈 MÉTRIQUES DE PERFORMANCE À SUIVRE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Calcul des KPIs actuels\n",
    "    monthly_growth = df.groupby(df['InvoiceDate'].dt.to_period('M'))['Total_Amount'].sum()\n",
    "    if len(monthly_growth) > 1:\n",
    "        last_month_growth = ((monthly_growth.iloc[-1] - monthly_growth.iloc[-2]) / monthly_growth.iloc[-2] * 100)\n",
    "    else:\n",
    "        last_month_growth = 0\n",
    "    \n",
    "    print(\"🎯 KPIs ACTUELS :\")\n",
    "    print(f\"   💰 CA mensuel moyen: ${monthly_growth.mean():,.2f}\")\n",
    "    print(f\"   📈 Croissance dernier mois: {last_month_growth:.1f}%\")\n",
    "    print(f\"   👥 Clients actifs/mois: {total_customers/(analysis_period/30):.0f}\")\n",
    "    print(f\"   🛒 Commandes/jour: {total_transactions/(analysis_period):.1f}\")\n",
    "    print(f\"   💳 Panier moyen: ${avg_order_value:.2f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 KPIs À MONITORER :\")\n",
    "    print(\"   • Taux de rétention client\")\n",
    "    print(\"   • Customer Lifetime Value (CLV)\")\n",
    "    print(\"   • Taux de conversion\")\n",
    "    print(\"   • Fréquence d'achat\")\n",
    "    print(\"   • Marge brute par segment\")\n",
    "    \n",
    "    # Sauvegarde des résultats\n",
    "    report_summary = {\n",
    "        'total_revenue': total_revenue,\n",
    "        'total_transactions': total_transactions,\n",
    "        'total_customers': total_customers,\n",
    "        'avg_order_value': avg_order_value,\n",
    "        'analysis_period': analysis_period,\n",
    "        'anomalies_detected': anom_stats,\n",
    "        'top_customers': top_customers.to_dict(),\n",
    "        'top_products': top_products_viz.to_dict(),\n",
    "        'monthly_growth': last_month_growth\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✅ RAPPORT FINAL GÉNÉRÉ AVEC SUCCÈS !\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    return report_summary, fig_dashboard\n",
    "\n",
    "# Génération du rapport final\n",
    "final_report, dashboard_fig = generate_final_report(df, seasonal_results, anomaly_results)\n",
    "\n",
    "# =======================================================================\n",
    "# CONCLUSION NOTEBOOK 3\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 NOTEBOOK 3 - ANALYSE EXPLORATOIRE TERMINÉ !\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 RÉSUMÉ DE CE QUE NOUS AVONS ACCOMPLI :\")\n",
    "print(\"   ✅ Analyse exploratoire complète\")\n",
    "print(\"   ✅ Visualisations avancées (15+ graphiques)\")\n",
    "print(\"   ✅ Analyse saisonnalité détaillée\")\n",
    "print(\"   ✅ Détection d'anomalies multi-dimensionnelle\")\n",
    "print(\"   ✅ Insights business actionnables\")\n",
    "print(\"   ✅ Recommandations stratégiques\")\n",
    "print(\"   ✅ Dashboard récapitulatif\")\n",
    "print(\"   ✅ Roadmap pour la suite\")\n",
    "\n",
    "print(f\"\\n🚀 PROCHAINE ÉTAPE : NOTEBOOK 4 - FEATURE ENGINEERING\")\n",
    "print(\"   🎯 Objectif: Préparer les données pour le ML\")\n",
    "print(\"   🛠️ Techniques: RFM, Variables temporelles, Encoding\")\n",
    "print(\"   📊 Résultat: Dataset prêt pour modélisation\")\n",
    "\n",
    "print(f\"\\n💾 DONNÉES PRÊTES POUR LA SUITE :\")\n",
    "print(f\"   • Dataset nettoyé: {len(df)} lignes\")\n",
    "print(f\"   • Variables créées: {len(df.columns)} colonnes\")\n",
    "print(f\"   • Anomalies identifiées: {sum(final_report['anomalies_detected'].values())}\")\n",
    "print(f\"   • Insights business: 20+ recommandations\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
