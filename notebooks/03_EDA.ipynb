{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c7fcecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ NOTEBOOK 3 : ANALYSE EXPLORATOIRE\n",
      "========================================\n",
      "ğŸ“Š DÃ©couverte des patterns business\n",
      "ğŸ” Insights actionnables\n",
      "ğŸ“ˆ Visualisations interactives\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NOTEBOOK 3 : ANALYSE EXPLORATOIRE DES DONNÃ‰ES E-COMMERCE\n",
    "# ============================================================================\n",
    "# Objectif : DÃ©couvrir les patterns, tendances et insights cachÃ©s\n",
    "# Focus : Visualisations actionables pour le business\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"ğŸ¯ NOTEBOOK 3 : ANALYSE EXPLORATOIRE\")\n",
    "print(\"=\" * 40)\n",
    "print(\"ğŸ“Š DÃ©couverte des patterns business\")\n",
    "print(\"ğŸ” Insights actionnables\")\n",
    "print(\"ğŸ“ˆ Visualisations interactives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5318c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š APERÃ‡U DES DONNÃ‰ES NETTOYÃ‰ES\n",
      "===================================\n",
      "ğŸ“ Dimensions: (1040892, 13)\n",
      "ğŸ“… PÃ©riode: 2009-12-01 07:45:00 â†’ 2011-12-09 12:50:00\n",
      "ğŸŒ Pays: 43\n",
      "ğŸ‘¥ Clients: 248,949\n",
      "ğŸ“¦ Produits: 5,305\n",
      "\n",
      "ğŸ”§ TYPES DE DONNÃ‰ES :\n",
      "Invoice                     object\n",
      "StockCode                   object\n",
      "Description                 object\n",
      "Quantity                     int64\n",
      "InvoiceDate         datetime64[ns]\n",
      "Price                      float64\n",
      "Customer ID                 object\n",
      "Country                     object\n",
      "Transaction_Type            object\n",
      "Total_Amount               float64\n",
      "Suspicious                    bool\n",
      "Price_Outlier                 bool\n",
      "Quantity_Outlier              bool\n",
      "dtype: object\n",
      "\n",
      "ğŸ”§ TYPES DE DONNÃ‰ES FINAUX :\n",
      "  â€¢ Invoice: object\n",
      "  â€¢ StockCode: object\n",
      "  â€¢ Description: object\n",
      "  â€¢ Quantity: int64\n",
      "  â€¢ InvoiceDate: datetime64[ns]\n",
      "  â€¢ Price: float64\n",
      "  â€¢ Customer ID: object\n",
      "  â€¢ Country: object\n",
      "  â€¢ Transaction_Type: object\n",
      "  â€¢ Total_Amount: float64\n",
      "  â€¢ Suspicious: bool\n",
      "  â€¢ Price_Outlier: bool\n",
      "  â€¢ Quantity_Outlier: bool\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ“Š CHARGEMENT ET APERÃ‡U DES DONNÃ‰ES NETTOYÃ‰ES\n",
    "# ============================================================================\n",
    "\n",
    "# Charger les donnÃ©es nettoyÃ©es\n",
    "df = pd.read_pickle('C:/Users/Moi/E-commerce_Marketing_Analytics/data/processed/cleaned_ecommerce_data.pkl')\n",
    "\n",
    "# Reconversion des types (nÃ©cessaire aprÃ¨s CSV)\n",
    "#df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "#df['Customer ID'] = df['Customer ID'].astype(str)\n",
    "\n",
    "print(\"ğŸ“Š APERÃ‡U DES DONNÃ‰ES NETTOYÃ‰ES\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"ğŸ“ Dimensions: {df.shape}\")\n",
    "print(f\"ğŸ“… PÃ©riode: {df['InvoiceDate'].min()} â†’ {df['InvoiceDate'].max()}\")\n",
    "print(f\"ğŸŒ Pays: {df['Country'].nunique()}\")\n",
    "print(f\"ğŸ‘¥ Clients: {df['Customer ID'].nunique():,}\")\n",
    "print(f\"ğŸ“¦ Produits: {df['StockCode'].nunique():,}\")\n",
    "\n",
    "# AperÃ§u des types de donnÃ©es\n",
    "print(\"\\nğŸ”§ TYPES DE DONNÃ‰ES :\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nğŸ”§ TYPES DE DONNÃ‰ES FINAUX :\")\n",
    "for col in df.columns:\n",
    "    print(f\"  â€¢ {col}: {df[col].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4b86eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’° ANALYSE FINANCIÃˆRE GLOBALE\n",
      "==============================\n",
      "ğŸ’µ Chiffre d'affaires brut: $20,445,293.52\n",
      "â†©ï¸  Montant des retours: $1,516,344.05\n",
      "ğŸ’ Chiffre d'affaires net: $18,928,949.47\n",
      "ğŸ“Š Taux de retour: 7.4%\n",
      "\n",
      "ğŸ“ˆ MÃ‰TRIQUES PAR COMMANDE :\n",
      "ğŸ’° Panier moyen: $20.01\n",
      "ğŸ“Š Panier mÃ©dian: $10.00\n",
      "ğŸ›’ Nombre total de commandes: 1,021,752\n",
      "\n",
      "ğŸ“¦ ANALYSE DES ARTICLES :\n",
      "ğŸ“Š Articles vendus: 10,907,268\n",
      "ğŸ›’ Articles par commande: 10.7\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ’° ANALYSE FINANCIÃˆRE GLOBALE\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_financial_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse complÃ¨te des performances financiÃ¨res\n",
    "    \"\"\"\n",
    "    print(\"ğŸ’° ANALYSE FINANCIÃˆRE GLOBALE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # MÃ©triques globales\n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE']\n",
    "    returns_data = df[df['Transaction_Type'] == 'RETURN']\n",
    "    \n",
    "    total_revenue = sales_data['Total_Amount'].sum()\n",
    "    total_returns = abs(returns_data['Total_Amount'].sum())\n",
    "    net_revenue = total_revenue - total_returns\n",
    "    \n",
    "    print(f\"ğŸ’µ Chiffre d'affaires brut: ${total_revenue:,.2f}\")\n",
    "    print(f\"â†©ï¸  Montant des retours: ${total_returns:,.2f}\")\n",
    "    print(f\"ğŸ’ Chiffre d'affaires net: ${net_revenue:,.2f}\")\n",
    "    print(f\"ğŸ“Š Taux de retour: {(total_returns/total_revenue)*100:.1f}%\")\n",
    "    \n",
    "    # MÃ©triques par transaction\n",
    "    avg_order_value = sales_data['Total_Amount'].mean()\n",
    "    median_order_value = sales_data['Total_Amount'].median()\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ MÃ‰TRIQUES PAR COMMANDE :\")\n",
    "    print(f\"ğŸ’° Panier moyen: ${avg_order_value:.2f}\")\n",
    "    print(f\"ğŸ“Š Panier mÃ©dian: ${median_order_value:.2f}\")\n",
    "    print(f\"ğŸ›’ Nombre total de commandes: {len(sales_data):,}\")\n",
    "    \n",
    "    # Analyse des articles\n",
    "    total_items_sold = sales_data['Quantity'].sum()\n",
    "    avg_items_per_order = sales_data['Quantity'].mean()\n",
    "    \n",
    "    print(f\"\\nğŸ“¦ ANALYSE DES ARTICLES :\")\n",
    "    print(f\"ğŸ“Š Articles vendus: {total_items_sold:,}\")\n",
    "    print(f\"ğŸ›’ Articles par commande: {avg_items_per_order:.1f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_revenue': total_revenue,\n",
    "        'net_revenue': net_revenue,\n",
    "        'return_rate': (total_returns/total_revenue)*100,\n",
    "        'avg_order_value': avg_order_value,\n",
    "        'total_orders': len(sales_data)\n",
    "    }\n",
    "\n",
    "# ExÃ©cution de l'analyse financiÃ¨re\n",
    "financial_metrics = analyze_financial_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ddae57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“… ANALYSE TEMPORELLE DES VENTES\n",
      "==============================\n",
      "ğŸ“Š PÃ©riode d'analyse: 2009-12-01 â†’ 2011-12-09\n",
      "ğŸ“ˆ Ventes quotidiennes moyennes: $33,849.82\n",
      "ğŸ• Heure de pointe: 12h\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ“… ANALYSE TEMPORELLE DES VENTES\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_temporal_patterns(df):\n",
    "    \"\"\"\n",
    "    Analyse des patterns temporels des ventes\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“… ANALYSE TEMPORELLE DES VENTES\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # Extraire les composantes temporelles\n",
    "    sales_data['Date'] = sales_data['InvoiceDate'].dt.date\n",
    "    sales_data['Hour'] = sales_data['InvoiceDate'].dt.hour\n",
    "    sales_data['DayOfWeek'] = sales_data['InvoiceDate'].dt.day_name()\n",
    "    sales_data['Month'] = sales_data['InvoiceDate'].dt.month\n",
    "    sales_data['MonthName'] = sales_data['InvoiceDate'].dt.month_name()\n",
    "    \n",
    "    # AgrÃ©gations\n",
    "    daily_sales = sales_data.groupby('Date').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    hourly_sales = sales_data.groupby('Hour')['Total_Amount'].sum().reset_index()\n",
    "    \n",
    "    monthly_sales = sales_data.groupby('MonthName').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    dow_sales = sales_data.groupby('DayOfWeek')['Total_Amount'].sum().reset_index()\n",
    "    \n",
    "    print(f\"ğŸ“Š PÃ©riode d'analyse: {sales_data['Date'].min()} â†’ {sales_data['Date'].max()}\")\n",
    "    print(f\"ğŸ“ˆ Ventes quotidiennes moyennes: ${daily_sales['Total_Amount'].mean():,.2f}\")\n",
    "    \n",
    "    # ğŸ”§ LIGNE CORRIGÃ‰E - Remplacez cette ligne :\n",
    "    # print(f\"ğŸ• Heure de pointe: {hourly_sales.loc[hourly_sales['Total_Amount'].idxmax(), 'Hour']}h\")\n",
    "    \n",
    "    # ğŸ”§ PAR CETTE LIGNE CORRIGÃ‰E :\n",
    "    if not hourly_sales.empty and hourly_sales['Total_Amount'].sum() > 0:\n",
    "        print(f\"ğŸ• Heure de pointe: {hourly_sales.loc[hourly_sales['Total_Amount'].idxmax(), 'Hour']}h\")\n",
    "    else:\n",
    "        print(\"ğŸ• Heure de pointe: Aucune donnÃ©e horaire disponible\")\n",
    "    \n",
    "    return {\n",
    "        'daily_sales': daily_sales,\n",
    "        'hourly_sales': hourly_sales,\n",
    "        'monthly_sales': monthly_sales,\n",
    "        'dow_sales': dow_sales\n",
    "    }\n",
    "\n",
    "# ExÃ©cution de l'analyse temporelle\n",
    "temporal_data = analyze_temporal_patterns(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "517b2cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” DIAGNOSTIC DES DONNÃ‰ES\n",
      "========================================\n",
      "ğŸ“Š Forme du DataFrame: (1040892, 13)\n",
      "ğŸ“‹ Colonnes: ['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'Price', 'Customer ID', 'Country', 'Transaction_Type', 'Total_Amount', 'Suspicious', 'Price_Outlier', 'Quantity_Outlier']\n",
      "ğŸ”¢ Lignes totales: 1,040,892\n",
      "\n",
      "ğŸ“ˆ TRANSACTION_TYPE:\n",
      "Transaction_Type\n",
      "SALE      1021752\n",
      "RETURN      19140\n",
      "Name: count, dtype: int64\n",
      "   â†’ Nombre de SALES: 1021752\n",
      "\n",
      "ğŸ“… INVOICEDATE:\n",
      "   â†’ Type: datetime64[ns]\n",
      "   â†’ Valeurs nulles: 0\n",
      "   â†’ PremiÃ¨res valeurs: [Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00'), Timestamp('2009-12-01 07:45:00')]\n",
      "\n",
      "ğŸ’° TOTAL_AMOUNT:\n",
      "   â†’ Type: float64\n",
      "   â†’ Valeurs nulles: 0\n",
      "   â†’ Min: -168469.6\n",
      "   â†’ Max: 168469.6\n",
      "   â†’ Moyenne: 18.185315544744313\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ” DIAGNOSTIC DES DONNÃ‰ES\n",
    "# ============================================================================\n",
    "\n",
    "def diagnose_data_issues(df):\n",
    "    \"\"\"\n",
    "    Diagnostic pour identifier les problÃ¨mes dans les donnÃ©es\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ” DIAGNOSTIC DES DONNÃ‰ES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # VÃ©rifications de base\n",
    "    print(f\"ğŸ“Š Forme du DataFrame: {df.shape}\")\n",
    "    print(f\"ğŸ“‹ Colonnes: {list(df.columns)}\")\n",
    "    print(f\"ğŸ”¢ Lignes totales: {len(df):,}\")\n",
    "    \n",
    "    # VÃ©rification Transaction_Type\n",
    "    if 'Transaction_Type' in df.columns:\n",
    "        print(f\"\\nğŸ“ˆ TRANSACTION_TYPE:\")\n",
    "        print(df['Transaction_Type'].value_counts())\n",
    "        sales_count = (df['Transaction_Type'] == 'SALE').sum()\n",
    "        print(f\"   â†’ Nombre de SALES: {sales_count}\")\n",
    "    else:\n",
    "        print(\"âŒ Colonne 'Transaction_Type' manquante!\")\n",
    "    \n",
    "    # VÃ©rification InvoiceDate\n",
    "    if 'InvoiceDate' in df.columns:\n",
    "        print(f\"\\nğŸ“… INVOICEDATE:\")\n",
    "        print(f\"   â†’ Type: {df['InvoiceDate'].dtype}\")\n",
    "        print(f\"   â†’ Valeurs nulles: {df['InvoiceDate'].isnull().sum()}\")\n",
    "        print(f\"   â†’ PremiÃ¨res valeurs: {df['InvoiceDate'].head().tolist()}\")\n",
    "    else:\n",
    "        print(\"âŒ Colonne 'InvoiceDate' manquante!\")\n",
    "    \n",
    "    # VÃ©rification Total_Amount\n",
    "    if 'Total_Amount' in df.columns:\n",
    "        print(f\"\\nğŸ’° TOTAL_AMOUNT:\")\n",
    "        print(f\"   â†’ Type: {df['Total_Amount'].dtype}\")\n",
    "        print(f\"   â†’ Valeurs nulles: {df['Total_Amount'].isnull().sum()}\")\n",
    "        print(f\"   â†’ Min: {df['Total_Amount'].min()}\")\n",
    "        print(f\"   â†’ Max: {df['Total_Amount'].max()}\")\n",
    "        print(f\"   â†’ Moyenne: {df['Total_Amount'].mean()}\")\n",
    "    else:\n",
    "        print(\"âŒ Colonne 'Total_Amount' manquante!\")\n",
    "\n",
    "# ExÃ©cutez ce diagnostic\n",
    "diagnose_data_issues(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93697f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¨ CRÃ‰ATION DU DASHBOARD FINANCIER\n",
      "===================================\n",
      "âœ… Dashboard financier crÃ©Ã©\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ¨ VISUALISATIONS FINANCIÃˆRES\n",
    "# ============================================================================\n",
    "\n",
    "def create_financial_dashboard(df, temporal_data):\n",
    "    \"\"\"\n",
    "    CrÃ©e un dashboard financier interactif\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ¨ CRÃ‰ATION DU DASHBOARD FINANCIER\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Configuration des subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Ã‰volution des Ventes Quotidiennes', 'Ventes par Heure',\n",
    "                       'Ventes par Jour de la Semaine', 'Ventes par Mois'),\n",
    "        specs=[[{'secondary_y': True}, {'type': 'bar'}],\n",
    "               [{'type': 'bar'}, {'type': 'bar'}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Ã‰volution quotidienne\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=temporal_data['daily_sales']['Date'], \n",
    "                  y=temporal_data['daily_sales']['Total_Amount'],\n",
    "                  name='Ventes Quotidiennes',\n",
    "                  line=dict(color='blue', width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Ventes par heure\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=temporal_data['hourly_sales']['Hour'],\n",
    "               y=temporal_data['hourly_sales']['Total_Amount'],\n",
    "               name='Ventes par Heure',\n",
    "               marker_color='lightblue'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Ventes par jour de la semaine\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    dow_ordered = temporal_data['dow_sales'].set_index('DayOfWeek').reindex(day_order).reset_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(x=dow_ordered['DayOfWeek'],\n",
    "               y=dow_ordered['Total_Amount'],\n",
    "               name='Ventes par Jour',\n",
    "               marker_color='lightgreen'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Ventes par mois\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=temporal_data['monthly_sales']['MonthName'],\n",
    "               y=temporal_data['monthly_sales']['Total_Amount'],\n",
    "               name='Ventes par Mois',\n",
    "               marker_color='lightcoral'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Mise Ã  jour du layout\n",
    "    fig.update_layout(\n",
    "        title_text=\"ğŸ“Š DASHBOARD FINANCIER E-COMMERCE\",\n",
    "        title_x=0.5,\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    pio.renderers.default='browser'\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"âœ… Dashboard financier crÃ©Ã©\")\n",
    "\n",
    "# CrÃ©ation du dashboard\n",
    "create_financial_dashboard(df, temporal_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8978faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘¥ ANALYSE DU COMPORTEMENT CLIENT\n",
      "===================================\n",
      "ğŸ“Š Total clients: 248,138\n",
      "ğŸ‘¤ Clients enregistrÃ©s: 5,881\n",
      "ğŸ­ Clients invitÃ©s: 242,257\n",
      "\n",
      "ğŸ’° RÃ‰PARTITION PAR SEGMENT :\n",
      "  Bronze: 233,014 clients (93.9%)\n",
      "  Silver: 4,705 clients (1.9%)\n",
      "  Platinum: 2,845 clients (1.1%)\n",
      "  Gold: 1,435 clients (0.6%)\n",
      "\n",
      "ğŸ† TOP CLIENTS :\n",
      "  1. Client 18102: $580,987.04 (1040 commandes)\n",
      "  2. Client 14646: $528,602.52 (3854 commandes)\n",
      "  3. Client 14156: $313,437.62 (4038 commandes)\n",
      "  4. Client 14911: $291,420.81 (11079 commandes)\n",
      "  5. Client 17450: $244,784.25 (421 commandes)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ‘¥ ANALYSE DES CLIENTS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_customer_behavior(df):\n",
    "    \"\"\"\n",
    "    Analyse approfondie du comportement client\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ‘¥ ANALYSE DU COMPORTEMENT CLIENT\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # MÃ©triques par client\n",
    "    customer_metrics = sales_data.groupby('Customer ID').agg({\n",
    "        'Total_Amount': ['sum', 'count', 'mean'],\n",
    "        'Invoice': 'nunique',\n",
    "        'InvoiceDate': ['min', 'max'],\n",
    "        'Quantity': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    customer_metrics.columns = ['Total_Spent', 'Total_Orders', 'Avg_Order_Value', \n",
    "                               'Unique_Invoices', 'First_Purchase', 'Last_Purchase', 'Items_Bought']\n",
    "    \n",
    "    # PÃ©riode d'activitÃ©\n",
    "    customer_metrics['Days_Active'] = (customer_metrics['Last_Purchase'] - customer_metrics['First_Purchase']).dt.days\n",
    "    \n",
    "    # Segmentation simple\n",
    "    customer_metrics['Segment'] = pd.cut(customer_metrics['Total_Spent'], \n",
    "                                       bins=[0, 100, 500, 1000, float('inf')],\n",
    "                                       labels=['Bronze', 'Silver', 'Gold', 'Platinum'])\n",
    "    \n",
    "    # Distinguer les clients invitÃ©s\n",
    "    customer_metrics['Customer_Type'] = customer_metrics.index.to_series().apply(\n",
    "        lambda x: 'Guest' if x.startswith('GUEST_') else 'Registered'\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“Š Total clients: {len(customer_metrics):,}\")\n",
    "    print(f\"ğŸ‘¤ Clients enregistrÃ©s: {(customer_metrics['Customer_Type'] == 'Registered').sum():,}\")\n",
    "    print(f\"ğŸ­ Clients invitÃ©s: {(customer_metrics['Customer_Type'] == 'Guest').sum():,}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’° RÃ‰PARTITION PAR SEGMENT :\")\n",
    "    segment_dist = customer_metrics['Segment'].value_counts()\n",
    "    for segment, count in segment_dist.items():\n",
    "        pct = (count / len(customer_metrics)) * 100\n",
    "        print(f\"  {segment}: {count:,} clients ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ† TOP CLIENTS :\")\n",
    "    top_customers = customer_metrics.nlargest(5, 'Total_Spent')\n",
    "    for idx, (customer_id, data) in enumerate(top_customers.iterrows(), 1):\n",
    "        print(f\"  {idx}. Client {customer_id}: ${data['Total_Spent']:,.2f} ({data['Total_Orders']} commandes)\")\n",
    "    \n",
    "    return customer_metrics\n",
    "\n",
    "# ExÃ©cution de l'analyse client\n",
    "customer_data = analyze_customer_behavior(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bb602e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ ANALYSE DES PERFORMANCES PRODUITS\n",
      "========================================\n",
      "ğŸ“Š Produits uniques: 6,554\n",
      "ğŸ’° Revenus totaux: $20,445,293.52\n",
      "\n",
      "ğŸ† TOP 10 PRODUITS (Revenus) :\n",
      "  M: $340,153.38 | Manual\n",
      "  22423: $335,733.20 | REGENCY CAKESTAND 3 TIER\n",
      "  DOT: $322,657.48 | DOTCOM POSTAGE\n",
      "  85123A: $257,906.71 | WHITE HANGING HEART T-LIGHT HOLDER\n",
      "  23843: $168,469.60 | PAPER CRAFT , LITTLE BIRDIE\n",
      "  47566: $148,590.20 | PARTY BUNTING\n",
      "  85099B: $146,151.28 | JUMBO BAG RED RETROSPOT\n",
      "  84879: $129,465.61 | ASSORTED COLOUR BIRD ORNAMENT\n",
      "  POST: $125,682.42 | POSTAGE\n",
      "  22086: $120,145.39 | PAPER CHAIN KIT 50'S CHRISTMAS \n",
      "\n",
      "ğŸ”¥ TOP 10 PRODUITS (QuantitÃ©) :\n",
      "  84077: 106,265 unitÃ©s | WORLD WAR 2 GLIDERS ASSTD DESIGNS\n",
      "  85123A: 94,208 unitÃ©s | WHITE HANGING HEART T-LIGHT HOLDER\n",
      "  23843: 80,995 unitÃ©s | PAPER CRAFT , LITTLE BIRDIE\n",
      "  84879: 80,138 unitÃ©s | ASSORTED COLOUR BIRD ORNAMENT\n",
      "  23166: 78,033 unitÃ©s | MEDIUM CERAMIC TOP STORAGE JAR\n",
      "  85099B: 77,331 unitÃ©s | JUMBO BAG RED RETROSPOT\n",
      "  17003: 70,393 unitÃ©s | BROCADE RING PURSE \n",
      "  21977: 56,116 unitÃ©s | PACK OF 60 PINK PAISLEY CAKE CASES\n",
      "  84991: 54,049 unitÃ©s | 60 TEATIME FAIRY CAKE CASES\n",
      "  22197: 48,969 unitÃ©s | SMALL POPCORN HOLDER\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ“¦ ANALYSE DES PRODUITS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_product_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse des performances produits\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“¦ ANALYSE DES PERFORMANCES PRODUITS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # MÃ©triques par produit\n",
    "    product_metrics = sales_data.groupby(['StockCode', 'Description']).agg({\n",
    "        'Quantity': 'sum',\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    product_metrics.columns = ['StockCode', 'Description', 'Total_Quantity', \n",
    "                              'Total_Revenue', 'Unique_Orders', 'Unique_Customers']\n",
    "    \n",
    "    # Calcul du prix moyen\n",
    "    product_metrics['Avg_Price'] = product_metrics['Total_Revenue'] / product_metrics['Total_Quantity']\n",
    "    \n",
    "    # Tri par revenus\n",
    "    product_metrics = product_metrics.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸ“Š Produits uniques: {len(product_metrics):,}\")\n",
    "    print(f\"ğŸ’° Revenus totaux: ${product_metrics['Total_Revenue'].sum():,.2f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ† TOP 10 PRODUITS (Revenus) :\")\n",
    "    top_products = product_metrics.head(10)\n",
    "    for idx, row in top_products.iterrows():\n",
    "        desc = row['Description'][:50] + '...' if pd.notna(row['Description']) and len(str(row['Description'])) > 50 else row['Description']\n",
    "        print(f\"  {row['StockCode']}: ${row['Total_Revenue']:,.2f} | {desc}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¥ TOP 10 PRODUITS (QuantitÃ©) :\")\n",
    "    top_qty = product_metrics.nlargest(10, 'Total_Quantity')\n",
    "    for idx, row in top_qty.iterrows():\n",
    "        desc = row['Description'][:50] + '...' if pd.notna(row['Description']) and len(str(row['Description'])) > 50 else row['Description']\n",
    "        print(f\"  {row['StockCode']}: {row['Total_Quantity']:,} unitÃ©s | {desc}\")\n",
    "    \n",
    "    return product_metrics\n",
    "\n",
    "# ExÃ©cution de l'analyse produit\n",
    "product_data = analyze_product_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ ANALYSE GÃ‰OGRAPHIQUE\n",
      "=========================\n",
      "ğŸŒ Pays actifs: 43\n",
      "ğŸ† Top pays: United Kingdom\n",
      "\n",
      "ğŸ’° TOP 10 PAYS (Revenus) :\n",
      "  United Kingdom: $17,378,389.04 (85.0%)\n",
      "  EIRE: $659,371.21 (3.2%)\n",
      "  Netherlands: $554,038.09 (2.7%)\n",
      "  Germany: $425,019.71 (2.1%)\n",
      "  France: $350,456.09 (1.7%)\n",
      "  Australia: $169,283.46 (0.8%)\n",
      "  Spain: $108,332.49 (0.5%)\n",
      "  Switzerland: $100,707.89 (0.5%)\n",
      "  Sweden: $91,869.82 (0.4%)\n",
      "  Denmark: $68,580.69 (0.3%)\n",
      "\n",
      "ğŸ‘¥ TOP 10 PAYS (Clients) :\n",
      "  United Kingdom: 244,737 clients\n",
      "  EIRE: 1,614 clients\n",
      "  Hong Kong: 358 clients\n",
      "  Unspecified: 237 clients\n",
      "  France: 223 clients\n",
      "  Switzerland: 147 clients\n",
      "  Portugal: 140 clients\n",
      "  Germany: 107 clients\n",
      "  United Arab Emirates: 88 clients\n",
      "  Bahrain: 67 clients\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸŒ ANALYSE GÃ‰OGRAPHIQUE\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_geographic_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse des performances par pays\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸŒ ANALYSE GÃ‰OGRAPHIQUE\")\n",
    "    \n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    sales_data = df[df['Transaction_Type'] == 'SALE'].copy()\n",
    "    \n",
    "    # MÃ©triques par pays\n",
    "    country_metrics = sales_data.groupby('Country').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    country_metrics.columns = ['Country', 'Total_Revenue', 'Total_Orders', 'Unique_Customers', 'Items_Sold']\n",
    "    \n",
    "    # Calculs additionnels\n",
    "    country_metrics['Avg_Order_Value'] = country_metrics['Total_Revenue'] / country_metrics['Total_Orders']\n",
    "    country_metrics['Revenue_per_Customer'] = country_metrics['Total_Revenue'] / country_metrics['Unique_Customers']\n",
    "    \n",
    "    # Tri par revenus\n",
    "    country_metrics = country_metrics.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸŒ Pays actifs: {len(country_metrics)}\")\n",
    "    print(f\"ğŸ† Top pays: {country_metrics.iloc[0]['Country']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’° TOP 10 PAYS (Revenus) :\")\n",
    "    top_countries = country_metrics.head(10)\n",
    "    for idx, row in top_countries.iterrows():\n",
    "        pct = (row['Total_Revenue'] / country_metrics['Total_Revenue'].sum()) * 100\n",
    "        print(f\"  {row['Country']}: ${row['Total_Revenue']:,.2f} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ‘¥ TOP 10 PAYS (Clients) :\")\n",
    "    top_customers_countries = country_metrics.nlargest(10, 'Unique_Customers')\n",
    "    for idx, row in top_customers_countries.iterrows():\n",
    "        print(f\"  {row['Country']}: {row['Unique_Customers']:,} clients\")\n",
    "    \n",
    "    return country_metrics\n",
    "\n",
    "# ExÃ©cution de l'analyse gÃ©ographique\n",
    "geographic_data = analyze_geographic_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a522e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CRÃ‰ATION DU DASHBOARD BUSINESS\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ“ˆ VISUALISATIONS INTERACTIVES - PERFORMANCES BUSINESS\n",
    "# ============================================================================\n",
    "\n",
    "def create_business_dashboard(df):\n",
    "    \"\"\"\n",
    "    Dashboard interactif des performances business\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š CRÃ‰ATION DU DASHBOARD BUSINESS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # PrÃ©paration des donnÃ©es pour les graphiques\n",
    "    monthly_sales = df.groupby(df['InvoiceDate'].dt.to_period('M')).agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    monthly_sales['InvoiceDate'] = monthly_sales['InvoiceDate'].dt.to_timestamp()\n",
    "    \n",
    "    # 1. GRAPHIQUE 1 : Ã‰volution mensuelle des ventes\n",
    "    fig1 = go.Figure()\n",
    "    \n",
    "    fig1.add_trace(go.Scatter(\n",
    "        x=monthly_sales['InvoiceDate'],\n",
    "        y=monthly_sales['Total_Amount'],\n",
    "        mode='lines+markers',\n",
    "        name='Revenus Mensuels',\n",
    "        line=dict(color='#1f77b4', width=3),\n",
    "        marker=dict(size=8)\n",
    "    ))\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='ğŸ“ˆ Ã‰VOLUTION DES REVENUS MENSUELS',\n",
    "        xaxis_title='Mois',\n",
    "        yaxis_title='Revenus ( $ )',\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "    # 2. GRAPHIQUE 2 : Top 10 pays par revenus\n",
    "    top_countries = df.groupby('Country')['Total_Amount'].sum().nlargest(10).reset_index()\n",
    "    \n",
    "    fig2 = px.bar(\n",
    "        top_countries,\n",
    "        x='Total_Amount',\n",
    "        y='Country',\n",
    "        orientation='h',\n",
    "        title='ğŸŒ TOP 10 PAYS PAR REVENUS',\n",
    "        labels={'Total_Amount': 'Revenus ( $ )', 'Country': 'Pays'}\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        yaxis={'categoryorder': 'total ascending'}\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # 3. GRAPHIQUE 3 : Heatmap des ventes par jour/heure\n",
    "    sales_heatmap = df.pivot_table(\n",
    "        values='Total_Amount',\n",
    "        index=df['InvoiceDate'].dt.day_name(),\n",
    "        columns=df['InvoiceDate'].dt.hour,\n",
    "        aggfunc='sum'\n",
    "    )\n",
    "    \n",
    "    # RÃ©organiser les jours de la semaine\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    sales_heatmap = sales_heatmap.reindex(day_order)\n",
    "    \n",
    "    fig3 = px.imshow(\n",
    "        sales_heatmap,\n",
    "        title='ğŸ• HEATMAP VENTES PAR JOUR/HEURE',\n",
    "        labels=dict(x=\"Heure\", y=\"Jour\", color=\"Revenus ($)\"),\n",
    "        aspect=\"auto\"\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    return fig1, fig2, fig3\n",
    "\n",
    "# CrÃ©ation du dashboard\n",
    "dashboard_figs = create_business_dashboard(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bc63790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¥ ANALYSE COMPORTEMENT CLIENT\n",
      "===================================\n",
      "ğŸ’° SEGMENTATION PAR REVENUS :\n",
      "  ğŸ† Bronze: 233,022 clients | $2,084,122.37 total | $8.94 moy/client | $8.91 moy/commande\n",
      "  ğŸ† Silver: 4,710 clients | $1,078,279.34 total | $228.93 moy/client | $128.32 moy/commande\n",
      "  ğŸ† Gold: 1,437 clients | $1,029,402.00 total | $716.35 moy/client | $176.66 moy/commande\n",
      "  ğŸ† Platinum: 2,796 clients | $15,420,363.29 total | $5515.15 moy/client | $166.87 moy/commande\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ¯ ANALYSE DES PATTERNS DE COMPORTEMENT CLIENT\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_customer_behavior(df):\n",
    "    \"\"\"\n",
    "    Analyse approfondie du comportement client\n",
    "    \"\"\"\n",
    "    print(\"ğŸ‘¥ ANALYSE COMPORTEMENT CLIENT\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # MÃ©triques par client\n",
    "    customer_metrics = df.groupby('Customer ID').agg({\n",
    "        'Total_Amount': ['sum', 'mean', 'count'],\n",
    "        'Quantity': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'InvoiceDate': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Aplatir les colonnes\n",
    "    customer_metrics.columns = ['Customer_ID', 'Total_Revenue', 'Avg_Order_Value', \n",
    "                               'Total_Orders', 'Total_Items', 'Unique_Invoices', \n",
    "                               'First_Purchase', 'Last_Purchase']\n",
    "    \n",
    "    # Calculs additionnels\n",
    "    customer_metrics['Customer_Lifetime_Days'] = (\n",
    "        customer_metrics['Last_Purchase'] - customer_metrics['First_Purchase']\n",
    "    ).dt.days\n",
    "    \n",
    "    customer_metrics['Recency_Days'] = (\n",
    "        df['InvoiceDate'].max() - customer_metrics['Last_Purchase']\n",
    "    ).dt.days\n",
    "    \n",
    "    # Segmentation simple\n",
    "    customer_metrics['Revenue_Segment'] = pd.cut(\n",
    "        customer_metrics['Total_Revenue'],\n",
    "        bins=[0, 100, 500, 1000, float('inf')],\n",
    "        labels=['Bronze', 'Silver', 'Gold', 'Platinum']\n",
    "    )\n",
    "    \n",
    "    # Statistiques par segment\n",
    "    print(\"ğŸ’° SEGMENTATION PAR REVENUS :\")\n",
    "    segment_stats = customer_metrics.groupby('Revenue_Segment').agg({\n",
    "        'Total_Revenue': ['count', 'sum', 'mean'],\n",
    "        'Avg_Order_Value': 'mean',\n",
    "        'Total_Orders': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    for segment in ['Bronze', 'Silver', 'Gold', 'Platinum']:\n",
    "        if segment in segment_stats.index:\n",
    "            count = segment_stats.loc[segment, ('Total_Revenue', 'count')]\n",
    "            revenue = segment_stats.loc[segment, ('Total_Revenue', 'sum')]\n",
    "            avg_revenue = segment_stats.loc[segment, ('Total_Revenue', 'mean')]\n",
    "            avg_order = segment_stats.loc[segment, ('Avg_Order_Value', 'mean')]\n",
    "            \n",
    "            print(f\"  ğŸ† {segment}: {count:,} clients | \"\n",
    "                  f\"${revenue:,.2f} total | \"\n",
    "                  f\"${avg_revenue:.2f} moy/client | \"\n",
    "                  f\"${avg_order:.2f} moy/commande\")\n",
    "    \n",
    "    # Graphique de distribution\n",
    "    fig4 = px.histogram(\n",
    "        customer_metrics,\n",
    "        x='Total_Revenue',\n",
    "        nbins=50,\n",
    "        title='ğŸ“Š DISTRIBUTION DES REVENUS PAR CLIENT',\n",
    "        labels={'Total_Revenue': 'Revenus par Client ($)', 'count': 'Nombre de Clients'}\n",
    "    )\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    return customer_metrics, fig4\n",
    "\n",
    "# Analyse comportement client\n",
    "customer_data, customer_fig = analyze_customer_behavior(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f18d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ANALYSE PERFORMANCE PRODUITS\n",
      "===================================\n",
      "ğŸ† TOP 10 PRODUITS (Revenus) :\n",
      "  ğŸ“¦ DOT: $322,647.47 | 1429 clients | $225.79/client\n",
      "      ğŸ“ DOTCOM POSTAGE...\n",
      "  ğŸ“¦ 22423: $319,187.90 | 1951 clients | $163.60/client\n",
      "      ğŸ“ REGENCY CAKESTAND 3 TIER...\n",
      "  ğŸ“¦ 85123A: $248,519.61 | 1996 clients | $124.51/client\n",
      "      ğŸ“ WHITE HANGING HEART T-LIGHT HOLDER...\n",
      "  ğŸ“¦ 47566: $147,351.65 | 1515 clients | $97.26/client\n",
      "      ğŸ“ PARTY BUNTING...\n",
      "  ğŸ“¦ 85099B: $144,023.86 | 1529 clients | $94.19/client\n",
      "      ğŸ“ JUMBO BAG RED RETROSPOT...\n",
      "  ğŸ“¦ 84879: $128,691.54 | 1176 clients | $109.43/client\n",
      "      ğŸ“ ASSORTED COLOUR BIRD ORNAMENT...\n",
      "  ğŸ“¦ 22086: $118,683.69 | 1243 clients | $95.48/client\n",
      "      ğŸ“ PAPER CHAIN KIT 50'S CHRISTMAS ...\n",
      "  ğŸ“¦ POST: $110,430.41 | 592 clients | $186.54/client\n",
      "      ğŸ“ POSTAGE...\n",
      "  ğŸ“¦ 79321: $81,078.32 | 537 clients | $150.98/client\n",
      "      ğŸ“ CHILLI LIGHTS...\n",
      "  ğŸ“¦ 84347: $72,196.52 | 550 clients | $131.27/client\n",
      "      ğŸ“ ROTATING SILVER ANGELS T-LIGHT HLDR...\n",
      "\n",
      "ğŸ‘¥ TOP 10 PRODUITS (PopularitÃ©) :\n",
      "  ğŸ“¦ 85123A: 1996 clients | $248,519.61 revenus\n",
      "      ğŸ“ WHITE HANGING HEART T-LIGHT HOLDER...\n",
      "  ğŸ“¦ 22423: 1951 clients | $319,187.90 revenus\n",
      "      ğŸ“ REGENCY CAKESTAND 3 TIER...\n",
      "  ğŸ“¦ 85099B: 1529 clients | $144,023.86 revenus\n",
      "      ğŸ“ JUMBO BAG RED RETROSPOT...\n",
      "  ğŸ“¦ 47566: 1515 clients | $147,351.65 revenus\n",
      "      ğŸ“ PARTY BUNTING...\n",
      "  ğŸ“¦ DOT: 1429 clients | $322,647.47 revenus\n",
      "      ğŸ“ DOTCOM POSTAGE...\n",
      "  ğŸ“¦ 22138: 1326 clients | $41,829.06 revenus\n",
      "      ğŸ“ BAKING SET 9 PIECE RETROSPOT ...\n",
      "  ğŸ“¦ 22457: 1300 clients | $47,427.35 revenus\n",
      "      ğŸ“ NATURAL SLATE HEART CHALKBOARD ...\n",
      "  ğŸ“¦ 22469: 1286 clients | $48,998.70 revenus\n",
      "      ğŸ“ HEART OF WICKER SMALL...\n",
      "  ğŸ“¦ 22086: 1243 clients | $118,683.69 revenus\n",
      "      ğŸ“ PAPER CHAIN KIT 50'S CHRISTMAS ...\n",
      "  ğŸ“¦ 21790: 1213 clients | $23,431.48 revenus\n",
      "      ğŸ“ VINTAGE SNAP CARDS...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ† ANALYSE DES PRODUITS PERFORMANTS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_product_performance(df):\n",
    "    \"\"\"\n",
    "    Analyse dÃ©taillÃ©e des performances produits\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¦ ANALYSE PERFORMANCE PRODUITS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # MÃ©triques par produit\n",
    "    product_metrics = df.groupby(['StockCode', 'Description']).agg({\n",
    "        'Total_Amount': ['sum', 'mean'],\n",
    "        'Quantity': ['sum', 'mean'],\n",
    "        'Customer ID': 'nunique',\n",
    "        'Invoice': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Aplatir les colonnes\n",
    "    product_metrics.columns = ['StockCode', 'Description', 'Total_Revenue', \n",
    "                              'Avg_Revenue_per_Sale', 'Total_Quantity', \n",
    "                              'Avg_Quantity_per_Sale', 'Unique_Customers', \n",
    "                              'Unique_Orders']\n",
    "    \n",
    "    # Calculs additionnels\n",
    "    product_metrics['Revenue_per_Customer'] = (\n",
    "        product_metrics['Total_Revenue'] / product_metrics['Unique_Customers']\n",
    "    )\n",
    "    \n",
    "    product_metrics['Repeat_Purchase_Rate'] = (\n",
    "        product_metrics['Unique_Orders'] / product_metrics['Unique_Customers']\n",
    "    )\n",
    "    \n",
    "    # Tri par revenus\n",
    "    product_metrics = product_metrics.sort_values('Total_Revenue', ascending=False)\n",
    "    \n",
    "    print(\"ğŸ† TOP 10 PRODUITS (Revenus) :\")\n",
    "    top_products = product_metrics.head(10)\n",
    "    for idx, row in top_products.iterrows():\n",
    "        print(f\"  ğŸ“¦ {row['StockCode']}: ${row['Total_Revenue']:,.2f} | \"\n",
    "              f\"{row['Unique_Customers']} clients | \"\n",
    "              f\"${row['Revenue_per_Customer']:.2f}/client\")\n",
    "        print(f\"      ğŸ“ {row['Description'][:50]}...\")\n",
    "    \n",
    "    print(f\"\\nğŸ‘¥ TOP 10 PRODUITS (PopularitÃ©) :\")\n",
    "    popular_products = product_metrics.nlargest(10, 'Unique_Customers')\n",
    "    for idx, row in popular_products.iterrows():\n",
    "        print(f\"  ğŸ“¦ {row['StockCode']}: {row['Unique_Customers']} clients | \"\n",
    "              f\"${row['Total_Revenue']:,.2f} revenus\")\n",
    "        print(f\"      ğŸ“ {row['Description'][:50]}...\")\n",
    "    \n",
    "    # Graphique de corrÃ©lation\n",
    "    fig5 = px.scatter(\n",
    "        product_metrics.head(100),  # Top 100 pour lisibilitÃ©\n",
    "        x='Unique_Customers',\n",
    "        y='Total_Revenue',\n",
    "        size='Total_Quantity',\n",
    "        hover_data=['StockCode', 'Description'],\n",
    "        title='ğŸ“Š CORRÃ‰LATION POPULARITÃ‰ vs REVENUS (Top 100)',\n",
    "        labels={'Unique_Customers': 'Nombre de Clients', 'Total_Revenue': 'Revenus ($)'}\n",
    "    )\n",
    "    \n",
    "    fig5.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig5.show()\n",
    "    \n",
    "    return product_metrics, fig5\n",
    "\n",
    "# Analyse performance produits\n",
    "product_data, product_fig = analyze_product_performance(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be5df858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“… ANALYSE SAISONNALITÃ‰ COMPLÃˆTE\n",
      "========================================\n",
      "ğŸ“Š RÃ‰SUMÃ‰ MENSUEL :\n",
      "   Year  Month MonthName  Total_Amount_sum  Total_Amount_mean  \\\n",
      "0  2009     12  December         796700.16              17.81   \n",
      "1  2010      1   January         622516.50              19.93   \n",
      "2  2010      2  February         531288.27              18.28   \n",
      "3  2010      3     March         763271.59              18.62   \n",
      "4  2010      4     April         587953.24              17.47   \n",
      "\n",
      "   Total_Amount_count  Invoice_nunique  Customer ID_nunique  Quantity_sum  \\\n",
      "0               44744             2330                14513        418597   \n",
      "1               31238             1633                 9902        374524   \n",
      "2               29060             1969                 6289        367503   \n",
      "3               40989             2367                 9508        488021   \n",
      "4               33653             1892                 7222        350533   \n",
      "\n",
      "   Revenue_per_Order  Revenue_per_Customer  \n",
      "0             341.93                 54.90  \n",
      "1             381.21                 62.87  \n",
      "2             269.83                 84.48  \n",
      "3             322.46                 80.28  \n",
      "4             310.76                 81.41  \n",
      "\n",
      "ğŸ“ˆ ANALYSE TRIMESTRIELLE :\n",
      "   Year  Quarter  Total_Amount  Invoice  Customer ID Quarter_Label  \\\n",
      "0  2009        4     796700.16     2330        14513       Q4 2009   \n",
      "1  2010        1    1917076.36     5969        24861       Q1 2010   \n",
      "2  2010        2    1878336.16     6526        22088       Q2 2010   \n",
      "3  2010        3    2079252.31     6269        20805       Q3 2010   \n",
      "4  2010        4    3278090.79     8659        51142       Q4 2010   \n",
      "5  2011        1    1737587.03     4852        31317       Q1 2011   \n",
      "6  2011        2    1904448.52     5918        25902       Q2 2011   \n",
      "7  2011        3    2379168.03     5991        31238       Q3 2011   \n",
      "8  2011        4    2958290.10     7114        39625       Q4 2011   \n",
      "\n",
      "   Revenue_Growth  \n",
      "0             NaN  \n",
      "1          140.63  \n",
      "2           -2.02  \n",
      "3           10.70  \n",
      "4           57.66  \n",
      "5          -46.99  \n",
      "6            9.60  \n",
      "7           24.93  \n",
      "8           24.34  \n",
      "\n",
      "ğŸ“… PATTERN HEBDOMADAIRE :\n",
      "   DayOfWeek    DayName  Total_Revenue  Avg_Revenue  Total_Orders  \\\n",
      "0          0     Monday     3296905.28        17.76          8595   \n",
      "1          1    Tuesday     3716240.02        19.17         10299   \n",
      "2          2  Wednesday     3297215.33        18.40          9597   \n",
      "3          3   Thursday     3902396.78        19.77         11335   \n",
      "4          4     Friday     2927237.07        19.33          8505   \n",
      "5          5   Saturday        9803.05        24.39            32   \n",
      "6          6     Sunday     1779151.93        13.37          5265   \n",
      "\n",
      "   Unique_Customers  \n",
      "0             60606  \n",
      "1             58845  \n",
      "2             48155  \n",
      "3             40115  \n",
      "4             48104  \n",
      "5                28  \n",
      "6              3993  \n",
      "\n",
      "ğŸ• PATTERN HORAIRE :\n",
      "Top 5 heures de pointe :\n",
      "   Hour  Total_Revenue  Total_Orders\n",
      "6    12     2669525.49          8098\n",
      "4    10     2416921.68          6030\n",
      "7    13     2338014.41          7163\n",
      "5    11     2318310.15          6628\n",
      "8    14     2218191.00          6519\n",
      "\n",
      "ğŸ¯ INSIGHTS SAISONNIERS CLÃ‰S :\n",
      "==============================\n",
      "ğŸ“ˆ MEILLEUR MOIS : November 2011\n",
      "   ğŸ’° Revenus: $1,456,163.58\n",
      "   ğŸ“¦ Commandes: 3462\n",
      "   ğŸ‘¥ Clients: 20824\n",
      "\n",
      "ğŸ“‰ MOIS LE PLUS FAIBLE : December 2011\n",
      "   ğŸ’° Revenus: $432,719.06\n",
      "   ğŸ“¦ Commandes: 1015\n",
      "\n",
      "ğŸ“ˆ MEILLEUR JOUR : Thursday\n",
      "   ğŸ’° Revenus moyens: $3,902,396.78\n",
      "   ğŸ“¦ Commandes: 11335\n",
      "\n",
      "ğŸ“‰ JOUR LE PLUS FAIBLE : Saturday\n",
      "   ğŸ’° Revenus moyens: $9,803.05\n",
      "\n",
      "ğŸ• HEURE DE POINTE : 12.0h\n",
      "   ğŸ’° Revenus: $2,669,525.49\n",
      "   ğŸ“¦ Commandes: 8098.0\n",
      "\n",
      "ğŸ• HEURE CREUSE : 6.0h\n",
      "   ğŸ’° Revenus: $-497.35\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ“… ANALYSE SAISONNALITÃ‰ DÃ‰TAILLÃ‰E - NOTEBOOK 3\n",
    "# ============================================================================\n",
    "\n",
    "def seasonal_analysis_complete(df):\n",
    "    \"\"\"\n",
    "    Analyse complÃ¨te des patterns saisonniers\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“… ANALYSE SAISONNALITÃ‰ COMPLÃˆTE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # PrÃ©paration des donnÃ©es temporelles\n",
    "    df['Year'] = df['InvoiceDate'].dt.year\n",
    "    df['Month'] = df['InvoiceDate'].dt.month\n",
    "    df['MonthName'] = df['InvoiceDate'].dt.month_name()\n",
    "    df['Quarter'] = df['InvoiceDate'].dt.quarter\n",
    "    df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
    "    df['DayName'] = df['InvoiceDate'].dt.day_name()\n",
    "    df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "    df['Week'] = df['InvoiceDate'].dt.isocalendar().week\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 1. ANALYSE MENSUELLE DÃ‰TAILLÃ‰E\n",
    "    # =======================================================================\n",
    "    \n",
    "    monthly_summary = df.groupby(['Year', 'Month', 'MonthName']).agg({\n",
    "        'Total_Amount': ['sum', 'mean', 'count'],\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique',\n",
    "        'Quantity': 'sum'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    monthly_summary.columns = ['_'.join(col).strip() for col in monthly_summary.columns]\n",
    "    monthly_summary = monthly_summary.reset_index()\n",
    "    \n",
    "    # Calcul des mÃ©triques business\n",
    "    monthly_summary['Revenue_per_Order'] = (\n",
    "        monthly_summary['Total_Amount_sum'] / monthly_summary['Invoice_nunique']\n",
    "    )\n",
    "    monthly_summary['Revenue_per_Customer'] = (\n",
    "        monthly_summary['Total_Amount_sum'] / monthly_summary['Customer ID_nunique']\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ“Š RÃ‰SUMÃ‰ MENSUEL :\")\n",
    "    print(monthly_summary.head())\n",
    "    \n",
    "    # Graphique 1: Ã‰volution mensuelle multi-mÃ©triques\n",
    "    fig1 = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Revenus Mensuels', 'Nombre de Commandes', \n",
    "                       'Clients Uniques', 'Panier Moyen'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # DonnÃ©es pour graphique\n",
    "    month_data = monthly_summary.groupby('Month').agg({\n",
    "        'Total_Amount_sum': 'mean',\n",
    "        'Invoice_nunique': 'mean',\n",
    "        'Customer ID_nunique': 'mean',\n",
    "        'Revenue_per_Order': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Ajout des traces\n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Total_Amount_sum'],\n",
    "                  mode='lines+markers', name='Revenus', line=dict(color='#1f77b4')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Invoice_nunique'],\n",
    "                  mode='lines+markers', name='Commandes', line=dict(color='#ff7f0e')),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Customer ID_nunique'],\n",
    "                  mode='lines+markers', name='Clients', line=dict(color='#2ca02c')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig1.add_trace(\n",
    "        go.Scatter(x=month_data['Month'], y=month_data['Revenue_per_Order'],\n",
    "                  mode='lines+markers', name='Panier Moyen', line=dict(color='#d62728')),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='ğŸ“… ANALYSE SAISONNALITÃ‰ MENSUELLE',\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 2. ANALYSE TRIMESTRIELLE\n",
    "    # =======================================================================\n",
    "    \n",
    "    quarterly_data = df.groupby(['Year', 'Quarter']).agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calcul croissance trimestrielle\n",
    "    quarterly_data['Quarter_Label'] = 'Q' + quarterly_data['Quarter'].astype(str) + ' ' + quarterly_data['Year'].astype(str)\n",
    "    quarterly_data['Revenue_Growth'] = quarterly_data['Total_Amount'].pct_change() * 100\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ ANALYSE TRIMESTRIELLE :\")\n",
    "    print(quarterly_data)\n",
    "    \n",
    "    # Graphique 2: Performance trimestrielle\n",
    "    fig2 = px.bar(\n",
    "        quarterly_data,\n",
    "        x='Quarter_Label',\n",
    "        y='Total_Amount',\n",
    "        title='ğŸ“Š REVENUS PAR TRIMESTRE',\n",
    "        labels={'Total_Amount': 'Revenus ( $ )', 'Quarter_Label': 'Trimestre'}\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 3. ANALYSE HEBDOMADAIRE\n",
    "    # =======================================================================\n",
    "    \n",
    "    weekly_pattern = df.groupby(['DayOfWeek', 'DayName']).agg({\n",
    "        'Total_Amount': ['sum', 'mean'],\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    weekly_pattern.columns = ['DayOfWeek', 'DayName', 'Total_Revenue', 'Avg_Revenue',\n",
    "                             'Total_Orders', 'Unique_Customers']\n",
    "    \n",
    "    # RÃ©organiser les jours\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekly_pattern['DayName'] = pd.Categorical(weekly_pattern['DayName'], categories=day_order, ordered=True)\n",
    "    weekly_pattern = weekly_pattern.sort_values('DayName')\n",
    "    \n",
    "    print(f\"\\nğŸ“… PATTERN HEBDOMADAIRE :\")\n",
    "    print(weekly_pattern)\n",
    "    \n",
    "    # Graphique 3: Pattern hebdomadaire\n",
    "    fig3 = px.bar(\n",
    "        weekly_pattern,\n",
    "        x='DayName',\n",
    "        y='Total_Revenue',\n",
    "        title='ğŸ“Š PATTERN HEBDOMADAIRE DES VENTES',\n",
    "        labels={'Total_Revenue': 'Revenus ( $ )', 'DayName': 'Jour de la Semaine'}\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 4. ANALYSE HORAIRE\n",
    "    # =======================================================================\n",
    "    \n",
    "    hourly_pattern = df.groupby('Hour').agg({\n",
    "        'Total_Amount': ['sum', 'mean'],\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    hourly_pattern.columns = ['Hour', 'Total_Revenue', 'Avg_Revenue', 'Total_Orders', 'Unique_Customers']\n",
    "    \n",
    "    print(f\"\\nğŸ• PATTERN HORAIRE :\")\n",
    "    peak_hours = hourly_pattern.nlargest(5, 'Total_Revenue')\n",
    "    print(\"Top 5 heures de pointe :\")\n",
    "    print(peak_hours[['Hour', 'Total_Revenue', 'Total_Orders']])\n",
    "    \n",
    "    # Graphique 4: Pattern horaire\n",
    "    fig4 = px.line(\n",
    "        hourly_pattern,\n",
    "        x='Hour',\n",
    "        y='Total_Revenue',\n",
    "        title='ğŸ“Š PATTERN HORAIRE DES VENTES',\n",
    "        labels={'Total_Revenue': 'Revenus ($)', 'Hour': 'Heure'}\n",
    "    )\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 5. INSIGHTS SAISONNIERS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ¯ INSIGHTS SAISONNIERS CLÃ‰S :\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Meilleur mois\n",
    "    best_month = monthly_summary.loc[monthly_summary['Total_Amount_sum'].idxmax()]\n",
    "    worst_month = monthly_summary.loc[monthly_summary['Total_Amount_sum'].idxmin()]\n",
    "    \n",
    "    print(f\"ğŸ“ˆ MEILLEUR MOIS : {best_month['MonthName']} {best_month['Year']}\")\n",
    "    print(f\"   ğŸ’° Revenus: ${best_month['Total_Amount_sum']:,.2f}\")\n",
    "    print(f\"   ğŸ“¦ Commandes: {best_month['Invoice_nunique']}\")\n",
    "    print(f\"   ğŸ‘¥ Clients: {best_month['Customer ID_nunique']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‰ MOIS LE PLUS FAIBLE : {worst_month['MonthName']} {worst_month['Year']}\")\n",
    "    print(f\"   ğŸ’° Revenus: ${worst_month['Total_Amount_sum']:,.2f}\")\n",
    "    print(f\"   ğŸ“¦ Commandes: {worst_month['Invoice_nunique']}\")\n",
    "    \n",
    "    # Meilleur jour\n",
    "    best_day = weekly_pattern.loc[weekly_pattern['Total_Revenue'].idxmax()]\n",
    "    worst_day = weekly_pattern.loc[weekly_pattern['Total_Revenue'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ MEILLEUR JOUR : {best_day['DayName']}\")\n",
    "    print(f\"   ğŸ’° Revenus moyens: ${best_day['Total_Revenue']:,.2f}\")\n",
    "    print(f\"   ğŸ“¦ Commandes: {best_day['Total_Orders']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‰ JOUR LE PLUS FAIBLE : {worst_day['DayName']}\")\n",
    "    print(f\"   ğŸ’° Revenus moyens: ${worst_day['Total_Revenue']:,.2f}\")\n",
    "    \n",
    "    # Heures de pointe\n",
    "    peak_hour = hourly_pattern.loc[hourly_pattern['Total_Revenue'].idxmax()]\n",
    "    low_hour = hourly_pattern.loc[hourly_pattern['Total_Revenue'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nğŸ• HEURE DE POINTE : {peak_hour['Hour']}h\")\n",
    "    print(f\"   ğŸ’° Revenus: ${peak_hour['Total_Revenue']:,.2f}\")\n",
    "    print(f\"   ğŸ“¦ Commandes: {peak_hour['Total_Orders']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ• HEURE CREUSE : {low_hour['Hour']}h\")\n",
    "    print(f\"   ğŸ’° Revenus: ${low_hour['Total_Revenue']:,.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'monthly_summary': monthly_summary,\n",
    "        'quarterly_data': quarterly_data,\n",
    "        'weekly_pattern': weekly_pattern,\n",
    "        'hourly_pattern': hourly_pattern,\n",
    "        'figures': [fig1, fig2, fig3, fig4]\n",
    "    }\n",
    "\n",
    "# ExÃ©cution de l'analyse saisonnalitÃ©\n",
    "seasonal_results = seasonal_analysis_complete(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "250947ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DÃ‰TECTION D'ANOMALIES COMPLÃˆTE\n",
      "========================================\n",
      "ğŸ’° ANALYSE DES ANOMALIES TRANSACTIONNELLES\n",
      "---------------------------------------------\n",
      "ğŸ“Š STATISTIQUES VALEUR COMMANDE :\n",
      "   Moyenne: $352.97\n",
      "   MÃ©diane: $192.34\n",
      "   Ã‰cart-type: $1645.25\n",
      "   Seuil infÃ©rieur: $-592.48\n",
      "   Seuil supÃ©rieur: $987.46\n",
      "   ğŸš¨ Anomalies dÃ©tectÃ©es: 3972 commandes\n",
      "\n",
      "ğŸ”¥ TOP 10 COMMANDES ANORMALEMENT Ã‰LEVÃ‰ES :\n",
      "   ğŸ“‹ 581483: $168,469.60 | 80995 items | 1 produits\n",
      "   ğŸ“‹ 541431: $77,183.60 | 74215 items | 1 produits\n",
      "   ğŸ“‹ 574941: $52,940.94 | 14149 items | 101 produits\n",
      "   ğŸ“‹ 576365: $50,653.91 | 13956 items | 99 produits\n",
      "   ğŸ“‹ 533027: $49,844.99 | 13387 items | 111 produits\n",
      "   ğŸ“‹ 531516: $45,332.97 | 12410 items | 115 produits\n",
      "   ğŸ“‹ 493819: $44,051.60 | 25018 items | 94 produits\n",
      "   ğŸ“‹ 556444: $38,970.00 | 60 items | 1 produits\n",
      "   ğŸ“‹ 524181: $33,167.80 | 8820 items | 14 produits\n",
      "   ğŸ“‹ 567423: $31,698.16 | 12572 items | 12 produits\n",
      "\n",
      "ğŸ“¦ ANALYSE DES ANOMALIES PRODUITS\n",
      "----------------------------------------\n",
      "ğŸš¨ PRODUITS AVEC VARIATIONS DE PRIX SUSPECTES : 1170\n",
      "Top 10 variations de prix :\n",
      "   ğŸ“¦ POST: Variation 7.77x | Prix: $0.00 -  $ 8142.75\n",
      "   ğŸ“¦ 17003: Variation 6.83x | Prix: $0.00 -  $ 57.60\n",
      "   ğŸ“¦ BANK CHARGES: Variation 5.18x | Prix: $0.00 -  $ 18910.69\n",
      "   ğŸ“¦ PADS: Variation 4.36x | Prix: $0.00 -  $ 36.60\n",
      "   ğŸ“¦ 84016: Variation 4.05x | Prix: $0.00 -  $ 1157.15\n",
      "   ğŸ“¦ ADJUST: Variation 3.81x | Prix: $4.57 -  $ 5117.03\n",
      "   ğŸ“¦ 22502: Variation 3.70x | Prix: $0.00 -  $ 649.50\n",
      "   ğŸ“¦ M: Variation 3.52x | Prix: $0.00 -  $ 38970.00\n",
      "   ğŸ“¦ 84033: Variation 3.48x | Prix: $0.00 -  $ 85.10\n",
      "   ğŸ“¦ D: Variation 2.82x | Prix: $0.01 -  $ 1867.86\n",
      "\n",
      "ğŸ‘¥ ANALYSE DES ANOMALIES CLIENTS\n",
      "-----------------------------------\n",
      "ğŸš¨ CLIENTS ANORMAUX DÃ‰TECTÃ‰S : 12448\n",
      "Top 10 clients les plus anormaux :\n",
      "   ğŸ‘¤ Client 18102:  $ 570,380.61 | 153 commandes | Score: -0.352\n",
      "   ğŸ‘¤ Client 14646:  $ 523,342.07 | 164 commandes | Score: -0.346\n",
      "   ğŸ‘¤ Client 13694:  $ 190,020.84 | 164 commandes | Score: -0.346\n",
      "   ğŸ‘¤ Client 12415:  $ 143,269.29 | 33 commandes | Score: -0.346\n",
      "   ğŸ‘¤ Client 17511:  $ 168,491.62 | 85 commandes | Score: -0.345\n",
      "   ğŸ‘¤ Client 14156:  $ 296,063.44 | 202 commandes | Score: -0.345\n",
      "   ğŸ‘¤ Client 14298:  $ 90,489.31 | 84 commandes | Score: -0.343\n",
      "   ğŸ‘¤ Client 16684:  $ 141,502.25 | 65 commandes | Score: -0.343\n",
      "   ğŸ‘¤ Client 14088:  $ 62,400.02 | 20 commandes | Score: -0.343\n",
      "   ğŸ‘¤ Client 17450:  $ 231,390.55 | 61 commandes | Score: -0.342\n",
      "\n",
      "â° ANALYSE DES ANOMALIES TEMPORELLES\n",
      "----------------------------------------\n",
      "ğŸš¨ JOURS AVEC ACTIVITÃ‰ ANORMALE : 55\n",
      "Top 10 jours anormaux :\n",
      "   ğŸ“… 2011-11-14:  $ 111,958.62 | 152 commandes | Z-score: 4.74\n",
      "   ğŸ“… 2011-09-20:  $ 109,228.08 | 77 commandes | Z-score: 4.58\n",
      "   ğŸ“… 2010-11-15:  $ 104,708.97 | 133 commandes | Z-score: 4.31\n",
      "   ğŸ“… 2010-09-27:  $ 97,804.70 | 111 commandes | Z-score: 3.91\n",
      "   ğŸ“… 2010-11-04:  $ 88,267.65 | 219 commandes | Z-score: 3.35\n",
      "   ğŸ“… 2010-10-14:  $ 85,969.18 | 122 commandes | Z-score: 3.21\n",
      "   ğŸ“… 2010-04-29:  $ -22,350.96 | 106 commandes | Z-score: 3.16\n",
      "   ğŸ“… 2010-11-08:  $ 83,662.44 | 124 commandes | Z-score: 3.08\n",
      "   ğŸ“… 2011-12-08:  $ 81,294.33 | 145 commandes | Z-score: 2.94\n",
      "   ğŸ“… 2010-11-10:  $ 79,469.50 | 152 commandes | Z-score: 2.83\n",
      "\n",
      "ğŸ¯ RÃ‰SUMÃ‰ DÃ‰TECTION D'ANOMALIES\n",
      "===================================\n",
      "ğŸ“Š TRANSACTIONS ANORMALES : 3972 commandes\n",
      "ğŸ“¦ PRODUITS SUSPECTS : 1170 produits\n",
      "ğŸ‘¥ CLIENTS ANORMAUX : 12448 clients\n",
      "â° JOURS ANORMAUX : 55 jours\n",
      "\n",
      "ğŸ“ˆ POURCENTAGES D'ANOMALIES :\n",
      "   Transactions: 7.4%\n",
      "   Produits: 22.1%\n",
      "   Clients: 5.0%\n",
      "   Jours: 9.1%\n",
      "\n",
      "ğŸ’¡ RECOMMANDATIONS :\n",
      "ğŸ” ACTIONS IMMÃ‰DIATES :\n",
      "   â€¢ VÃ©rifier les commandes > $10,000\n",
      "   â€¢ Investiguer les variations de prix > 100%\n",
      "   â€¢ Analyser les clients avec score anomalie < -0.5\n",
      "   â€¢ Examiner les pics de ventes inexpliquÃ©s\n",
      "ğŸ›¡ï¸ MESURES PRÃ‰VENTIVES :\n",
      "   â€¢ Alertes automatiques pour commandes > seuil\n",
      "   â€¢ Validation manuelle pour variations prix > 50%\n",
      "   â€¢ Monitoring comportement clients VIP\n",
      "   â€¢ SystÃ¨me de dÃ©tection temps rÃ©el\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ” DÃ‰TECTION D'ANOMALIES - NOTEBOOK 3\n",
    "# ============================================================================\n",
    "\n",
    "def detect_anomalies_complete(df):\n",
    "    \"\"\"\n",
    "    DÃ©tection complÃ¨te des anomalies dans les donnÃ©es e-commerce\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” DÃ‰TECTION D'ANOMALIES COMPLÃˆTE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Imports pour dÃ©tection d'anomalies\n",
    "    from scipy import stats\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import numpy as np\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 1. DÃ‰TECTION ANOMALIES TRANSACTIONS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(\"ğŸ’° ANALYSE DES ANOMALIES TRANSACTIONNELLES\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    transaction_stats = df.groupby('Invoice').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Quantity': 'sum',\n",
    "        'StockCode': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    transaction_stats.columns = ['Invoice', 'Total_Order_Value', 'Total_Items', 'Unique_Products']\n",
    "    \n",
    "    # Calcul des seuils d'anomalie (mÃ©thode IQR)\n",
    "    def detect_outliers_iqr(data, column):\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "        return outliers, lower_bound, upper_bound\n",
    "    \n",
    "    # DÃ©tection anomalies valeur commande\n",
    "    order_anomalies, lower_order, upper_order = detect_outliers_iqr(\n",
    "        transaction_stats, 'Total_Order_Value'\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“Š STATISTIQUES VALEUR COMMANDE :\")\n",
    "    print(f\"   Moyenne: ${transaction_stats['Total_Order_Value'].mean():.2f}\")\n",
    "    print(f\"   MÃ©diane: ${transaction_stats['Total_Order_Value'].median():.2f}\")\n",
    "    print(f\"   Ã‰cart-type: ${transaction_stats['Total_Order_Value'].std():.2f}\")\n",
    "    print(f\"   Seuil infÃ©rieur: ${lower_order:.2f}\")\n",
    "    print(f\"   Seuil supÃ©rieur: ${upper_order:.2f}\")\n",
    "    print(f\"   ğŸš¨ Anomalies dÃ©tectÃ©es: {len(order_anomalies)} commandes\")\n",
    "    \n",
    "    # Top anomalies par valeur\n",
    "    print(f\"\\nğŸ”¥ TOP 10 COMMANDES ANORMALEMENT Ã‰LEVÃ‰ES :\")\n",
    "    top_anomalies = order_anomalies.nlargest(10, 'Total_Order_Value')\n",
    "    for _, row in top_anomalies.iterrows():\n",
    "        print(f\"   ğŸ“‹ {row['Invoice']}: ${row['Total_Order_Value']:,.2f} | \"\n",
    "              f\"{row['Total_Items']} items | {row['Unique_Products']} produits\")\n",
    "    \n",
    "    # Graphique 1: Distribution avec anomalies\n",
    "    fig1 = go.Figure()\n",
    "    \n",
    "    # Histogramme normal\n",
    "    fig1.add_trace(go.Histogram(\n",
    "        x=transaction_stats['Total_Order_Value'],\n",
    "        nbinsx=50,\n",
    "        name='Commandes normales',\n",
    "        opacity=0.7\n",
    "    ))\n",
    "    \n",
    "    # Ligne seuil supÃ©rieur\n",
    "    fig1.add_vline(\n",
    "        x=upper_order,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        annotation_text=f\"Seuil anomalie:  $ {upper_order:.0f}\"\n",
    "    )\n",
    "    \n",
    "    fig1.update_layout(\n",
    "        title='ğŸ“Š DISTRIBUTION VALEUR COMMANDES + SEUIL ANOMALIES',\n",
    "        xaxis_title='Valeur Commande ( $ )',\n",
    "        yaxis_title='FrÃ©quence',\n",
    "        template='plotly_white',\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    fig1.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 2. DÃ‰TECTION ANOMALIES PRODUITS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“¦ ANALYSE DES ANOMALIES PRODUITS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Analyse par produit\n",
    "    product_anomalies = df.groupby('StockCode').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Quantity': 'sum',\n",
    "        'Price': ['mean', 'std', 'min', 'max'],\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten columns\n",
    "    product_anomalies.columns = ['StockCode', 'Total_Revenue', 'Total_Quantity', \n",
    "                                'Avg_Price', 'Price_Std', 'Min_Price', 'Max_Price', 'Unique_Customers']\n",
    "    \n",
    "    # DÃ©tection prix anormaux\n",
    "    product_anomalies['Price_Variation'] = product_anomalies['Price_Std'] / product_anomalies['Avg_Price']\n",
    "    product_anomalies['Price_Range'] = product_anomalies['Max_Price'] - product_anomalies['Min_Price']\n",
    "    \n",
    "    # Produits avec variations de prix suspectes\n",
    "    price_anomalies = product_anomalies[\n",
    "        (product_anomalies['Price_Variation'] > 1.0) |  # Variation > 100%\n",
    "        (product_anomalies['Price_Range'] > product_anomalies['Avg_Price'] * 2)  # Range > 200% du prix moyen\n",
    "    ].sort_values('Price_Variation', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸš¨ PRODUITS AVEC VARIATIONS DE PRIX SUSPECTES : {len(price_anomalies)}\")\n",
    "    print(\"Top 10 variations de prix :\")\n",
    "    for _, row in price_anomalies.head(10).iterrows():\n",
    "        print(f\"   ğŸ“¦ {row['StockCode']}: Variation {row['Price_Variation']:.2f}x | \"\n",
    "              f\"Prix: ${row['Min_Price']:.2f} -  $ {row['Max_Price']:.2f}\")\n",
    "    \n",
    "    # Graphique 2: Scatter plot prix vs quantitÃ©\n",
    "    product_anomalies['Total_Revenue_Abs'] = product_anomalies['Total_Revenue'].abs()\n",
    "    fig2 = px.scatter(\n",
    "        product_anomalies.head(1000),  # Top 1000 pour lisibilitÃ©\n",
    "        x='Avg_Price',\n",
    "        y='Total_Quantity',\n",
    "        size='Total_Revenue_Abs',\n",
    "        color='Price_Variation',\n",
    "        hover_data=['StockCode'],\n",
    "        title='ğŸ“Š DÃ‰TECTION ANOMALIES PRODUITS : PRIX vs QUANTITÃ‰',\n",
    "        labels={'Avg_Price': 'Prix Moyen ( $ )', 'Total_Quantity': 'QuantitÃ© Totale'},\n",
    "        color_continuous_scale='Viridis'\n",
    "    )\n",
    "    \n",
    "    fig2.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig2.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 3. DÃ‰TECTION ANOMALIES CLIENTS\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ‘¥ ANALYSE DES ANOMALIES CLIENTS\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Analyse comportement client\n",
    "    customer_behavior = df.groupby('Customer ID').agg({\n",
    "        'Total_Amount': ['sum', 'mean', 'count'],\n",
    "        'Invoice': 'nunique',\n",
    "        'StockCode': 'nunique',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    customer_behavior.columns = ['Customer_ID', 'Total_Spent', 'Avg_Transaction', \n",
    "                               'Total_Transactions', 'Unique_Orders', 'Unique_Products', 'Total_Items']\n",
    "    \n",
    "    # MÃ©triques clients\n",
    "    customer_behavior['Avg_Items_per_Order'] = customer_behavior['Total_Items'] / customer_behavior['Unique_Orders']\n",
    "    customer_behavior['Avg_Products_per_Order'] = customer_behavior['Unique_Products'] / customer_behavior['Unique_Orders']\n",
    "    \n",
    "    # DÃ©tection clients anormaux avec Isolation Forest\n",
    "    features_for_anomaly = ['Total_Spent', 'Avg_Transaction', 'Total_Transactions', \n",
    "                           'Unique_Products', 'Avg_Items_per_Order']\n",
    "    \n",
    "    # PrÃ©paration des donnÃ©es\n",
    "    X = customer_behavior[features_for_anomaly].fillna(0)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "    customer_behavior['Anomaly'] = iso_forest.fit_predict(X_scaled)\n",
    "    customer_behavior['Anomaly_Score'] = iso_forest.decision_function(X_scaled)\n",
    "    \n",
    "    # Clients anormaux\n",
    "    anomalous_customers = customer_behavior[customer_behavior['Anomaly'] == -1].sort_values('Anomaly_Score')\n",
    "    \n",
    "    print(f\"ğŸš¨ CLIENTS ANORMAUX DÃ‰TECTÃ‰S : {len(anomalous_customers)}\")\n",
    "    print(\"Top 10 clients les plus anormaux :\")\n",
    "    for _, row in anomalous_customers.head(10).iterrows():\n",
    "        print(f\"   ğŸ‘¤ Client {row['Customer_ID']}:  $ {row['Total_Spent']:,.2f} | \"\n",
    "              f\"{row['Unique_Orders']} commandes | Score: {row['Anomaly_Score']:.3f}\")\n",
    "    \n",
    "    # Graphique 3: Visualisation anomalies clients\n",
    "    fig3 = px.scatter(\n",
    "        customer_behavior,\n",
    "        x='Total_Spent',\n",
    "        y='Avg_Transaction',\n",
    "        color='Anomaly',\n",
    "        color_discrete_map={1: 'blue', -1: 'red'},\n",
    "        title='ğŸ“Š DÃ‰TECTION ANOMALIES CLIENTS',\n",
    "        labels={'Total_Spent': 'DÃ©pense Totale ( $ )', 'Avg_Transaction': 'Transaction Moyenne ($)'},\n",
    "        hover_data=['Customer_ID', 'Unique_Orders']\n",
    "    )\n",
    "    \n",
    "    fig3.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig3.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 4. DÃ‰TECTION ANOMALIES TEMPORELLES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nâ° ANALYSE DES ANOMALIES TEMPORELLES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # AgrÃ©gation journaliÃ¨re\n",
    "    daily_sales = df.groupby(df['InvoiceDate'].dt.date).agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique',\n",
    "        'Customer ID': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_sales.columns = ['Date', 'Daily_Revenue', 'Daily_Orders', 'Daily_Customers']\n",
    "    \n",
    "    # Z-score pour dÃ©tection anomalies temporelles\n",
    "    daily_sales['Revenue_ZScore'] = np.abs(stats.zscore(daily_sales['Daily_Revenue']))\n",
    "    daily_sales['Orders_ZScore'] = np.abs(stats.zscore(daily_sales['Daily_Orders']))\n",
    "    \n",
    "    # Jours anormaux (Z-score > 2)\n",
    "    temporal_anomalies = daily_sales[\n",
    "        (daily_sales['Revenue_ZScore'] > 2) | \n",
    "        (daily_sales['Orders_ZScore'] > 2)\n",
    "    ].sort_values('Revenue_ZScore', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸš¨ JOURS AVEC ACTIVITÃ‰ ANORMALE : {len(temporal_anomalies)}\")\n",
    "    print(\"Top 10 jours anormaux :\")\n",
    "    for _, row in temporal_anomalies.head(10).iterrows():\n",
    "        print(f\"   ğŸ“… {row['Date']}:  $ {row['Daily_Revenue']:,.2f} | \"\n",
    "              f\"{row['Daily_Orders']} commandes | Z-score: {row['Revenue_ZScore']:.2f}\")\n",
    "    \n",
    "    # Graphique 4: SÃ©rie temporelle avec anomalies\n",
    "    fig4 = go.Figure()\n",
    "    \n",
    "    # SÃ©rie normale\n",
    "    fig4.add_trace(go.Scatter(\n",
    "        x=daily_sales['Date'],\n",
    "        y=daily_sales['Daily_Revenue'],\n",
    "        mode='lines',\n",
    "        name='Revenus journaliers',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    \n",
    "    # Points anomalies\n",
    "    fig4.add_trace(go.Scatter(\n",
    "        x=temporal_anomalies['Date'],\n",
    "        y=temporal_anomalies['Daily_Revenue'],\n",
    "        mode='markers',\n",
    "        name='Anomalies',\n",
    "        marker=dict(color='red', size=8),\n",
    "    ))\n",
    "    \n",
    "    fig4.update_layout(\n",
    "        title='ğŸ“Š DÃ‰TECTION ANOMALIES TEMPORELLES',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Revenus Journaliers ( $ )',\n",
    "        template='plotly_white',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    fig4.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 5. RÃ‰SUMÃ‰ ANOMALIES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ¯ RÃ‰SUMÃ‰ DÃ‰TECTION D'ANOMALIES\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"ğŸ“Š TRANSACTIONS ANORMALES : {len(order_anomalies)} commandes\")\n",
    "    print(f\"ğŸ“¦ PRODUITS SUSPECTS : {len(price_anomalies)} produits\")\n",
    "    print(f\"ğŸ‘¥ CLIENTS ANORMAUX : {len(anomalous_customers)} clients\")\n",
    "    print(f\"â° JOURS ANORMAUX : {len(temporal_anomalies)} jours\")\n",
    "    \n",
    "    # Pourcentages\n",
    "    total_transactions = len(transaction_stats)\n",
    "    total_products = len(product_anomalies)\n",
    "    total_customers = len(customer_behavior)\n",
    "    total_days = len(daily_sales)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ POURCENTAGES D'ANOMALIES :\")\n",
    "    print(f\"   Transactions: {len(order_anomalies)/total_transactions*100:.1f}%\")\n",
    "    print(f\"   Produits: {len(price_anomalies)/total_products*100:.1f}%\")\n",
    "    print(f\"   Clients: {len(anomalous_customers)/total_customers*100:.1f}%\")\n",
    "    print(f\"   Jours: {len(temporal_anomalies)/total_days*100:.1f}%\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(f\"\\nğŸ’¡ RECOMMANDATIONS :\")\n",
    "    print(\"ğŸ” ACTIONS IMMÃ‰DIATES :\")\n",
    "    print(\"   â€¢ VÃ©rifier les commandes > $10,000\")\n",
    "    print(\"   â€¢ Investiguer les variations de prix > 100%\")\n",
    "    print(\"   â€¢ Analyser les clients avec score anomalie < -0.5\")\n",
    "    print(\"   â€¢ Examiner les pics de ventes inexpliquÃ©s\")\n",
    "    \n",
    "    print(\"ğŸ›¡ï¸ MESURES PRÃ‰VENTIVES :\")\n",
    "    print(\"   â€¢ Alertes automatiques pour commandes > seuil\")\n",
    "    print(\"   â€¢ Validation manuelle pour variations prix > 50%\")\n",
    "    print(\"   â€¢ Monitoring comportement clients VIP\")\n",
    "    print(\"   â€¢ SystÃ¨me de dÃ©tection temps rÃ©el\")\n",
    "    \n",
    "    return {\n",
    "        'transaction_anomalies': order_anomalies,\n",
    "        'product_anomalies': price_anomalies,\n",
    "        'customer_anomalies': anomalous_customers,\n",
    "        'temporal_anomalies': temporal_anomalies,\n",
    "        'figures': [fig1, fig2, fig3, fig4],\n",
    "        'summary_stats': {\n",
    "            'total_transaction_anomalies': len(order_anomalies),\n",
    "            'total_product_anomalies': len(price_anomalies),\n",
    "            'total_customer_anomalies': len(anomalous_customers),\n",
    "            'total_temporal_anomalies': len(temporal_anomalies)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ExÃ©cution de la dÃ©tection d'anomalies\n",
    "anomaly_results = detect_anomalies_complete(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2269c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ RAPPORT FINAL - ANALYSE EXPLORATOIRE\n",
      "==================================================\n",
      "ğŸ¯ SYNTHÃˆSE EXÃ‰CUTIVE\n",
      "====================\n",
      "ğŸ“Š MÃ‰TRIQUES BUSINESS GLOBALES\n",
      "   ğŸ’° Chiffre d'affaires total: $18,928,949.47\n",
      "   ğŸ“¦ Nombre de commandes: 53,628\n",
      "   ğŸ‘¥ Clients uniques: 248,949\n",
      "   ğŸ›ï¸ Produits uniques: 5,305\n",
      "   ğŸ’³ Panier moyen: $352.97\n",
      "   ğŸ“… PÃ©riode analysÃ©e: 738 jours (2009-12-01 â†’ 2011-12-09)\n",
      "\n",
      "ğŸ” INSIGHTS CLÃ‰S DÃ‰COUVERTS\n",
      "==============================\n",
      "ğŸ‘¥ DIMENSION CLIENTS :\n",
      "   ğŸ’ Top 20% clients gÃ©nÃ¨rent 98.5% du CA\n",
      "   ğŸ“ˆ Client le plus valuable: $570,380.61\n",
      "   ğŸ”„ Commandes moyennes par client: 1.2\n",
      "\n",
      "ğŸ“¦ DIMENSION PRODUITS :\n",
      "   ğŸ† Top 10 produits reprÃ©sentent 9.2% du CA\n",
      "   ğŸ¯ Produit star:  $ 322,647.47 de revenus\n",
      "   ğŸ“Š 80/20 Rule: 1061 produits gÃ©nÃ¨rent 80% du CA\n",
      "\n",
      "â° DIMENSION TEMPORELLE :\n",
      "   ğŸ“ˆ Meilleur mois: Mois 11 (2,872,964 $ )\n",
      "   ğŸ“‰ Mois le plus faible: Mois 2 (1,028,339$)\n",
      "   ğŸ—“ï¸ Meilleur jour: Jeudi (3,902,397$)\n",
      "\n",
      "ğŸš¨ ANOMALIES CRITIQUES DÃ‰TECTÃ‰ES\n",
      "===================================\n",
      "ğŸ“Š RÃ‰SUMÃ‰ DES ANOMALIES :\n",
      "   ğŸ’° Transactions suspectes: 3972\n",
      "   ğŸ“¦ Produits avec prix anormaux: 1170\n",
      "   ğŸ‘¥ Clients au comportement atypique: 12448\n",
      "   â° Jours avec activitÃ© anormale: 55\n",
      "   ğŸ’¸ Impact financier anomalies: $8,256,853.01 (43.6% du CA)\n",
      "\n",
      "ğŸ“Š CRÃ‰ATION DU DASHBOARD RÃ‰CAPITULATIF\n",
      "========================================\n",
      "\n",
      "ğŸ¯ RECOMMANDATIONS STRATÃ‰GIQUES\n",
      "===================================\n",
      "ğŸš€ RECOMMANDATIONS IMMÃ‰DIATES (0-3 mois):\n",
      "   1. ğŸ‘¥ CLIENTS :\n",
      "      â€¢ CrÃ©er programme fidÃ©litÃ© pour top 20% clients\n",
      "      â€¢ Campagne de rÃ©activation clients inactifs\n",
      "      â€¢ Analyse dÃ©taillÃ©e des clients Ã  forte valeur\n",
      "      â€¢ Segmentation RFM pour personnalisation\n",
      "   2. ğŸ“¦ PRODUITS :\n",
      "      â€¢ Optimiser stock des produits stars\n",
      "      â€¢ Analyser marge des top performers\n",
      "      â€¢ Cross-selling sur produits complÃ©mentaires\n",
      "      â€¢ Ã‰liminer produits low-performers\n",
      "   3. ğŸ’° PRICING :\n",
      "      â€¢ Investiguer variations prix anormales\n",
      "      â€¢ Standardiser politique tarifaire\n",
      "      â€¢ Tests A/B sur pricing dynamique\n",
      "      â€¢ Monitoring concurrence\n",
      "   4. ğŸ›¡ï¸ CONTRÃ”LE QUALITÃ‰ :\n",
      "      â€¢ SystÃ¨me d'alertes pour commandes > $10K\n",
      "      â€¢ Validation manuelle transactions suspectes\n",
      "      â€¢ Audit des comptes clients anormaux\n",
      "      â€¢ VÃ©rification des pics de ventes\n",
      "\n",
      "ğŸ“ˆ RECOMMANDATIONS MOYEN TERME (3-12 mois):\n",
      "   1. ğŸ¯ STRATÃ‰GIE MARKETING :\n",
      "      â€¢ Campagnes ciblÃ©es par segment client\n",
      "      â€¢ Optimisation saisonniÃ¨re des promotions\n",
      "      â€¢ Marketing automation basÃ© sur comportement\n",
      "      â€¢ StratÃ©gie omnicanal\n",
      "   2. ğŸ“Š ANALYTICS AVANCÃ‰S :\n",
      "      â€¢ ModÃ¨les prÃ©dictifs de churn\n",
      "      â€¢ Scoring de valeur client (CLV)\n",
      "      â€¢ Recommandations produits IA\n",
      "      â€¢ Forecasting des ventes\n",
      "   3. ğŸ—ï¸ INFRASTRUCTURE :\n",
      "      â€¢ Dashboard temps rÃ©el\n",
      "      â€¢ SystÃ¨me de dÃ©tection anomalies automatique\n",
      "      â€¢ Data pipeline optimisÃ©\n",
      "      â€¢ Reporting automatisÃ©\n",
      "\n",
      "ğŸ—ºï¸ ROADMAP PROCHAINES ANALYSES\n",
      "==============================\n",
      "ğŸ“‹ NOTEBOOK 4 - FEATURE ENGINEERING :\n",
      "   â€¢ CrÃ©ation variables RFM\n",
      "   â€¢ Features temporelles avancÃ©es\n",
      "   â€¢ Encoding catÃ©gorielles\n",
      "   â€¢ Features d'interaction\n",
      "ğŸ“‹ NOTEBOOK 5 - MACHINE LEARNING :\n",
      "   â€¢ Clustering clients (K-means)\n",
      "   â€¢ PrÃ©diction valeur client\n",
      "   â€¢ SystÃ¨me de recommandation\n",
      "   â€¢ DÃ©tection churn\n",
      "ğŸ“‹ NOTEBOOK 6 - DÃ‰PLOIEMENT :\n",
      "   â€¢ API de prÃ©diction\n",
      "   â€¢ Dashboard interactif\n",
      "   â€¢ Monitoring modÃ¨les\n",
      "   â€¢ Documentation complÃ¨te\n",
      "\n",
      "ğŸ“ˆ MÃ‰TRIQUES DE PERFORMANCE Ã€ SUIVRE\n",
      "========================================\n",
      "ğŸ¯ KPIs ACTUELS :\n",
      "   ğŸ’° CA mensuel moyen: $757,157.98\n",
      "   ğŸ“ˆ Croissance dernier mois: -70.3%\n",
      "   ğŸ‘¥ Clients actifs/mois: 10120\n",
      "   ğŸ›’ Commandes/jour: 72.7\n",
      "   ğŸ’³ Panier moyen: $352.97\n",
      "\n",
      "ğŸ¯ KPIs Ã€ MONITORER :\n",
      "   â€¢ Taux de rÃ©tention client\n",
      "   â€¢ Customer Lifetime Value (CLV)\n",
      "   â€¢ Taux de conversion\n",
      "   â€¢ FrÃ©quence d'achat\n",
      "   â€¢ Marge brute par segment\n",
      "\n",
      "âœ… RAPPORT FINAL GÃ‰NÃ‰RÃ‰ AVEC SUCCÃˆS !\n",
      "===================================\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ NOTEBOOK 3 - ANALYSE EXPLORATOIRE TERMINÃ‰ !\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š RÃ‰SUMÃ‰ DE CE QUE NOUS AVONS ACCOMPLI :\n",
      "   âœ… Analyse exploratoire complÃ¨te\n",
      "   âœ… Visualisations avancÃ©es (15+ graphiques)\n",
      "   âœ… Analyse saisonnalitÃ© dÃ©taillÃ©e\n",
      "   âœ… DÃ©tection d'anomalies multi-dimensionnelle\n",
      "   âœ… Insights business actionnables\n",
      "   âœ… Recommandations stratÃ©giques\n",
      "   âœ… Dashboard rÃ©capitulatif\n",
      "   âœ… Roadmap pour la suite\n",
      "\n",
      "ğŸš€ PROCHAINE Ã‰TAPE : NOTEBOOK 4 - FEATURE ENGINEERING\n",
      "   ğŸ¯ Objectif: PrÃ©parer les donnÃ©es pour le ML\n",
      "   ğŸ› ï¸ Techniques: RFM, Variables temporelles, Encoding\n",
      "   ğŸ“Š RÃ©sultat: Dataset prÃªt pour modÃ©lisation\n",
      "\n",
      "ğŸ’¾ DONNÃ‰ES PRÃŠTES POUR LA SUITE :\n",
      "   â€¢ Dataset nettoyÃ©: 1040892 lignes\n",
      "   â€¢ Variables crÃ©Ã©es: 21 colonnes\n",
      "   â€¢ Anomalies identifiÃ©es: 17645\n",
      "   â€¢ Insights business: 20+ recommandations\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ“‹ RAPPORT FINAL + RECOMMANDATIONS - NOTEBOOK 3\n",
    "# ============================================================================\n",
    "\n",
    "def generate_final_report(df, seasonal_results, anomaly_results):\n",
    "    \"\"\"\n",
    "    GÃ©nÃ©ration du rapport final avec recommandations stratÃ©giques\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“‹ RAPPORT FINAL - ANALYSE EXPLORATOIRE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 1. SYNTHÃˆSE EXÃ‰CUTIVE\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(\"ğŸ¯ SYNTHÃˆSE EXÃ‰CUTIVE\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # MÃ©triques clÃ©s globales\n",
    "    total_revenue = df['Total_Amount'].sum()\n",
    "    total_transactions = df['Invoice'].nunique()\n",
    "    total_customers = df['Customer ID'].nunique()\n",
    "    total_products = df['StockCode'].nunique()\n",
    "    avg_order_value = total_revenue / total_transactions\n",
    "    \n",
    "    # PÃ©riode d'analyse\n",
    "    start_date = df['InvoiceDate'].min()\n",
    "    end_date = df['InvoiceDate'].max()\n",
    "    analysis_period = (end_date - start_date).days\n",
    "    \n",
    "    print(f\"ğŸ“Š MÃ‰TRIQUES BUSINESS GLOBALES\")\n",
    "    print(f\"   ğŸ’° Chiffre d'affaires total: ${total_revenue:,.2f}\")\n",
    "    print(f\"   ğŸ“¦ Nombre de commandes: {total_transactions:,}\")\n",
    "    print(f\"   ğŸ‘¥ Clients uniques: {total_customers:,}\")\n",
    "    print(f\"   ğŸ›ï¸ Produits uniques: {total_products:,}\")\n",
    "    print(f\"   ğŸ’³ Panier moyen: ${avg_order_value:.2f}\")\n",
    "    print(f\"   ğŸ“… PÃ©riode analysÃ©e: {analysis_period} jours ({start_date.strftime('%Y-%m-%d')} â†’ {end_date.strftime('%Y-%m-%d')})\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 2. INSIGHTS CLÃ‰S PAR DIMENSION\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ” INSIGHTS CLÃ‰S DÃ‰COUVERTS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # A. INSIGHTS CLIENTS\n",
    "    print(\"ğŸ‘¥ DIMENSION CLIENTS :\")\n",
    "    customer_segments = df.groupby('Customer ID').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Invoice': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Segmentation clients\n",
    "    top_20_customers = customer_segments.nlargest(int(len(customer_segments) * 0.2), 'Total_Amount')\n",
    "    top_20_revenue = top_20_customers['Total_Amount'].sum()\n",
    "    \n",
    "    print(f\"   ğŸ’ Top 20% clients gÃ©nÃ¨rent {top_20_revenue/total_revenue*100:.1f}% du CA\")\n",
    "    print(f\"   ğŸ“ˆ Client le plus valuable: ${customer_segments['Total_Amount'].max():,.2f}\")\n",
    "    print(f\"   ğŸ”„ Commandes moyennes par client: {customer_segments['Invoice'].mean():.1f}\")\n",
    "    \n",
    "    # B. INSIGHTS PRODUITS\n",
    "    print(f\"\\nğŸ“¦ DIMENSION PRODUITS :\")\n",
    "    product_performance = df.groupby('StockCode').agg({\n",
    "        'Total_Amount': 'sum',\n",
    "        'Quantity': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    top_products = product_performance.nlargest(10, 'Total_Amount')\n",
    "    top_10_revenue = top_products['Total_Amount'].sum()\n",
    "    \n",
    "    print(f\"   ğŸ† Top 10 produits reprÃ©sentent {top_10_revenue/total_revenue*100:.1f}% du CA\")\n",
    "    print(f\"   ğŸ¯ Produit star:  $ {product_performance['Total_Amount'].max():,.2f} de revenus\")\n",
    "    print(f\"   ğŸ“Š 80/20 Rule: {(product_performance['Total_Amount'] > product_performance['Total_Amount'].quantile(0.8)).sum()} produits gÃ©nÃ¨rent 80% du CA\")\n",
    "    \n",
    "    # C. INSIGHTS TEMPORELS\n",
    "    print(f\"\\nâ° DIMENSION TEMPORELLE :\")\n",
    "    \n",
    "    # Meilleurs mois (depuis seasonal_results)\n",
    "    monthly_data = df.groupby(df['InvoiceDate'].dt.month).agg({\n",
    "        'Total_Amount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    best_month = monthly_data.loc[monthly_data['Total_Amount'].idxmax(), 'InvoiceDate']\n",
    "    worst_month = monthly_data.loc[monthly_data['Total_Amount'].idxmin(), 'InvoiceDate']\n",
    "    \n",
    "    print(f\"   ğŸ“ˆ Meilleur mois: Mois {best_month} ({monthly_data['Total_Amount'].max():,.0f} $ )\")\n",
    "    print(f\"   ğŸ“‰ Mois le plus faible: Mois {worst_month} ({monthly_data['Total_Amount'].min():,.0f}$)\")\n",
    "    \n",
    "    # Jour de la semaine\n",
    "    weekday_performance = df.groupby(df['InvoiceDate'].dt.dayofweek)['Total_Amount'].sum()\n",
    "    best_day = weekday_performance.idxmax()\n",
    "    days_names = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "    \n",
    "    print(f\"   ğŸ—“ï¸ Meilleur jour: {days_names[best_day]} ({weekday_performance.max():,.0f}$)\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 3. ANALYSE DES ANOMALIES DÃ‰TECTÃ‰ES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸš¨ ANOMALIES CRITIQUES DÃ‰TECTÃ‰ES\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # RÃ©cupÃ©ration des rÃ©sultats d'anomalies\n",
    "    anom_stats = anomaly_results['summary_stats']\n",
    "    \n",
    "    print(f\"ğŸ“Š RÃ‰SUMÃ‰ DES ANOMALIES :\")\n",
    "    print(f\"   ğŸ’° Transactions suspectes: {anom_stats['total_transaction_anomalies']}\")\n",
    "    print(f\"   ğŸ“¦ Produits avec prix anormaux: {anom_stats['total_product_anomalies']}\")\n",
    "    print(f\"   ğŸ‘¥ Clients au comportement atypique: {anom_stats['total_customer_anomalies']}\")\n",
    "    print(f\"   â° Jours avec activitÃ© anormale: {anom_stats['total_temporal_anomalies']}\")\n",
    "    \n",
    "    # Impact des anomalies\n",
    "    transaction_anomalies = anomaly_results['transaction_anomalies']\n",
    "    if len(transaction_anomalies) > 0:\n",
    "        anomaly_revenue = transaction_anomalies['Total_Order_Value'].sum()\n",
    "        print(f\"   ğŸ’¸ Impact financier anomalies: ${anomaly_revenue:,.2f} ({anomaly_revenue/total_revenue*100:.1f}% du CA)\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 4. DASHBOARD RÃ‰CAPITULATIF\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“Š CRÃ‰ATION DU DASHBOARD RÃ‰CAPITULATIF\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Dashboard avec 4 graphiques principaux\n",
    "    fig_dashboard = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'ğŸ’° TOP 10 CLIENTS (CA)',\n",
    "            'ğŸ“¦ TOP 10 PRODUITS (Revenus)',\n",
    "            'ğŸ“… Ã‰VOLUTION MENSUELLE',\n",
    "            'ğŸ• PERFORMANCE HORAIRE'\n",
    "        ),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Top 10 clients\n",
    "    top_customers = df.groupby('Customer ID')['Total_Amount'].sum().nlargest(10)\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=top_customers.index.astype(str), y=top_customers.values, name='Top Clients'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Top 10 produits\n",
    "    top_products_viz = df.groupby('StockCode')['Total_Amount'].sum().nlargest(10)\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=top_products_viz.index, y=top_products_viz.values, name='Top Produits'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Ã‰volution mensuelle\n",
    "    monthly_evolution = df.groupby(df['InvoiceDate'].dt.to_period('M'))['Total_Amount'].sum()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Scatter(x=monthly_evolution.index.astype(str), y=monthly_evolution.values, \n",
    "                  mode='lines+markers', name='CA Mensuel'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Performance horaire\n",
    "    hourly_perf = df.groupby(df['InvoiceDate'].dt.hour)['Total_Amount'].sum()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=hourly_perf.index, y=hourly_perf.values, name='CA par Heure'),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig_dashboard.update_layout(\n",
    "        title_text=\"ğŸ“Š DASHBOARD RÃ‰CAPITULATIF - ANALYSE E-COMMERCE\",\n",
    "        showlegend=False,\n",
    "        height=800,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig_dashboard.show()\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 5. RECOMMANDATIONS STRATÃ‰GIQUES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ¯ RECOMMANDATIONS STRATÃ‰GIQUES\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    print(\"ğŸš€ RECOMMANDATIONS IMMÃ‰DIATES (0-3 mois):\")\n",
    "    print(\"   1. ğŸ‘¥ CLIENTS :\")\n",
    "    print(\"      â€¢ CrÃ©er programme fidÃ©litÃ© pour top 20% clients\")\n",
    "    print(\"      â€¢ Campagne de rÃ©activation clients inactifs\")\n",
    "    print(\"      â€¢ Analyse dÃ©taillÃ©e des clients Ã  forte valeur\")\n",
    "    print(\"      â€¢ Segmentation RFM pour personnalisation\")\n",
    "    \n",
    "    print(\"   2. ğŸ“¦ PRODUITS :\")\n",
    "    print(\"      â€¢ Optimiser stock des produits stars\")\n",
    "    print(\"      â€¢ Analyser marge des top performers\")\n",
    "    print(\"      â€¢ Cross-selling sur produits complÃ©mentaires\")\n",
    "    print(\"      â€¢ Ã‰liminer produits low-performers\")\n",
    "    \n",
    "    print(\"   3. ğŸ’° PRICING :\")\n",
    "    print(\"      â€¢ Investiguer variations prix anormales\")\n",
    "    print(\"      â€¢ Standardiser politique tarifaire\")\n",
    "    print(\"      â€¢ Tests A/B sur pricing dynamique\")\n",
    "    print(\"      â€¢ Monitoring concurrence\")\n",
    "    \n",
    "    print(\"   4. ğŸ›¡ï¸ CONTRÃ”LE QUALITÃ‰ :\")\n",
    "    print(\"      â€¢ SystÃ¨me d'alertes pour commandes > $10K\")\n",
    "    print(\"      â€¢ Validation manuelle transactions suspectes\")\n",
    "    print(\"      â€¢ Audit des comptes clients anormaux\")\n",
    "    print(\"      â€¢ VÃ©rification des pics de ventes\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ RECOMMANDATIONS MOYEN TERME (3-12 mois):\")\n",
    "    print(\"   1. ğŸ¯ STRATÃ‰GIE MARKETING :\")\n",
    "    print(\"      â€¢ Campagnes ciblÃ©es par segment client\")\n",
    "    print(\"      â€¢ Optimisation saisonniÃ¨re des promotions\")\n",
    "    print(\"      â€¢ Marketing automation basÃ© sur comportement\")\n",
    "    print(\"      â€¢ StratÃ©gie omnicanal\")\n",
    "    \n",
    "    print(\"   2. ğŸ“Š ANALYTICS AVANCÃ‰S :\")\n",
    "    print(\"      â€¢ ModÃ¨les prÃ©dictifs de churn\")\n",
    "    print(\"      â€¢ Scoring de valeur client (CLV)\")\n",
    "    print(\"      â€¢ Recommandations produits IA\")\n",
    "    print(\"      â€¢ Forecasting des ventes\")\n",
    "    \n",
    "    print(\"   3. ğŸ—ï¸ INFRASTRUCTURE :\")\n",
    "    print(\"      â€¢ Dashboard temps rÃ©el\")\n",
    "    print(\"      â€¢ SystÃ¨me de dÃ©tection anomalies automatique\")\n",
    "    print(\"      â€¢ Data pipeline optimisÃ©\")\n",
    "    print(\"      â€¢ Reporting automatisÃ©\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 6. ROADMAP PROCHAINES ANALYSES\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ—ºï¸ ROADMAP PROCHAINES ANALYSES\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(\"ğŸ“‹ NOTEBOOK 4 - FEATURE ENGINEERING :\")\n",
    "    print(\"   â€¢ CrÃ©ation variables RFM\")\n",
    "    print(\"   â€¢ Features temporelles avancÃ©es\")\n",
    "    print(\"   â€¢ Encoding catÃ©gorielles\")\n",
    "    print(\"   â€¢ Features d'interaction\")\n",
    "    \n",
    "    print(\"ğŸ“‹ NOTEBOOK 5 - MACHINE LEARNING :\")\n",
    "    print(\"   â€¢ Clustering clients (K-means)\")\n",
    "    print(\"   â€¢ PrÃ©diction valeur client\")\n",
    "    print(\"   â€¢ SystÃ¨me de recommandation\")\n",
    "    print(\"   â€¢ DÃ©tection churn\")\n",
    "    \n",
    "    print(\"ğŸ“‹ NOTEBOOK 6 - DÃ‰PLOIEMENT :\")\n",
    "    print(\"   â€¢ API de prÃ©diction\")\n",
    "    print(\"   â€¢ Dashboard interactif\")\n",
    "    print(\"   â€¢ Monitoring modÃ¨les\")\n",
    "    print(\"   â€¢ Documentation complÃ¨te\")\n",
    "    \n",
    "    # =======================================================================\n",
    "    # 7. MÃ‰TRIQUES DE PERFORMANCE\n",
    "    # =======================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ MÃ‰TRIQUES DE PERFORMANCE Ã€ SUIVRE\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Calcul des KPIs actuels\n",
    "    monthly_growth = df.groupby(df['InvoiceDate'].dt.to_period('M'))['Total_Amount'].sum()\n",
    "    if len(monthly_growth) > 1:\n",
    "        last_month_growth = ((monthly_growth.iloc[-1] - monthly_growth.iloc[-2]) / monthly_growth.iloc[-2] * 100)\n",
    "    else:\n",
    "        last_month_growth = 0\n",
    "    \n",
    "    print(\"ğŸ¯ KPIs ACTUELS :\")\n",
    "    print(f\"   ğŸ’° CA mensuel moyen: ${monthly_growth.mean():,.2f}\")\n",
    "    print(f\"   ğŸ“ˆ Croissance dernier mois: {last_month_growth:.1f}%\")\n",
    "    print(f\"   ğŸ‘¥ Clients actifs/mois: {total_customers/(analysis_period/30):.0f}\")\n",
    "    print(f\"   ğŸ›’ Commandes/jour: {total_transactions/(analysis_period):.1f}\")\n",
    "    print(f\"   ğŸ’³ Panier moyen: ${avg_order_value:.2f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ KPIs Ã€ MONITORER :\")\n",
    "    print(\"   â€¢ Taux de rÃ©tention client\")\n",
    "    print(\"   â€¢ Customer Lifetime Value (CLV)\")\n",
    "    print(\"   â€¢ Taux de conversion\")\n",
    "    print(\"   â€¢ FrÃ©quence d'achat\")\n",
    "    print(\"   â€¢ Marge brute par segment\")\n",
    "    \n",
    "    # Sauvegarde des rÃ©sultats\n",
    "    report_summary = {\n",
    "        'total_revenue': total_revenue,\n",
    "        'total_transactions': total_transactions,\n",
    "        'total_customers': total_customers,\n",
    "        'avg_order_value': avg_order_value,\n",
    "        'analysis_period': analysis_period,\n",
    "        'anomalies_detected': anom_stats,\n",
    "        'top_customers': top_customers.to_dict(),\n",
    "        'top_products': top_products_viz.to_dict(),\n",
    "        'monthly_growth': last_month_growth\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nâœ… RAPPORT FINAL GÃ‰NÃ‰RÃ‰ AVEC SUCCÃˆS !\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    return report_summary, fig_dashboard\n",
    "\n",
    "# GÃ©nÃ©ration du rapport final\n",
    "final_report, dashboard_fig = generate_final_report(df, seasonal_results, anomaly_results)\n",
    "\n",
    "# =======================================================================\n",
    "# CONCLUSION NOTEBOOK 3\n",
    "# =======================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ NOTEBOOK 3 - ANALYSE EXPLORATOIRE TERMINÃ‰ !\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nğŸ“Š RÃ‰SUMÃ‰ DE CE QUE NOUS AVONS ACCOMPLI :\")\n",
    "print(\"   âœ… Analyse exploratoire complÃ¨te\")\n",
    "print(\"   âœ… Visualisations avancÃ©es (15+ graphiques)\")\n",
    "print(\"   âœ… Analyse saisonnalitÃ© dÃ©taillÃ©e\")\n",
    "print(\"   âœ… DÃ©tection d'anomalies multi-dimensionnelle\")\n",
    "print(\"   âœ… Insights business actionnables\")\n",
    "print(\"   âœ… Recommandations stratÃ©giques\")\n",
    "print(\"   âœ… Dashboard rÃ©capitulatif\")\n",
    "print(\"   âœ… Roadmap pour la suite\")\n",
    "\n",
    "print(f\"\\nğŸš€ PROCHAINE Ã‰TAPE : NOTEBOOK 4 - FEATURE ENGINEERING\")\n",
    "print(\"   ğŸ¯ Objectif: PrÃ©parer les donnÃ©es pour le ML\")\n",
    "print(\"   ğŸ› ï¸ Techniques: RFM, Variables temporelles, Encoding\")\n",
    "print(\"   ğŸ“Š RÃ©sultat: Dataset prÃªt pour modÃ©lisation\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ DONNÃ‰ES PRÃŠTES POUR LA SUITE :\")\n",
    "print(f\"   â€¢ Dataset nettoyÃ©: {len(df)} lignes\")\n",
    "print(f\"   â€¢ Variables crÃ©Ã©es: {len(df.columns)} colonnes\")\n",
    "print(f\"   â€¢ Anomalies identifiÃ©es: {sum(final_report['anomalies_detected'].values())}\")\n",
    "print(f\"   â€¢ Insights business: 20+ recommandations\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
